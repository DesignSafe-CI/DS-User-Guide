diff --git a/user-guide/docs/curating/bestpractices.md b/user-guide/docs/curating/bestpractices.md
index ecec6129..c61573b4 100644
--- a/user-guide/docs/curating/bestpractices.md
+++ b/user-guide/docs/curating/bestpractices.md
@@ -1,778 +1,281 @@
-## Best Practices
+# Best Practices for Data Curation and Publication 
 
-### Data Collections Development
+## Curation Quality 
 
-#### Accepted Data  { #accepteddata }
+Curation quality involves ensuring the accuracy, completeness, consistency, and reliability of your dataset.  In the DDR, curation quality policies as well as the curation and publication interactive functions are geared towards ensuring excellence in data publications. Each data publication is unique; it reflects and provides evidence of the research work of individuals and teams. It is the user's responsibility to publish data that is up to the best standards of their profession, and the DDR's  commitment is to help them achieve these standards.In addition, the following best practices are highly recommended to assure that a dataset is curated towards reusability and reproducibility:
 
-The DDR accepts engineering datasets generated through simulation, hybrid simulation, experimental, and field research methods regarding the impacts of wind, earthquake, and storm surge hazards, as well as debris management, fire, and blast explosions. We also accept social and behavioral sciences (SBE) data encompassing the study of the human dimensions of hazards and disasters. As the field and the expertise of the community evolves we have expanded our focus to include datasets related to COVID-19. Data reports, publications of Jupyter notebooks, code, scripts, lectures, and learning materials are also accepted.
+* Check for completeness of data transfer. Sometimes users upload folders with large numbers of files, and transfers get interrupted so everything in the folder may not get transferred. Please check that all folders contain all the files intended.
+* Use quality control methods to review the data for errors or to improve its fitness to the research application. Methods may involve: calibration, validation, normalization, resizing, improved resolution, cleaning, transformation to open formats, noise reduction, sub-sampling, performance testing, consolidation, further documentation, etc. Always include an explanation of the quality control methods you used in the data report or readme file so that other users are aware of the quality control methods employed. 
+* When publishing tabular data include a data dictionary in the data report to explain the meaning of the column fields. 
+* Data dictionaries are also useful to clarify acronyms, abbreviations or codes for measurements used in your data or documentation.
+* It is possible to publish both raw and curated data. Raw data comes directly from experiment recording instruments (camera, apps, sensors, scanners, etc). When raw data is corrected, calibrated, reviewed, edited or post-processed in any way for publication, it is considered curated. Some researchers want to publish their raw data along with their curated data. For those who wish to publish both, carefully consider the necessity of publishing both sets, and how another researcher might use them. Always clarify whether your data is raw or curated in the description, by adding a tag to label the files, or in a data report and include information about the method used to curate it.
+* Researchers generate enormous amounts of images and other file types. While there are no restrictions on the number of files in a project, it is important to be selective as to not overwhelm users. Make sure that all images have a purpose and are illustrative of a process or a function, and avoid redundancy. Use file tags to describe them, this is to make sure users know what you want to highlight. The same approach should be applied for other data formats.
+* Researchers that publish large amounts of files (for example as simulation outputs or field research collections) should consider publishing scripts/tools that allow selection/visualization/post-processing of files of interest so users can review and subset  data.
+* When publishing scripts/code, always include a readme file that explains clearly how to use the scripts.
+* Before publishing scripts and notebooks, always make sure your code works properly.
 
-#### Accepted and Recommended File Formats  { #acceptedfileformats }
 
-Due to the diversity of data and instruments used by our community, there are no current restrictions on the file formats users can upload to the DDR. However, for long-term preservation and interoperability purposes, we recommend and promote storing and publishing data in open formats, and we follow the <a href="https://www.loc.gov/preservation/resources/rfs/TOC.html">Library of Congress Recommended Formats</a>.
 
-In addition, we suggest that users look into the <a href="https://datacurationnetwork.org/outputs/data-curation-primers/">Data Curation Primers</a>, which are "peer-reviewed, living documents that detail a specific subject, disciplinary area or curation task and that can be used as a reference to curate research data.  The primers include curation practices for documenting data types that while not open or recommended, are very established in the academic fields surrounding Natural Hazards research such as Matlab and Microsoft Excel.
+### AI-Ready Curation Quality
 
-Below is an adaptation of the list of recommended formats for data and documentation by <a href="https://guides.library.stanford.edu/data-best-practices/format-files">Stanford Libraries.</a> For those available, we include a link to the curation primers:
+AI Ready curation quality  is about ensuring data is clean, organized, structured, unbiased, and includes necessary contextual information to support AI workflows effectively leading to secure and meaningful outcomes. Overall, it points to achieving research reproducibility. DDR's policies and best practices cover many of the requirements to publish AI ready data, and we notice via citations that many types of published datasets in DDR are used in AI applications. There are additional recommendations for datasets specifically created to train particular ML models and or benchmarks and testbeds to be used in many applications. In those cases, beyond following all the applicable policies and best practices to publish a quality dataset, researchers should also:
 
-* <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/Databases%20Data%20Curation%20Primer/databases-data-curation-primer.md">Databases</a>: XML, CSV
-* <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/Geodatabase%20Data%20Curation%20Primer/Geodata-Primer.md">Geospatial</a>: SHP, DBF, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/GeoTIFF%20Data%20Curation%20Primer/geotiff-data-curation-primer.md">GeoTIFF</a>, <a href="https://deepblue.lib.umich.edu/handle/2027.42/145724">netCDF</a>, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/GeoJSON%20Data%20Curation%20Primer/GeoJSON-data-curation-primer.md">GeoJSON </a> 
-* PointCloud: LAS, LAZ, XYZ, PTX
-* Moving images: MOV, MPEG, AVI, MXF
-* Sounds: WAVE, AIFF, MP3, MXF
-* Statistics: ASCII, DTA, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/SPSS%20Data%20Curation%20Primer/SPSS-data-curation-primer.md#Format-Overview">POR</a>, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/SAS%20Data%20Curation%20Primer/SAS-data-curation-primer.md">SAS</a>, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/SPSS%20Data%20Curation%20Primer/SPSS-data-curation-primer.md#Format-Overview">SAV</a>
-* Still images: TIFF, JPEG 2000, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/PDF%20Data%20Curation%20Primer/PDF-data-curation-primer.md">PDF,</a> PNG, GIF, BMP
-* <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/Tableau%20Data%20Curation%20Primer/Tableau-data-curation-primer.md">Tabular data</a>: CSV
-* Text: XML, <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/PDF%20Data%20Curation%20Primer/PDF-data-curation-primer.md">PDF/A</a>, HTML, ASCII, UTF-8 , 
-* CODE:  (tcl files, py files) <a href="https://github.com/DataCurationNetwork/data-primers/blob/master/Jupyter%20Notebook%20Data%20Curation%20Primer/Jupyter%20Notebooks%20Data%20Curation%20Primer.md">Jupyter Notebook</a>
-* Seismology: SEED
-
-#### Data Size { #datasize }
-
-Currently we do not pose restrictions on the volume of data users upload to and publish in the DDR. This is meant to accommodate the vast amount of data researchers in the natural hazards community can generate, especially during the course of large-scale research projects.
-
-However, for data curation and publication purposes users need to consider the sizes of their data for its proper reuse. Publishing large amounts of data requires more curation work (organizing and describing) so that other users can understand the structure and contents of the dataset. In addition, downloading very large projects may require the use of [Globus](../../managingdata/datatransfer#globus).  We further discuss data selection and quality considerations in the Data Curation section.
-
----
-
-### Data Curation
-
-Data curation involves the organization, description, quality control, preservation, accessibility, and ease of reuse of data, with the goal of making your data publication <a href="https://www.go-fair.org/fair-principles/">FAIR</a> with assurance that it will be useful for generations to come.
+* Reference the public model used to train the data in the field Reference Data or Software.  
+* Document in the data report the results of the trained model including the model's performance under the published dataset. If the results are published in a paper, reference the paper in Related Work. 
+* Reference any data if/that was reused to generate the training/benchmark dataset.
 
-Extensive support for data curation can be found in the <a href="#curation-publication-guides">Data Curation and Publication User Guides</a> and in <a href="https://www.youtube.com/playlist?list=PL2GxvrdFrBlkwHBgQ47pZO-77ZLrJKYHV">Data Curation Tutorials</a>. In addition, we strongly recommend that users follow the step by step onboarding instructions available in the My Projects curation interface. <a href="#nheri-virtual-office-hours">Virtual Office Hours</a> are also available twice a week.
+The concept is that AI ready data involves showcasing a network of resources that includes: the data, the model and the performance of the model/results. The following are examples of datasets published in DDR that comply with AI readiness.
 
-Below we highlight general curation best practices.
 
-#### Managing and Sharing Data in My Projects { #managingdata }
 
-All data and documentation collected and generated during a research project can be uploaded to My Project from the inception of the project. Within My Project, data are kept private for sharing amongst team members and for curation until published. Using My Project to share data with your team members during the course of research facilitates the progressive curation of data and its eventual publication.
+Del-Castillo-Negrete, C., B. Pachev, P. Arora, E. Valseth, C. Dawson (2023). "Alaska 1m Surge Events - Nome, Red Dog Dock, Unalakleet (1992 - 2022)", in Alaska Storm Surge Events. DesignSafe-CI. [https://doi.org/10.17603/ds2-4rnb-j321](https://doi.org/10.17603/ds2-4rnb-j321)
 
-However, when conducting human subjects research, you must follow and comply with the procedures submitted to and approved by your Institutional Review Board (IRB) as well as your own ethical commitment to participants for sharing protected data in My Project.
 
-Researchers working at a NHERI EF will receive their bulk data files directly into an existing My Project created for the team.
 
-For all other research performed at a non-NHERI facility, it will be the responsibility of the research team to upload their data to the DDR.
+Massey, C., D. Townsend, B. Rosser, R. Morgenstern, K. Jones, B. Lukovic, J. Davidson (2021). "Version 2.0 of the landslide inventory for the Mw 7.8 14 November 2016, Kaikōura Earthquake", in V2.0 Landslide inventory for the Mw7.8 14 November 2016, Kaikōura Earthquake, New Zealand. DesignSafe-CI. [https://doi.org/10.17603/ds2-1ftv-hm22](https://doi.org/10.17603/ds2-1ftv-hm22)
 
-There are different ways to upload data to My Project:
 
-* Do not upload folders and files with special characters in their filenames. In general, keep filenames meaningful but short and without spacing. See file naming convention recommendations in the <a href="#organization">Data Organization and Description</a>
-* Select the Add button, then File upload to begin uploading data from your local machine. You can browse and select files or drag and drop files into the window that appears.  
-* Connect to your favorite cloud storage provider. <a href="/user-guide/managingdata/datatransfer/#cloud">We currently support integration with Box,  Dropbox, and Google Drive.</a> 
-* You can also copy data to and from My Data.  
-* You may consider zipping files for purpses of uploading: however, you should unzip them for curation and publication purposes.  
-* For uploads of files bigger than 2 Gigabytes and or more than 25 files, consider using Globus, CyberDuck and  Command Line Utilities. Explanations on how to use those applications are available in our <a href="/user-guide/managingdata/datatransfer/">Data Transfer Guide.</a>
 
-Downloading several individual files via our web interface could be cumbersome, so DesignSafe offers a number of alternatives. First, users may interact with data in the Workspace using any of the available tools and applications without the need to download; for this, users will need a DesignSafe account. Users needing to download a large number of files from a project may also use <a href="/user-guide/managingdata/datatransfer/#globus">Globus</a>. When feasible, to facilitate data download from their projects users may consider aggregating data into larger files.
+## Curating Various Types of Research Data
 
-Be aware that while you may store all of a project files in My Project, you may not need to publish all of them. During curation and publication you will have the option to select a subset of the uploaded files that you wish to publish without the need to delete them.
+### Proprietary Formats
 
-More information about the different Workspaces in DesignSafe and how to manage data from one to the other can be found <a href="/user-guide/managingdata/datatransfer/">here</a>.
+Many instruments used in natural hazards research involve proprietary file formats. Many of those files can be converted to open formats within their corresponding software prior to uploading to DDR.  In turn, Excel and Matlab are proprietary file formats that are frequently used in this community for analysis purposes. Instead of Excel spreadsheet files, it is best to publish data in CSV format so it can be used by different software. However, in some cases conversion may distort the data structures and thus the files cannot be converted. Always retain an original copy of any structured data before attempting conversions, and check between the two for fidelity. Additionally, it is possible to upload and publish both the proprietary and the converted version in the DDR, especially if you consider that publishing with a proprietary format is convenient for data reuse.
 
-#### Selecting a Project Type { #selectingprojecttype }
+When publishing proprietary files that are ubiquitous in the field, please refer to the following Data Curation Primers. 
 
-Depending on the research method pursued, users may curate and publish data as "Experimental", "Simulation", "Hybrid Simulation," or "Field Research" project type. The Field Research project type accommodates "Interdisciplinary Datasets" involving engineering and/or social science collections.
+* [Matlab](https://deepblue.lib.umich.edu/handle/2027.42/154686)
+* [Excel](https://github.com/DataCurationNetwork/data-primers/blob/main/Excel%20Data%20Curation%20Primer/Excel%20Data%20Curation%20Primer.md)
 
-Based on <a href="#policies">data models</a> designed by experts in the field, the different project types provide interactive tools and metadata forms to curate the dataset so it is complete and understandable for others to reuse. So for example,users that want to publish a simulation dataset will have to include files and information about the model or software used, the input and the output files, and add a readme file or a data report.
+### Compressed Data
 
-Users should select the project type that best fits their research method and dataset.  If the data does not fit any of the above project types, they can select project type" Other." In project type "Other" users can curate and publish standalone reports, learning materials, white papers, conference proceedings, tools, scripts, or data that does not fit with the research models mentioned above.
+Users that upload data as a zip file should unzip before curating and publishing, as zip files prevent others from directly viewing and making sense of the published data and the repository. If uploading compressed files to My Data, it is possible to unzip it using the extraction [utility](https://www.designsafe-ci.org/rw/workspace/#!/extract-0.1u1) available in the workspace before copying data to My Project for curation and publication.
 
-#### Working in My Project { #working }
+### Simulation Data
 
-Once the project type is selected, the interactive interface in My Project will guide users through the curation and publication steps through detailed onboarding instructions.
+When curating and publishing simulation datasets researchers should follow this [best practices document](https://doi.org/10.17603/ds2-wsqp-fw44). The document addresses the needs and recommendations of the numerical modeling community, and is informed by the experience of engineers that  conduct simulations. These best practices focus on attaining published datasets with precise descriptions of the simulation' design, access to the software used, and when possible, the complete publication of inputs and all outputs. Tying these pieces together requires documentation to understand the research motivation, origin, processing, and functions of the simulation dataset in line with FAIR principles. 
 
-My Project is a space where users can work during the process of curation and publication and after publication to publish new data products or to analyze their data.
+### Geospatial Data
 
-Because My Project is a shared space, it is recommended that teams select a data manager to coordinate file organization, transfers, curation, naming, etc.
+We encourage the use of [recommended Geospatial data formats](https://www.loc.gov/preservation/resources/rfs/geo-carto.html). Within the Data Depot [Tools and Applications](https://www.designsafe-ci.org/use-designsafe/tools-applications/) we provide open source software for users to share and analyze geospatial data. [QGIS](https://www.designsafe-ci.org/use-designsafe/tools-applications/gis-tools/qgis/) accommodates most open format datasets, and [HazMapper](https://www.designsafe-ci.org/use-designsafe/tools-applications/gis-tools/hazmapper/) is capable of visualizing geo-tagged photos and GeoJSON files. To access this software, users should create an account in DesignSafe.
 
-After data is published users can still work on My Project for progressive publishing of new experiments, missions or simulations within the project, to version and/or to edit or amend the existing publication. See amends and versions in this document.
+Understanding that ArcGIS software is widespread in this community, it is possible to upload both proprietary and recommended geospatial data formats in the DDR. When publishing feature and raster files, it is important to make sure that all the relevant files for reuse–such as the projection and header files are included in the publication. For example, for shapefiles it is important to publish all .shp (the file that contains the geometry for all features), .shx (the file that indexes the geometry) and .dbf (the file that stores feature attributes in a tabular format) files.
 
-#### General Research Data Best Practices { #bestpractices }
+### Point Cloud Data
 
-Below we include general research data best practices but we strongly recommend to review the available <a href="https://datacurationnetwork.org/outputs/data-curation-primers/">Data Curation Primers</a> for more specific directions on how to document and organize specific research data types.
+It is recommended to avoid publishing proprietary point cloud data extensions. Instead, users should consider publishing post-processed and open format data such as las or laz files. In addition, point cloud data publications may be very large and therefore of difficult access if not displayed on a map. In [Tools and Applications](https://www.designsafe-ci.org/use-designsafe/tools-applications/), we have Potree available for users to view point cloud datasets. Through the Potree Convertor application, non-proprietary point cloud files can be converted to a Potree readable format for visualization in DesignSafe.
 
-##### Proprietary Formats { #bestpractices-formats }
+### Jupyter Notebooks
 
-Excel and Matlab are two proprietary file formats highly used in this community. Instead of Excel spreadsheet files, it is best to publish data as simple csv so it can be used by different software. However,  we understand that in some cases (e.g. Matlab, Excel) conversion may distort the data structures. Always retain an original copy of any structured data before attempting conversions, and then check between the two for fidelity. In addition, in the DDR it is possible to upload and publish both the proprietary and the converted version, especially if you consider that publishing with a proprietary format is convenient for data reuse.
+As you plan for publishing a Jupyter Notebook, please consider the following issues:
 
-##### Compressed Data { #bestpractices-compresseddata }
+1. The DesignSafe publication process involves copying the contents of your project at the time of publication to a read only space within the Published projects section of the Data Depot (i.e., this directory can be accessed at NHERI-Published in JupyterHub). Any future user of your notebook will access it in the read-only Published projects section. Therefore, any local path you are using while developing your notebook that is accessing a file from a private space (e.g., "MyData", "MyProjects") will need to be replaced by an absolute path to the published project. Consider this example: you are developing a notebook in PRJ-0000 located in your "MyProjects" directory and you are reading a csv file living in this project at this path: `/home/jupyter/MyProjects/PRJ-0000/Foo.csv`. Before publishing the notebook, you need to change the path to this csv file to `/home/jupyter/NHERI-Published/PRJ-0000/Foo.csv`.
+2. The published area is a read-only space. In the published section, users can run notebooks, but the notebook is not allowed to write any file to this location. If the notebook needs to write a file, the author of the notebook must make sure that it can write to a file in each user directory ([example of a published notebook that writes files to user directories](https://doi.org/10.17603/ds2-v310-qc53)). Since the published space is read-only, if a user wants to revise, enhance or edit the published notebook they will have to copy the notebook to their My data and continue working on the copied version of the notebook located in their My data. A readme file must be published within the project that explains how future users can run and take advantage of the Jupyter Notebook.
+3. Jupyter Notebooks rely on packages that are used to develop them (e.g., numpy, geopandas, ipywidgets, CartoPy, Scikit-Learn). For preservation purposes, it is important to publish a requirements file including a list of all packages and their versions along with the notebook as a metadata file.
 
-Users that upload data as a zip file should unzip before curating and publishing, as zip files prevent others from directly viewing and understanding the published data. If uploading compressed files to "My Data" , it is possible to unzip it using [the extraction utility available in the workspace](https://www.designsafe-ci.org/workspace/extract){target=_blank} before copying data to My Project for curation and publication.
+## Organizing and Naming Files
 
-##### Simulation Data { #bestpractices-simulationdata }
+The DDR data models  provide categories for users to organize their data in a standardized way. Categories highlight the main components of the dataset in relation to the research method used. Each category has a form that must be filled with metadata to describe and represent its characteristics, and there are onboarding instructions on what kind of information is suitable for each metadata field. Once you have categorized the files do not make changes to categorized files through an SSH connection or through Globus. If you need to, please remove the category, deselect the files, and start over.
 
-In the Data Depot's Published directory there is a [best practices document](https://doi.org/10.17603/ds2-wsqp-fw44){:target="_blank"} for publishing simulation datasets in DesignSafe. The topics addressed reflect the numerical modeling community needs and recommendations, and are informed by the experience of the working group members and the larger DesignSafe expert cohort while conducting and curating simulations in the context of natural hazards research. These best practices focus on attaining published datasets with precise descriptions of the simulations’ designs, references to or access to the software involved, and complete publication of inputs and if possible all outputs. Tying these pieces together requires documentation to understand the research motivation, origin, processing, and functions of the simulation dataset in line with FAIR principles. These best practices can also be used by simulation researchers in any domain to curate and publish simulation data in any repository.
+Under each category, corresponding files are represented as a list to facilitate accessibility of the dataset. However, curation of large datasets may require further organization of files into folders, which can be done prior to uploading the data or in My Project. In doing so it is best to avoid extensively nested folders, as browsing through folder hierarchies on the web slows the computer and confuses the user as to the location of the files. 
 
-##### Geospatial Data { #bestpractices-geospatial }
+To avoid excessive nesting and improve navigation, users can come up with a file naming convention schema, ideally during the research planning phase and prior to gathering the data. Well-constructed folder and file names make it possible to identify files by succinctly expressing their content and their relations to other files, considering the key information they want to convey to others.
 
-We encourage the use of open Geospatial data formats. Within DS Tools and Applications we provide two open source software for users to share and analyze geospatial data. QGIS can handle most open format datasets and HazMapper, is capable of visualizing geo-tagged photos and GeoJSON files. To access these software users should  get an account in DesignSafe.
+/// details | Naming Convention **Ideas**
+    type: tip
 
-Understanding that ArcGIS software is widespread in this community  in the DDR it is possible to upload both proprietary and recommended geospatial data formats. When publishing feature and raster files it is important to make sure that all of the relevant files for reuse such as the projection file and header file are included in the publication for future re-use. For example, for shapefiles it is important to publish all .shp (the file that contains the geometry for all features), .shx (the file that indexes the geometry) and .dbf (the file that stores feature attributes in a tabular format) files.
+* Project acronym, is good for branding the data
+* Location/spatial coordinates
+* Type of data
+* Type of structure tested
+* Simulation or experiment type
+* Test/run number and parameters/conditions
+* Natural hazard
+* Damage type
+* Version number of file
 
-##### Point Cloud Data { #bestpractices-pointcloud }
+///
+/// details | Naming Convention **Recommendations**
+    type: tip
 
-It is highly recommended to avoid publishing proprietary point cloud data extensions.  Instead, users should consider publishing post-processed and open format extension data such as las or laz files. In addition, point cloud data publications may be very large. In DS, we have Potree available for users to view point cloud datasets. Through the Potree Convertor application, non-proprietary point cloud files can be converted to a potree readable format to be visualized in DesignSafe.
+* File naming should be meaningful, both to the team and to others, and should be kept short. 
+* Consider the folder name as complementary to the file naming convention
+* File names should not have spaces, periods, accents, or special characters, as those features may cause errors within the storage systems.
+* Always leave the three letter file extension. 
+* The meaning and components of file naming conventions should be documented in the Data Report so that others can identify files. 
+* Do not repeat filenames or folder names across different experiments, collections and missions, or simulations, as this is confusing for other users. Always include another piece of information to distinguish files and folders across groupings. 
 
-##### Jupyter Notebooks { #jupyter }
+///
 
-More and more researchers are publishing projects that contain Jupyter Notebooks as part of their data. They can be used to provide sample queries on the published data as well as providing digital data reports.  As you plan for publishing a Jupyter Notebook, please consider the following issues:
+## Recommended File Formats
 
-1. The DesignSafe publication process involves copying the contents of your project at the time of publication to a read only space within the Published projects section of the Data Depot (i.e., this directory can be accessed at NHERI-Published in JupyterHub). Any future user of your notebook will access it in the read only Published projects section. Therefore, any local path you are using while developing your notebook that is accessing a file from a private space (e.g., "MyData", "MyProjects") will need to be replaced by an absolute path to the published project. Consider this example: you are developing a notebook in PRJ-0000 located in your "MyProjects" directory and you are reading a csv file living in this project at this path: `/home/jupyter/MyProjects/PRJ-0000/Foo.csv`. Before publishing the notebook, you need to change the path to this csv file to `/home/jupyter/NHERI-Published/PRJ-0000/Foo.csv`.
-1. The published area is a read-only space. In the published section, users can run notebooks, but the notebook is not allowed to write any file to this location. If the notebook needs to write a file, you as the author of the notebook should make sure the notebook is robust to write the file in each user directory. <a href="https://doi.org/10.17603/ds2-v310-qc53">Here</a> is an example of a published notebook that writes files to user directories. Furthermore, since the published space is read-only, if a user wants to revise, enhance or edit the published notebook they will have to copy the notebook to their mydata and continue working on the copied version of the notebook located in their mydata. To ensure that users understand these limitations, we require a readme file be published within the project that explains how future users can run and take advantage of the Jupyter Notebook.
-1. Jupyter Notebooks rely on packages that are used to develop them (e.g., numpy, geopandas, ipywidgets, CartoPy, Scikit-Learn). For preservation purposes, it is important to publish a requirement file including a list of all packages and their versions along with the notebook as a metadata file.
+For long-term preservation and interoperability purposes, we recommend and promote storing and publishing data in open formats. Below is an adaptation of the list of recommended formats for data and documentation by [Stanford Libraries.](https://guides.library.stanford.edu/data-best-practices/format-files) For those available, we include a link to the  [Data Curation Primers](https://datacurationnetwork.org/outputs/data-curation-primers/) which are peer-reviewed documents that can be used as guidelines to curate research data:
 
-#### Data Organization and Description { #organization }
-
-In My Projects, users may upload files and or create folders to keep their files organized; the latter is common when projects have numerous files. However, browsing through an extensive folder hierarchy on the web may be slower on your local computer, so users should try to use the smallest number of nested folders necessary and if possible, none at all, to improve all users’ experience.
+* [Databases](https://github.com/DataCurationNetwork/data-primers/blob/master/Databases%20Data%20Curation%20Primer/databases-data-curation-primer.md): XML, CSV
+* [Geospatial](https://github.com/DataCurationNetwork/data-primers/blob/master/Geodatabase%20Data%20Curation%20Primer/Geodata-Primer.md): SHP, DBF, [GeoTIFF](https://github.com/DataCurationNetwork/data-primers/blob/master/GeoTIFF%20Data%20Curation%20Primer/geotiff-data-curation-primer.md), [netCDF](https://deepblue.lib.umich.edu/handle/2027.42/145724), [GeoJSON](https://github.com/DataCurationNetwork/data-primers/blob/master/GeoJSON%20Data%20Curation%20Primer/GeoJSON-data-curation-primer.md)
+* PointCloud: LAS, LAZ, XYZ, PTX
+* Moving images: MOV, MPEG, AVI, MXF
+* Sounds: WAVE, AIFF, MP3, MXF
+* Statistics: ASCII, DTA, [POR](https://github.com/DataCurationNetwork/data-primers/blob/master/SPSS%20Data%20Curation%20Primer/SPSS-data-curation-primer.md#Format-Overview), [SAS](https://github.com/DataCurationNetwork/data-primers/blob/master/SAS%20Data%20Curation%20Primer/SAS-data-curation-primer.md), [SAV](https://github.com/DataCurationNetwork/data-primers/blob/master/SPSS%20Data%20Curation%20Primer/SPSS-data-curation-primer.md#Format-Overview)
+* Still images: TIFF, JPEG 2000, [PDF,](https://github.com/DataCurationNetwork/data-primers/blob/master/PDF%20Data%20Curation%20Primer/PDF-data-curation-primer.md) PNG, GIF, BMP
+* [Tabular data](https://github.com/DataCurationNetwork/data-primers/blob/master/Tableau%20Data%20Curation%20Primer/Tableau-data-curation-primer.md): CSV
+* Text: XML, [PDF/A](https://github.com/DataCurationNetwork/data-primers/blob/master/PDF%20Data%20Curation%20Primer/PDF-data-curation-primer.md), HTML, ASCII, UTF-8 ,
+* CODE: (tcl files, py files) [Jupyter Notebook](https://github.com/DataCurationNetwork/data-primers/blob/master/Jupyter%20Notebook%20Data%20Curation%20Primer/Jupyter%20Notebooks%20Data%20Curation%20Primer.md)
+* Seismology: SEED
 
-Except for project type "Other" which does not have categories, users will categorize their files or folders according to the corresponding project type. Categories describe and highlight the main components of the dataset in relation to the research method used to obtain it. Each category has a form that needs to be filled with metadata to explain the methods and characteristics of the dataset, and there are onboarding instructions on what kind of information is suitable for each metadata field. In turn, some of these fields are required, which means that they are fundamental for the clarity of the project's description. The best way to approach data curation in My Project, is to organize the files in relation to the data model of choice and have the files already organized and complete before categorizing and tagging. While curating data in My Project, do not move, rename or modify files that have been already categorized. In particular, do not make changes to categorized files through an SSH connection or through Globus. If you need to, please remove the category, deselect the files, and start all over.
+## Tagging
 
-Within the different project types, there are different layers for describing a dataset. At the project level, it is desirable to provide an overview of the research, including its general goal and outcomes, what is the audience, and how the data can be reused. For large projects we encourage users to provide an outline of the scope and contents of the data. At the categories level, the descriptions need to address technical and methodological aspects involved in obtaining the data.
+Users can tag folders and  files for ease of data comprehension and reuse by others. While tagging is not required,  we recommend it because it helps others to identify file contents in the dataset landing page. The list of tags available are agreed upon terms contributed by experts in the field. If the tags available do not apply, feel free to add custom tags, and you may also submit tickets informing the curation team about the need to incorporate them in the list.  Using tags to clarify the file function is also a way of avoiding excessive folder nesting.
 
-In addition, users can tag individual files or groups of files for ease of data comprehension and reuse by others. While categories are required, tagging is not, though we recommend that users tag their files because it helps other users to efficiently identify file contents in the publication interface. For each project type the list of tags are agreed upon terms contributed by experts in the field of NH. If the tags available do not apply, feel free to add custom tags and submit tickets informing the curation team about the need to incorporate them in the list. We heard from our users that the list of tags per category reaffirms them of the need to include certain types of documentation to their publication.
 
-To enhance organization and description of projects type "Other," users can group files in folders when needed and use file tags. However, it is always best to avoid overly nesting and instead use the file tags and descriptions to indicate what are the groupings.
 
-File naming conventions are often an important part of the work of organizing and running large scale experimental and simulation data. File names make it possible to identify files by succintly expressing their content and their relations to other files. File naming conventions should be established during the research planning phase, they should be meaningful -to the team and to others- and they should be kept short. When establishing a file naming convention, researchers should think about the key information elements they want to convey for others to identify tiles and group of files. The meaning and components of file naming conventions should be documented in a Data Report or readme file so that others can understand and identify files as well. Users should consider that in DesignSafe you will be able to describe files with tags and descriptions when you curate them. File naming conventions should not have spaces or special characters, as those features may cause errors within the storage systems. See this Stanford University Libraries best practices<a href="https://guides.library.stanford.edu/data-best-practices"> for file naming convention. </a>
+## Writing Helpful Titles, Keywords, and Descriptions
 
-The following are good examples of data organization and description of different project types:
+Well-written titles, keywords, and descriptions are key for understanding, discovery, and marketing of your research. Here are some tips to craft ones:
 
-* Experimental
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3197">Progressive Damage and Failure of Wood-Frame Coastal Residential Structures Due to Hurricane Surge and Wave Forces.</a>
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2141">CFS-NHERI: Seismic Resiliency of Repetitively Framed Mid-rise cold-Formed Steel Buildings.</a>
+### Project Level Titles
 
-* Simulation
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2972">Modeling and Analysis of Steel Frame Building Systems</a>
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2968">Texas FEMA Hurricane Winds and Surge</a>
+Except for the data type "Other," the Data Depot Repository (DDR) requires titles at both the project level and the dataset level (mission, experiment, simulation, hybrid simulation). The dataset level title serves as the primary citation title, while the project title functions as a complementary secondary title. The citation format is shown below:
 
-* Hybrid Simulation
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-1634">Aeroelastic Real-Time Hybrid Simulation - A New Concept for Wind Engineering Testing </a>
+Author/s (year of publication). "Dataset Title", in Project title 
 
-* Field Research
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3333">Expert Survey on Community Resilience Testbed Use and Development (Social Science)</a>
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2440">Ridgecrest, CA Earthquake Sequence, July 4 and 5, 2019.</a> (Engineering)
+Example Citation:
 
-* Interdisciplinary Field Research
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2656">A Longitudinal Community Resilience Focused Technical Investigation of the Lumberton, North Carolina Flood of 2016 (in progress).</a>
+Stark, N., M. Gardner, M. Grilliot, A. Lyda, K. Dedinsky, J. Mueller, C. Pezoldt, J. Hubler, C. Castro-Bolinaga, A. Schueller, W. Zhan, M. Haefeli, S. Burghardt, M. Wondolowski, S. Holberg, M. Hassan, J. Parker, J. Laurel-Castillo, L. Eggensberger, E. Nichols, H. Herndon, P. Wang, M. Olabarrieta Lizaso, B. Raubenheimer, Y. Hashash, S. ADUSEI, N. Jafari (2025). "NEER/GEER: Hurricanes Helene & Milton Dataset", in Multidisciplinary Pre, During and Post Storm Data Collection. DesignSafe-CI. [https://doi.org/10.17603/ds2-m8h3-5802](https://doi.org/10.17603/ds2-m8h3-5802)
 
-* Other
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3285">Contribution to Cold Formed Steel Seismic Design within CFS-NHERI Project.</a>
-	* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2289">Global Academic Hazards and Disaster research Centers Data</a>
+### Project Level Titles
 
-#### Project Documentation { #documentation }
+* Remember that this is the sub-title of the dataset citation.
+* Keep titles short, between 50 and 60 characters long.
+* Use descriptive words that point to the key themes and characteristics of the research project.
+* Do not repeat the title of the dataset.
+* Do not repeat the title of a paper, which could create confusion.
+* Avoid using or spelling out acronyms. 
 
-NH datasets can be very large and complex, so we require that users submit a data report or a readme file to publish along with their data to express information that will facilitate understanding and reuse of your project. This documentation may include the structure of the data, a data dictionary, information of where everything is, explanation of the file naming convention used, and the methodology used to check the quality of the data. The data report in this <a href="https://doi.org/10.17603/ds2-5aej-e227">published dataset</a> is an excellent example of documentation.
+### Dataset Level Titles
 
-To provide connections to different types of information about the published dataset, users can use the Related Work field. We provide different types of tags that explain their relation to the dataset. To connect to information resources that provide contextual information about the dataset (events or organizations) use the tag "context". To link to other published datasets in the DDR use the tag "link Dataset", and to connect to published papers that cite the dataset use the tag "is cited by". Importantly, users should add the DOI of these different information types in http format (if there is no DOI add a URL). The latter information is sent to DataCite, enabling exchange of citation counts within the broader research ecosystem through permanent identifiers. Related Works can be added after the dataset was published using the amends pipeline. This is useful when a paper citing the dataset is published after the publication of the dataset.
+* Remember that this is the title that will be featured in the citation. 
+* Keep titles short,  between 50 and 60 characters long.
+* Use descriptive words that point to the key themes and characteristics of the dataset.
+* Do not repeat the title of the research project, or use “Dataset for:…(title of research project)
+* Do not repeat the title of a paper to avoid duplication of DOIs or use "Replication Dataset for:...(title of the paper). 
+* Avoid using or spelling out acronyms. 
 
-When applicable, we ask users to include information about their research funding in the Awards Info fields.
+### Keywords
 
-#### Data Quality Control { #quality }
+* Remember that other researchers use keywords to find datasets in the Data Depot or online. 
+* When applying keywords, researchers must think about how others would search for this particular dataset.
+* When applicable, use keywords to indicate the type of hazard, research method, technology, problem addressed, and purpose. 
+* Repeating words used in the description and titles as keywords increases the chances that the dataset will be discovered. 
 
-Each data publication is unique; it reflects and provides evidence of the research work of individuals and teams. Due to the specificity,  complexity, and scope of the research involved in each publication, the DDR cannot complete quality checks of the contents of the data published by users. It is the user's responsibility to publish data that is up to the best standards of their profession, and our commitment is to help them achieve these standards. In the DDR, data and metadata quality policies as well as the curation and publication interactive functions are geared towards ensuring excellence in data publications. In addition, below we include general data content quality recommendations:
+Consult the CONVERGE [check sheet](https://nam12.safelinks.protection.outlook.com/?url=https%3A%2F%2Fdoi.org%2F10.17603%2Fds2-swvc-sb26&data=05%7C02%7C%7C1b416aed89164d4c732208dd15356da6%7C31d7e2a5bdd8414e9e97bea998ebdfe1%7C0%7C0%7C638690041410632335%7CUnknown%7CTWFpbGZsb3d8eyJFbXB0eU1hcGkiOnRydWUsIlYiOiIwLjAuMDAwMCIsIlAiOiJXaW4zMiIsIkFOIjoiTWFpbCIsIldUIjoyfQ%3D%3D%7C0%7C%7C%7C&sdata=mfzeZFnF2WjcJA9ePOq6h%2BqjYSZAeSS1H77VDO7g4bk%3D&reserved=0) for guidance in choosing helpful keywords. 
 
-Before publishing, use applicable methods to review the data for errors (calibration, correction, validation, normalization, completeness checks) and document the process so that other reusers are aware of the quality control methods employed. Include the explanation about the quality control methods you used in the data report or readme file.
+### Descriptions
 
-Include a data dictionary or a readme file to explain the meaning of data fields.
+Except for Data type "Other", DesignSafe requires descriptions at the project level and at the dataset level (mission, experiment, simulation, hybrid simulation). Both descriptions are complementary. The project level description addresses the high level objectives of the research, who participates, why the research is unique, how many datasets will be published and who will benefit from it. The dataset level description focuses on the scope and content of the dataset and how it was obtained. Below are general recommendations that apply to both descriptions.  
 
-Researchers in NH generate enormous amounts of images. While we are not posing restrictions on the amount of files, in order to be effective in communicating their research users being selective with the images chosen to publish is key.  For example, making sure they have a purpose, are illustrative of a process or a function, and using file tags to describe them. The same concept can be applied for other data formats.
+\* Minimum 200 words, max 300 for each level
 
-It is possible to publish raw and curated data. Raw data is that which comes directly from the recording instruments (camera, apps, sensors, scanners, etc). When raw data is corrected, calibrated, reviewed, edited or post-processed in any way for publication, it is considered curated. Some researchers want to publish their raw data as well as their curated data. For users who seek to publish both, consider why it is necessary to publish both sets and how another researcher would use them. Always clarify whether your data is raw or curated in the description or in a data report/readme file including the method used to post-process it.
+### Project Level Descriptions
 
-#### Managing Protected Data in the DDR { #protectedddr }
+* Begin with a general statement that provides context to the study by which the dataset was created (e.g., The system under investigation…). 
+* Mention the type(s) of hazard being studied (wind, earthquake, wildfire,  multi-hazard, etc.). 
+* Address the research problem that the data is helping to solve.
+* Do not copy the abstract of the paper, as that describes the research results and not the dataset itself.
+* Address who will benefit from reusing the data and how (reproducibility, generating new studies, validation, Machine Learning, etc.)?
+* Use language that can reach experts as well as broader audiences.
+* Use words that you think will help or are used by others to find datasets like yours online. Repeat these words across the title, descriptions, and keywords to increase online discoverability.
+* Avoid using acronyms if possible. Spell out the full acronym if you must.
 
-Users that plan to work with human subjects should have their IRB approval in place prior to storing, curating, and publishing data in the DDR. We recommend following the recommendations included in the CONVERGE series of<a href="https://converge.colorado.edu/resources/check-sheets/ethical-considerations/"> check sheets</a> that outline how researchers should manage/approach the lifecycle data that contain personal and sensitive information; these check sheets have also been published in the<a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2946"> DDR</a>.
+### Dataset Level Descriptions
 
-At the moment of selecting a Field Research project, users are prompted to respond if they will be working with human subjects. If the answer is yes, the DDR curator is automatically notified and gets in touch with the project team to discuss the nature and conditions of the data and the IRB commitments.
+* Datasets should be described as a standalone research output, so they can be understood independently from related research products such as a published paper or research code.Focus on describing the dataset. You may begin the text with "This dataset…"
+* Provide an overview of the methodology by which the dataset was obtained.
+* Provide a very brief overview of the scope and contents of the dataset and how it is organized. 
+* Indicate if the data was quality controlled - you may go into more detail in the Data Report. 
+* Keep descriptions concise and engaging, further details about the dataset should be introduced in a Data Report.
+* Use language that can reach experts as well as layperson audiences.
+* Use words that you consider will help or are used by others to find datasets like yours online. 
+* Repeat these words across the title, description, and keywords to increase online discoverability.
+* Avoid using acronyms if possible. Spell out the full acronym if you must.
+## Reusing and Citing Resources in the Datasets Landing Pages
 
-DesignSafe My Data and My Projects are secure spaces to store raw protected data as long as it is not under HIPAA, FERPA or FISMA regulations. If data needs to comply with these regulations, researchers must contact DDR through a <a href="http://www.designsafe-ci.org/help/new-ticket">help ticket</a> to evaluate the need to use <a href="https://www.tacc.utexas.edu/protected-data-service">TACC‘s Protected Data Service</a>. Researchers with doubts are welcome to send a <a href="http://www.designsafe-ci.org/help/new-ticket">ticket</a> or join <a href="https://www.designsafe-ci.org/learning-center/training/">curation office hours</a>.
+### Reusing Data and Software
 
-Projects that do not include the study of human subjects and are not under IRB purview may still contain items with Personally Identifiable Information (PII). For example, researchers conducting field observations may capture human subjects in their documentation including work crews, passersby, or people affected by the disaster. If camera instruments capture people that are in the observed areas incidentally, we recommend that their faces and any <a href="https://www.technology.pitt.edu/help-desk/how-to-documents/guide-identifying-personally-identifiable-information-pii">Personally Identifiable Information</a> should be anonymized/blurred before publishing. In the case of images of team members, make sure they are comfortable with making their images public. Do not include roofing/remodeling records containing any form of PII. When those are public records, researchers should point to the site from which they are obtained using the Referenced Data and or Related Work fields. In short, users should follow all other protected data policies and best practices outlined further in this document.
+In their projects, researchers frequently reuse data as input files, for validation, or to integrate with the data that they collect. They also reuse open software and may modify it for their purposes. To make sure that data and software can be reused, modified, and shared appropriately, researchers should always look into and proceed according to what is stated in the resource license. Licenses are standard ways for content creators to grant permissions to others to reuse their work under certain conditions. The license will, for example, indicate if the creators want to be attributed with a citation. In that regard, it is a good practice to always provide the citation of the software and data that was reused, even if the author does not require it. This is because authorship is part of the resource's provenance and to give credit to the creators.
 
-#### Metadata Requirements { #metadatareqs }
+### Citing Papers and Reused Data and Software
 
-Metadata is information that describes the data in the form of schemas. Metadata schemas provide a structured way for users to share information about data with other platforms and individuals. Because there is no standard schema to describe natural hazards engineering research data, the DDR developed data models containing elements and controlled terms for categorizing and describing NH data. The terms have been identified by experts in the NH community and are continuously expanded, updated, and corrected as we gather feedback and observe how researchers use them in their publications.
+DDR offers possibilities to cite different types of resources that provide context, cite, or were used to create a new data publication.  Located in the curation forms, those are:
 
-So that DDR metadata can be exchanged in a standard way, we map the fields and terms to widely-used, standardized schemas. The schemas are: <a href="https://www.dublincore.org/specifications/dublin-core/dcmi-terms/">Dublin Core</a> for description of the research data project, <a href="https://ddialliance.org/products/overview-of-current-products">DDI (Data Documentation Initiative)</a> for social science data, and <a href="https://datacite.org/dois.html">DataCite</a> for DOI assignment and citation. We use the <a href="https://www.w3.org/2001/sw/wiki/PROV">PROV</a> schema to connect the different components of multi-part data publications.
+- **Related Work**: to cite data, papers, websites, reports or presentations that provide context, have a direct relationship to, or cite the published dataset. Those resources could be external to DDR or published in DDR. The type of connection between the resource and the published dataset has to be selected by the user as: context (informs the published dataset), link (points to a resource that is complementary to, derives from, or is derived from the published dataset) and is cited by (the work references the published dataset) 
+- **Referenced Data and Software**: to cite data or software that have been reused to create the published dataset.
 
-Due to variations in research methods, users may not need to use all the metadata elements available to describe their data. However, for each project type we identified a required set that represents the structure of the data, are useful for discovery, and will allow proper citation of data. To ensure the quality of the publications, the system automatically checks for completeness of these core elements and whether data files are associated with them. If those elements and data are not present, the publication does not go through. For each project type, the metadata elements including those that are required and recommended are shown below.
+Note that:
 
-<table border="1" width="100%">
-<tr valign="top">
-<td><b>Experimental Research Project</b><br>
-<a href="#experimental_1">View Metadata Dictionary</a></b>
-
-<ul>
-	<li>DOI<sup>†</sup></li>
-	<li>Project Title</li>
-	<li>Author (PIs/Team Members)&#42;</li>
-	<li>Participant Institution&#42;</li>
-	<li>Project Type&#42;</li>
-	<li>Description</li>
-	<li>Publisher<sup>†</sup></li>
-	<li>Date of Publication<sup>†</sup></li>
-	<li>Licenses</li>
-	<li>Related Works&#42;<sup>$</sup></li>
-	<li>Award&#42;</li>
-	<li>Keywords</li>
-	<li>Experiment&#42;
-	<ul>
-		<li>Report</li>
-		<li>DOI<sup>†</sup></li>
-		<li>Experiment Title</li>
-		<li>Author (PIs/Team Members)&#42;</li>
-		<li>Experiment Description</li>
-		<li>Date of Publication<sup>†</sup></li>
-		<li>Dates of Experiment</li>
-		<li>Experimental Facility</li>
-		<li>Experiment Type</li>
-		<li>Equipment Type&#42;</li>
-		<li>Model Configuration&#42;</li>
-		<li>Sensor Information&#42;</li>
-		<li>Event&#42;</li>
-		<li>Experiment Report<sup>$</sup></li>
-	</ul>
-	</li>
-	<li>Analysis&#42;<sup>$</sup>
-	<ul>
-		<li>Analysis Title</li>
-		<li>Description</li>
-		<li>Referenced Data&#42;</li>
-	</ul>
-	</li>
-</ul>
-
-	
-</td>
-<td><b>Simulation Research Project</b><br>
-<a href="#simulation_1">View Metadata Dictionary</a></b>
-
-<ul>
-	<li>DOI<sup>†</sup></li>
-	<li>Project Title</li>
-	<li>Author (PIs/Team Members)&#42;</li>
-	<li>Participant Institution&#42;</li>
-	<li>Project Type&#42;</li>
-	<li>Description</li>
-	<li>Publisher<sup>†</sup></li>
-	<li>Date of Publication<sup>†</sup></li>
-	<li>Licenses</li>
-	<li>Related Works&#42;<sup>$</sup></li>
-	<li>Award&#42;</li>
-	<li>Keywords</li>
-	<li>Simulation&#42;
-	<ul>
-		<li>Report</li>
-		<li>Simulation Title</li>
-		<li>Author (PIs/Team Members)&#42;</li>
-		<li>Description</li>
-		<li>Simulation Type</li>
-		<li>Simulation Model</li>
-		<li>Simulation Input&#42;</li>
-		<li>Simulation Output&#42;</li>
-		<li>Referenced Data&#42;</li>
-		<li>Simulation Report<sup>$</sup></li>
-	</ul>
-	</li>
-	<li>Analysis&#42;<sup>$</sup>
-	<ul>
-		<li>Analysis Title</li>
-		<li>Description</li>
-		<li>Referenced Data&#42;</li>
-	</ul>
-	</li>
-</ul>
-
-</td></tr>
-
-<tr valign="top">
-
-<td><b>Hybrid Simulation Research Project</b><br>
-<a href="#hybrid_1">View Metadata Dictionary</a></b>
-
-<ul>
-	<li>DOI<sup>†</sup></li>
-	<li>Project Title</li>
-	<li>Author (PIs/Team Members)&#42;</li>
-	<li>Participant Institution&#42;</li>
-	<li>Project Type&#42;</li>
-	<li>Description</li>
-	<li>Publisher<sup>†</sup></li>
-	<li>Date of Publication<sup>†</sup></li>
-	<li>Licenses</li>
-	<li>Related Works&#42;<sup>$</sup></li>
-	<li>Award&#42;</li>
-	<li>Keywords</li>
-	<li>Hybrid Simulation&#42;
-	<ul>
-		<li>Report</li>
-		<li>Global Model
-		<ul>
-			<li>Global Model Title</li>
-			<li>Description</li>
-		</ul>
-		</li>
-		<li>Master Simulation Coordinator
-		<ul>
-			<li>Master Simulation Coordinator Title</li>
-			<li>Application and Version</li>
-			<li>Substructure Middleware</li>
-		</ul>
-		</li>
-		<li>Simulation Substructure&#42;
-		<ul>
-			<li>Simulation Substructure Title</li>
-			<li>Application and Version</li>
-			<li>Description</li>
-		</ul>
-		</li>
-		<li>Experiment Substructure&#42;
-		<ul>
-			<li>Experiment Substructure Title</li>
-			<li>Description</li>
-		</ul>
-		</li>
-	</ul>
-	</li>
-</ul>
-
-</td>
-
-<td><b>Field Research Project</b><br>
-<a href="#field">View Metadata Dictionary</a></b>
-
-<ul>
-	<li>Project Title</li>
-	<li>PI/Co-PI(s)&#42;</li>
-	<li>Project Type</li>
-	<li>Description</li>
-	<li>Related Work(s)&#42;<sup>$</sup></li>
-	<li>Award(s)&#42;<sup>$</sup></li>
-	<li>Keywords</li>
-	<li>Natural Hazard Event</li>
-	<li>Natural Hazard Date</li>
-	<li>Documents Collection&#42;<sup>$</sup>
-	<ul>
-		<li>Author(s)&#42;</li>
-		<li>Date of Publication<sup>†</sup></li>
-		<li>DOI<sup>†</sup></li>
-		<li>Publisher<sup>†</sup></li>
-		<li>License(s)&#42;</li>
-		<li>Referenced Data&#42;<sup>$</sup></li>
-		<li>Description</li>
-	</ul>
-	</li>
-	<li>Mission&#42;
-	<ul>
-		<li>Mission Title</li>
-		<li>Author(s)&#42;</li>
-		<li>Date(s) of Mission</li>
-		<li>Mission Site Location</li>
-		<li>Date of Publication</li>
-		<li>DOI<sup>†</sup></li>
-		<li>Publisher<sup>†</sup></li>
-		<li>License(s)<span style="font-size: 10.8333px;">&#42;</span></li>
-		<li>Mission Description</li>
-		<li>Research Planning Collection<span style="font-size: 10.8333px;">&#42;<sup>$</sup></span>
-		<ul>
-			<li>Collection Title</li>
-			<li>Data Collector(s)<span style="font-size: 10.8333px;">&#42;</span></li>
-			<li>Referenced Data&#42;<sup>$</sup></li>
-			<li>Collection Description</li>
-		</ul>
-		</li>
-		<li>Social Sciences Collection&#42;
-		<ul>
-			<li>Collection Title</li>
-			<li>Unit of Analysis<sup>$</sup></li>
-			<li>Mode(s) of Collection<sup>&#42;$</sup></li>
-			<li>Sampling Approach(es)<sup>&#42;$</sup></li>
-			<li>Sample Size<sup>$</sup></li>
-			<li>Date(s) of Collection</li>
-			<li>Data Collector(s)&#42;</li>
-			<li>Collection Site Location</li>
-			<li>Equipment&#42;</li>
-			<li>Restriction<sup>$</sup></li>
-			<li>Referenced Data&#42;<sup>$</sup></li>
-			<li>Collection Description</li>
-		</ul>
-		</li>
-		<li>Engineering/Geosciences Collection&#42;
-		<ul>
-			<li>Collection Title</li>
-			<li>Observation Type&#42;</li>
-			<li>Date(s) of Collection</li>
-			<li>Data Collector(s)&#42;</li>
-			<li>Collection Site Location</li>
-			<li>Equipment&#42;</li>
-			<li>Referenced Data&#42;<sup>$</sup></li>
-			<li>Collection Description</li>
-		</ul>
-		</li>
-	</ul>
-	</li>
-</ul>
-
-
-</td></tr>
-
-	
-
-<tr valign="top"><td><b>Other</b><br>
-<a href="#other_1">View Metadata Dictionary</a></b>
-
-<ul>
-	<li>DOI<sup>†</sup></li>
-	<li>Project Title</li>
-	<li>Author(s)&#42;</li>
-	<li>Data Type</li>
-	<li>Description</li>
-	<li>Publisher<sup>†</sup></li>
-	<li>Date of Publication<sup>†</sup></li>
-	<li>License(s)</li>
-	<li>Related Works&#42;<sup>$</sup></li>
-	<li>Award&#42;</li>
-	<li>Keywords</li>
-</ul>
-
-</td></tr></table>
-
----
-
-### Data Publication
-
-#### Protected Data { #protecteddata }
-
-Protected data in the  Data Depot Repository (DDR) are generally (but not always) included within interdisciplinary and social science research projects that study human subjects, which always need to have approval from an Institutional Review Board (IRB). We developed a data model and onboarding instructions <a href="https://converge.colorado.edu/data/data-publication">in coordination with our CONVERGE partners</a> to manage this type of data within our curation and publication pipelines. Additionally, CONVERGE has a series of <a href="https://converge.colorado.edu/resources/check-sheets/ethical-considerations/">check sheets</a> that outline how researchers should manage data that could contain sensitive information; these check sheets have also been published in <a href="http://doi.org/10.17603/ds2-7r74-1021">the DDR</a>.
-
-Natural Hazards also encompasses data that have granular geographical locations and images that may capture humans that are not the focus of the research/would not fall under the purview of an IRB. See both the Privacy Policy within our <a href="https://www.designsafe-ci.org/account/terms-conditions/">Terms of Use</a>,
-
-Data de-identification, specially for large datasets, can be tasking. Users working with the RAPID facility may discuss with them steps for pre-processing before uploading to DesignSafe.
-
-To publish protected data researchers should pursue the following steps and requirements:
-
-1. Do not publish <a href="https://www.hhs.gov/hipaa/for-professionals/privacy/laws-regulations/index.html">HIPAA</a>, <a href="https://studentprivacy.ed.gov/faq/what-ferpa">FERPA</a>, <a href="https://csrc.nist.gov/projects/risk-management/fisma-background">FISMA</a>, PII data or <a href="https://en.wikipedia.org/wiki/Information_sensitivity">sensitive information</a> in the DDR.  </li>
-1. To publish protected data and any related documentation (reports, planning documents, field notes, etc.) it must be processed to remove identifying information. No direct identifiers and up to three indirect identifiers are allowed. <strong>Direct identifiers</strong> include items such as participant names, participant initials, facial photographs (unless expressly authorized by participants), home addresses, phone number, email, vehicle identifiers, biometric data, names of relatives, social security numbers and dates of birth or other dates specific to individuals. Indirect identifiers are identifiers that, taken together, could be used to deduce someone’s identity. Examples of <strong>indirect identifiers</strong> include gender, household and family compositions, places of birth, or year of birth/age, ethnicity, general geographic indicators like postal code, socioeconomic data such as occupation, education, workplace or annual income.  </li>
-1. Look at the de-identification resources below to find answers for processing protected data.  </li>
-1. If a researcher has obtained consent from the subjects to publish PII (images, age, address), it should be clearly stated in the publication description and with no exceptions the IRB documentation including the informed consent statement, should be also available in the documentation.  </li>
-1. If a researcher needs to restrict public access to data because it includes HIPAA, FERPA, PII or other sensitive information, or if de-identification precludes the data from being meaningful, it is possible to publish only metadata about the data in the landing page along with descriptinve information a bout the dataset. The dataset will show as Restricted.  </li>
-1. IRB documentation should be included in the publication in all cases so that users clearly understand the restrictions imposed for the protected data. In addition, authors may publish the dataset instrument, provided that it does not include any form of protected information.  </li>
-1. Users interested in restricted data can contact the project PI or designated point of contact through their published email address to request access to the data and to discuss the conditions for its reuse.  </li>
-1. The responsibility of maintaining and managing a restricted dataset for the long term lies on the authors, and they can use <a href="https://www.tacc.utexas.edu/protected-data-service">TACC's Protected Data Services</a> if they see fit.  </li>
-1. Please contact DDR through a <a href="http://www.designsafe-ci.org/help/new-ticket">help ticket</a> or join <a href="https://www.designsafe-ci.org/learning-center/training/">curation office hours</a> prior to preparing this type of publication.  </li>
-
-##### De-identification Resources { #protecteddata-deidentification }
-
-The NISTIR 8053 publication <a href="https://nvlpubs.nist.gov/nistpubs/ir/2015/NIST.IR.8053.pdf">De-Identification of Personal Information</a> provides all the definitions and approaches to reduce privacy risk and enable research.
-
-Another <a href="https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id">NIST resource</a> including de-identification tools.
-
-John Hopkins Libraries Data Services <a href="https://dataservices.library.jhu.edu/resources/applications-to-assist-in-de-identification-of-human-subjects-research-data/">Applications to Assist in De-identification of Human Subjects Research Data</a>.
-
-#### Reusing Data Resources in your Publication { #reusingdata }
-
-Researchers frequently use data, code, papers or reports from other sources in their experiments, simulations and field research projects as input files, to integrate with data they create, or as references, and they want to republish them. It is a good practice to make sure that this data can be reused appropriately and republished as well as give credit to the data creators. Citing reused sources is also important to provide context and provenance to the project. In the DDR you can republish or reference reused data following the next premises:
-
-<ol>
-	<li dir="ltr">
-	If you use external data in a specific experiment, mission or simulation, cite it in the Referenced Data field.
-	</li>
-	<li dir="ltr">
-	Use the Related Work field at project level to include citations for the data you reused as well as your own publication related to the data reuse.
-	</li>
-	<li dir="ltr">
-	Include the cited resource title and corresponding DOI in https format; this way, users will be directed to the cited resource. 
-	</li>
-	<li dir="ltr">
-	Be aware of the reused data original license. The license will specify if and how you can modify, distribute, and cite the reused data.
-	</li>
-	<li dir="ltr">
-	If you have reused images from other sources (online, databases, publications, etc.), be aware that they may have copyrights. We recommend using <a href="http://guides.library.ubc.ca/c.php?g=698822&amp;p=4965735">these instructions</a> for how to use and cite them. 
-	</li>
-</ol>
-
-#### Timely Data Publication  { #timelypublication }
-
-Although no firm timeline requirements are specified for data publishing, researchers are expected to publish in a timely manner. Recommended timelines for publishing different types of research data (i.e., Experimental, Simulation, and Reconnaissance) are listed in Table 1.
-
-Guidelines specific to RAPID reconnaissance data can be found at <a href="https://rapid.designsafe-ci.org/media/filer_public/b3/82/b38231fb-21c9-41f8-b658-f516dfee87c8/rapid-designsafe_curation_guidelines_v3.pdf">rapid.designsafe-ci.org/media/filer_public/b3/82/b38231fb-21c9-41f8-b658-f516dfee87c8/rapid-designsafe_curation_guidelines_v3.pdf</a><br>
-
-##### Table 1. Recommended Publishing Timeline for Different Data Types { #table1 }
-
-<table border="1" width="100%">
-	<tbody>
-		<tr>
-			<td>
-			<b>Project/Data Type</b>
-			</td>
-			<td>
-			<b>Recommended Publishing Timeline</b>
-			</td>
-		</tr>
-		<tr>
-			<td>
-			Experimental
-			</td>
-			<td>
-			12 months from completion of experiment
-			</td>
-		</tr>
-		<tr>
-			<td>
-			Simulation
-			</td>
-			<td>
-			12 months from completion of simulations
-			</td>
-		</tr>
-		<tr>
-			<td>
-			Reconnaissance: Immediate Post-Disaster
-			</td>
-			<td>
-			3 months from returning from the field
-			</td>
-		</tr>
-		<tr>
-			<td>
-			Reconnaissance: Follow-up Research
-			</td>
-			<td>
-			6 months from returning from the field
-			</td>
-		</tr>
-	</tbody>
-</table>
-
-#### Public Accessibility Delay { #accessibilitydelay }
-
-Some journals require that researchers submitting a paper for review inlcude the corresponding dataset DOI in the manuscript. Data accessibility delay or embargo refers to time during which a dataset has a DOI but it is not made broadly accessible, awaiting for the review to be accepted by a journal paper.
-
-In August 25, 2022 the Office of Science and Technology Policy issued a <a href="https://www.whitehouse.gov/wp-content/uploads/2022/08/08-2022-OSTP-Public-access-Memo.pdf" target="_blank"> memorandum with policy guidelines </a> to “ensure free, immediate and equitable access to federally funded research.” In the spirit of this guidance, DesignSafe has ceased offering data accessibility delays or embargos. DesignSafe continues working with users to:
-
-<ul>
-	<li dir="ltr">
-	Provide access to reviewers via My Projects before the dataset is published. There is no DOI involved and the review is not annonymous.
-	</li>
-	<li dir="ltr">
-	Help users curate and publish their datasets so they are publicly available for reviewers in the best possible form.
-	</li>
-	<li dir="ltr">
-	Provide amends and versioning so that prompt changes can be made to data and metadata upon receiving feedback from the reviewers or at any other time.
-	</li>
-</ul>
-
-In addition, DesignSafe Data Depot does not offer capabilities for enabling single or double blind peer review.
-
-
-#### Licensing { #licensing }
-
-Within DesignSafe, you will choose a license to distribute your material. The reason for offering licences with few restrictions, is that by providing less demands on reusers, they are more effective at enabling reproducible science. We offere licenses with few to no restrictions. By providing less demands on reusers, they are more effective at enabling reproducible science. Because the DesignSafe Data Depot is an open repository, the following licenses will be offered:
-
-<ul>
-	<li>For datasets: ODC-PDDL and ODC-BY</li>
-	<li>For copyrightable materials (for example, documents, workflows, designs, etc.): CC0 and CC-BY</li>
-	<li>For code: GPL</li>
-</ul>
-
-You should select appropriate licenses for your publication after identifying which license best fits your needs and institutional standards. Note that datasets are not copyrightable materials, but works such as reports, instruments, presentations and learning objects are.
-
-<strong>Please select only one license per publication with a DOI. </strong>
-
-
-Available Licenses for Publishing Datasets in DesignSafe
-
-##### DATASETS { #licensing-datasets }
-
-If you are publishing data, such as simulation or experimental data, choose between:
-
-<table class="tg" style="width: 100%; padding-bottom: 15px;">
-	<tr>
-		<td><strong>Open Data Commons Attribution</strong>
-		<div style="color: #158600;">Recommended for datasets</div>
-		</td>
-	</tr>
-	<tr><td>
-		<ul>
-			<li>You allow others to freely share, reuse, and adapt your data/database.</li>
-			<li>You expect to be attributed for any public use of the data/database.</li>
-		</ul>
-
-		Please read the <a href="https://opendatacommons.org/licenses/by/summary/" target="_blank">License Website</a>
-	</td></tr></table>
-	
-
-<table>
-	<tr>
-		<td><strong>Open Data Commons Public Domain Dedication</strong>
-		<div style="color: orange;">Consider and read carefully</div>
-		</td>
-	</tr>
-
-	<tr><td>
-
-		<ul>
-			<li>You allow others to freely share, modify, and use this data/database for any purpose without any restrictions.</li>
-			<li>You do not expect to be attributed for it.</li>
-		</ul>
-
-
-		Please read the <a href="https://opendatacommons.org/licenses/pddl/summary/" target="_blank">License Website</a>
-		</td>
-	</tr>
-</table>
-
-##### WORKS { #licensing-works }
-
-If you are publishing papers, presentations, learning objects, workflows, designs, etc, choose between:
-
-<table class="tg" style="width: 100%; padding-bottom: 15px;">
-<tr>
-<td class="tg-0lax" valign="top">
-<tr>
-<td><strong>Creative Commons Attribution </strong>
-<div style="color: #158600;">Recommended for reports, instruments, learning objects, etc.</div>
-</td>
-</tr>
-<tr><td>
-			<ul>
-				<li>You allow others to freely share, reuse, and adapt your work.</li>
-				<li>You expect to be attributed for any public use of your work.</li>
-				<li>You retain your copyright.</li>
-			</ul>
+* There could be more than one Related Work and Referenced Data or Software per published dataset.  
+* Related Works and Referenced Data or Software can be added at any time during or after the dataset's publication. In the former case, it can be done through Amends or Versioning.
+* In the form researchers should include the cited resource title and corresponding DOI in https format; this way, other users will be directed to the cited resource.
+* When using a DOI, the platform will submit this information to a third party (Cross-Ref via DataCite) that will assign the citations to the corresponding resources so that authors are credited appropriately.
+* In order to reuse images from other sources (online, databases, publications, etc.), users should look into their rights and licensing restrictions and follow them appropriately.  Users should also follow [instructions on how to cite the images](https://guides.library.ubc.ca/images/citing).
 
-			Please read the <a href="https://creativecommons.org/licenses/by/4.0/" target="_blank">License Website</a>
-			</td>
-</tr></table>
+## Rights
 
+DDR publishes data and other types of materials, some of which such as reports, presentations, and learning materials are protected under the [U.S. Copyright law](https://www.copyright.gov/title17/). The U.S. Copyright Office considers that [information that is discovered as opposed to created does not have copyrights](https://www.copyright.gov/title17/). This applies to a majority of datasets published in DDR which are conceived as a collection of facts.
 
-<table>
-<tr>
-<td><strong>Creative Commons Public Domain Dedication</strong>
-<div style="color: orange;">Consider and read carefully</div>
-</td>
-</tr>
-<tr><td>
-<ul>
-<li>You allow others to freely share, modify, and use this work for any purpose without any restrictions.</li>
-<li>You do not expect to be attributed for it.</li>
-<li>You give all of your rights away.</li>
-</ul>
-Please read the <a href="https://creativecommons.org/publicdomain/zero/1.0/" target="_blank">License Website</a>
-</td>
-</tr>
-</table>
+Data may not, however, be only facts. That could be the case of certain types of field notes, answers from human subject interviews, or photographs. In turn, databases or other systems in which data is organized may be protected, but the data within will not be. In addition, [anything created solely by AI cannot be copyrighted](https://www.copyright.gov/ai/ai_policy_guidance.pdf). For updated information about this important topic see the University of Texas Libraries Copyright Issues in AI.
 
-##### SOFTWARE { #licensing-software }
+As an open repository committed to responsible access, we offer different licenses under which authors can share their data  publicly, and establish the conditions in which it can be reused by others. Options offered in the DDR are [Creative Commons licenses](https://creativecommons.org/share-your-work/cclicenses/) (with attribution or public domain) and [Open Data licenses](https://opendatacommons.org/licenses/) (with and without attribution). The first ones involve creative work under copyright law, and the latter are designed specifically for data. All licensing choices in DesignSafe involve the least restrictive conditions under which data and works can be shared and reused.  In general, any creative work such as papers, reports, presentations, social science research instruments, learning objects,  and posters can be shared under a Creative Commons license while for data it is best to choose an Open Data license. When consulting with our community, most expressed that they want to be attributed, which means that reusers of data should add the dataset citation in the reference section of the papers they publish using the data. Please refer to the [Licenses documentation](/user-guide/curating/policies/#licenses), and visit us during our [Virtual Office Hours](https://www.designsafe-ci.org/facilities/virtual-office-hours/) to discuss any doubts in choosing the right license with the data curator.
 
-If you are publishing community software, scripts, libraries, applications, etc, choose the following:
+## Amends and Versioning
 
-<table>
-<tr> <td><strong>GNU General Public License</strong></td> </tr>
-<tr><td>
-<ul>
-<li>You give permission to modify, copy, and redistribute the work or any derivative version.</li>
-<li>The licensee is free to choose whether or not to charge a fee for services that use this work.</li>
-<li>They cannot impose further restrictions on the rights imposed by this license.</li>
-</ul>
-Please read the <a href="http://www.gnu.org/licenses/gpl.html" target="_blank">License Website</a>
-</td></tr>
-</table>
-
-#### Subsequent Publishing { #publishing }
-
-With the exception of Project Type Other, which is a one time publication, in the DDR it is possible to publish datasets or works subsequently. A project can be conceived as an umbrella where reports or learning materials, code, and datasets from distinct experiments, simulations, hybrid simulations or field research missions that happen at different time periods, involve participation of distinct authors, or need to be released more promptly, can be published at different times. Each new product will have its own citation and DOI, and users may select a different license if that is appropriate for the material, (e.g. a user publishing a data report will use a Creative Commons license, and an Open Data Commons license to publish the data). The subsequent publication will be linked to the umbrella project via the citation, and to the other published products in the project through metadata.
-
-After a first publication, users can upload more data and create a new experiment/simulation/hybrid simulation or mission and proceed to curate it. Users should be aware that momentarily they cannot publish the new product following the publication pipeline. After curation and before advancing through the Publish My Project button, they should write a help ticket or attend curation office hours so that the DDR team can assist and publish the new product.
-
-#### Amends and Version Control  { #amends }
-
-Once a dataset is published users can do two things to improve and or / continue their data publication: amends and version control. Amends involve correcting certain metadata fields that do not incur major changes to the existing published record, and version control includes changes to the data. Once a dataset is published, however, we do not allow title or author changes. If those changes need to be made due to omission or mistake, users have to submit a Help ticket and discuss the change with the data curator. If applicable, changes will be done by the curation team.
+Once a dataset is published, users can amend or version their data publications. Amends involve correcting certain metadata fields that do not incur changes to the existing data files. Versioning involves amends and or changes to the data. These actions can be performed by the authors through My Project. 
 
 Amends include:
 
-<ul>
-<li>Improving descriptions: often after the curator reviews the publicationn, or following versioning, users need to clarify or enhance descriptions.</li>
-<li>Adding related works: when papers citing a dataset are published we encourage users to add the references in Related Works to improve data understandibility and cross-referencing and citation count.</li>
-<li>Changing the order of authors: even though DDR has interactive tools to set the order of authors in the publication pipeline, users further require changes after publication due to oversight.</li>
-</ul>
-
-Version control includes:
-
-<ul>
-<li>Adding or deleting files to a published dataset.</li>
-<li>Documenting the nature of the changes which will publicly show in the landing page.</li>
-<li>Descriptions of the nature of the changes are displayed for users to see what changed and stored as metadata.</li>
-<li>In the citation and landing pages, different versions of a dataset will have the same DOI and different version number. </li>
-<li>The DOI will always resolve to the latest version of the data publication. </li>
-<li>Users will always be able to access previous versions through the landing page.</li>
-</ul>
-
-When implementing amend and version take the following into consideration:
-
-<b data-stringify-type="bold">Amend</b> is only going to update the latest version of a publication (if there is only one version that will be the target). Only the specified fields in the metadata form will be updated. The order of authors must be confirmed before the amendments can be submitted.
+* Improving descriptions and adding keywords: after the curator reviews the publication, or following versioning, users may need to clarify or enhance descriptions and keywords.
+* Improve or add metadata: Adding information in a non-required field, or changing, improving already completed fields.
+* Changing the order of authors: even though DDR has interactive tools to set the order of authors in the publication pipeline, users may require changes after publication.
+* Add Funders and Awards: It is always important to provide credit to the agencies that fund the research that allows creating the data. 
+* Adding Related Works: when papers citing a dataset are published, we encourage users to add the references in Related Works (option: is cited by) to improve data understandability, cross-referencing, and citation count. Other related works inform contextual, informing the 
+* Adding Referenced Data and Software: when other datasets and or research software was used to create the published dataset.
 
-<b data-stringify-type="bold">Version</b> will create a new published version of a project. This pipeline will allow you to select a new set of files to publish, and whatever is selected in the pipeline is what will be published, nothing else. Additionally, the order of authors can be updated.
 
-<b data-stringify-type="bold">Important</b>: Any changes to the project’s metadata will also be updated (this update is limited to the same fields allowed in the Amend section), so there is no need to amend a newly versioned project unless you have made a mistake in the latest version.
 
-#### Leave Data Feedback { #feedback }
-
-We welcome feedback from users about the published datasets. For this, users can click on the "Leave Feedback" button at the top of the data presentation on the data publication landing pages. We suggest that feedback is written in a positive, constructive language. The following are examples of feedback questions and concerns:
-
-<ul>
-	<li>Questions about the dataset that are not answered in the published metadata and or documentation.</li>
-	<li>Missing documentation.</li>
-	<li>Questions about the method/instruments used to generate the data.</li>
-	<li>Questions about data validation.</li>
-	<li>Doubts/concerns about data organization and or inability to find desired files.</li>
-	<li>Interest in bibliography about the data/related to the data.</li>
-	<li>Interest in reusing the data.</li>
-	<li>Comments about the experience of reusing the data.</li>
-	<li>Request to access raw data if not published.</li>
-	<li>Congratulations.</li>
-</ul>
-
-#### Marketing Datasets { #marketing }
-
-Datasets take a lot of work to produce; they are important research products. By creating a complete, organized, and clearly described publication in DDR, users are inviting others to reuse and cite their data.  Researchers using published data from DDR must cite it using the DOI, which relies on the <a href="http://schema.datacite.org/">DataCite schema</a> for accurate citation. For convenience, users can retrieve a formatted citation from the published data landing page. It is recommended to insert the citations in the reference section of the paper to facilitate citation tracking and count.
-
-When using social media or any presentation platform to communicate research, it is important to include the proper citation and DOI on the presentations, emails, tweets, professional blog posts, etc.. A researcher does not actually need to reuse a dataset to cite it, but rather may cite it to point/review something about a dataset (e.g., how it was collected, its uniqueness, certain facts, etc.). This is similar to the process of citing other papers within a literary review section.
-
----
-
-### Data Preservation { #datapreservation }
-
-In the Data Depot Repository (DDR) data preservation is achieved through the combined efforts of the NH community that submits data and metadata following policies and best practices, and the DDR's administrative responsibilities and technical capabilities. The following data preservation best practices ensure preservation of the data from the moment in which researchers plan their data projects and for the long term after the data is published.
-
-Depositing your data and associated research project materials in the DDR meets NSF requirements for data management. See our <a href="../managingdata/#data-management-plan-guidance">Data Management Plan</a>.
-
-
-Follow the curation and publication onboarding instructions and steps -documented in the <a href="#curation-publication-guides">Data Curation and Publication Guides</a> - to ensure that your data curation and publication process is smooth and that your public datasets are well organized, complete, and understandable to others.
-
-
-To facilitate long term access to your published data, when possible, we recommend using open file formats. Open file formats facilitate interoperability between datasets and with applications, which in turn facilitates long term access to the datasets. <!-- The Data Curation and Publication Best Practices have information about [file formats](/user-guide/curating/bestpractices/#acceptedfileformats). -->
-
-
-DDR data is stored in high performance storage (HPC) resources deployed at the <a href="https://www.tacc.utexas.edu" target="_blank">Texas Advanced Computing Center</a>. These storage resources are reliable, secure, monitored 24/7, and under a rigorous maintenance and update schedule.
-
-
-While you are uploading and working with your data in DDR, your data is safe and geographically replicated in <a href="https://www.tacc.utexas.edu/systems/corral" target="_blank">Corral,</a> TACC's storage and data management resource.
-
-
-DDR operates a dedicated open source <a href="https://duraspace.org/fedora/">Fedora</a> 5.x digital repository. Once the dataset is curated and the user has agreed to the last step in the publication process, the data and the metadata that the user has been inputting throughout the curation processare sent to Fedora where each published dataset contains linkages between datastreams, versions, metadata, and system metadata. At ingest, Fedora metadata records are created and publication binaries are bundled with a hash (fixity) and stored on Corral in a secure location that is recorded on the metadata (<a href="https://wiki.lyrasis.org/display/FEDORA38/Fedora+Digital+Object+Model" target="_blank">See Fedora data model</a>). For each individual file, Fedora generates and maintains preservation metadata in the standard <a href="https://www.loc.gov/standards/premis/" target="_blank">PREMIS </a>format.
+Version control includes:
 
+* Adding or deleting files to a published dataset.
+* Documenting the nature of the changes which will publicly show in the landing page.
+* Descriptions of the nature of the changes are displayed for users to see what changed and stored as metadata.
+* Any changes to the project’s metadata will also be updated (this update is limited to the same fields allowed in the Amend section), so there is no need to amend a newly versioned project unless you have made a mistake in the latest version.
 
-In the case of the DDR, file system replication is automatic. Ingestion of data from the web-visible storage into Fedora takes place under automated control when the publication workflow executes. The Fedora repository and database is likewise replicated as well as backed up on an automated schedule. Metadata preservation is assured through the backup of Fedora's metadata database. In case of failure where data is compromised, we can restore the system from the replication.
+Versioning has these implications for the project’s DOI:
 
+* In the citation and landing pages, different versions of a dataset will have the same DOI and different version number.
+* The DOI will always resolve to the latest version of the data publication.
+* Users will always be able to access previous versions through the landing page.
 
-Both the front-end copies and the Fedora repositories are in systems that implement de-clustered RAID and have sufficient redundancy to manage up to 3 drive failures for a single file stripe. The file system itself is mirrored daily between two datacenters. The primary data is also periodically backed up to a tape archive for a third copy, in a third datacenter. The database that manages metadata in Fedora is also quiesced, snapshotted, and backed to tape on a regular automated schedule.
+When implementing amends and versioning, consider the following:
 
+* Amend will only update the latest version of a publication (if there is only one version that will be the target). Only the specified fields in the metadata form will be updated. The order of authors must be confirmed before the amendments can be submitted.
+* Once a dataset is published, major changes to the title or author changes are not permitted. If changes must be made due to omission or a mistake, users should submit a Help ticket and discuss the change with the data curator. If applicable, changes will be made by the curation team.
 
-The underlying storage systems for the DDR are managed in-house at TACC. All the storage systems used by DesignSafe are shared multi-tenant systems, hosting many projects concurrently in addition to DesignSafe – the front-end disk system currently has ~20PB of data, with the <a href="https://www.tacc.utexas.edu/systems/ranch" target="_blank">tape archive </a>containing roughly 80PB. These systems are operated in production by a large team of professional staff, in conjunction with TACC’s supercomputing platforms. Public user guides document the capabilities and hardware, and internal configuration management is managed via Redmine, visible only to systems staff.
 
 
-This preservation environment allows maintaining data in secure conditions at all times, before and after publication, comply with <a href="https://ndsa.org/publications/levels-of-digital-preservation/">NDSA Preservation Level 1</a>, attain and maintain the required representation and descriptive information about each file, and be ready at any time to transfer custody of published data and metadata in an orderly and validated fashion. Fedora has <a href="https://github.com/fcrepo-exts/fcrepo-import-export">export capabiiities</a> for transfer of data and metadata to another Fedora repository or to another system.
 
+## Leaving Data Feedback
 
-Each published dataset has a <a href="#curation-publication-faq">digital object identifier (DOI)</a> that provides a persistent link to the published data. The DOI is available in the dataset landing page, along with all the required metadata and documentation.
+Users can click a “Leave Feedback” button on the projects’ landing pages to provide comments on any publication. This feedback is transformed into a ticket and forwarded to the curation team for any needed actions, including contacting the authors. In addition, it is possible for users to message the authors directly as their contact information is available via the authors field in the datasets landing pages. However, leaving the feedback in the form allows tracking of the issues raised. The following are examples of feedback questions and concerns:
 
-To learn about our commitment to data preservation, please read our <a href="#data-preservation/">Digital Preservation Policy</a>.
+* Questions about the dataset that are not answered in the published metadata and or documentation.
+* Missing documentation.
+* Questions about the method/instruments used to generate the data.
+* Questions about data validation.
+* Doubts/concerns about data organization and or inability to find desired files.
+* Interest in bibliography about the data/related to the data.
+* Interest in reusing the data.
+* Comments about the experience of reusing the data.
+* Request to access raw data if not published.
+* Requests to access restricted data if the authors authorize it. 
+* Issues related to published code that is not working properly.
+* Congratulations.
\ No newline at end of file
diff --git a/user-guide/docs/curating/faq.md b/user-guide/docs/curating/faq.md
index 3dc106b4..45fa7156 100644
--- a/user-guide/docs/curating/faq.md
+++ b/user-guide/docs/curating/faq.md
@@ -1,101 +1,160 @@
 # Frequently Asked Questions
 
-### Selecting Files & Data { #selecting }
+<style id="faq-style">
+summary {
+    font-weight: var(--medium);
+}
+details {
+    margin-block: 1em;
+}
+</style>
 
-**Q: What are the best file formats for data publications?**  
-**A**: For long-term preservation purposes it is best to publish data in interoperable and open formats. For example, instead of Excel spreadsheet files -which are proprietary- it is best to convert them to CSV for publication. And, instead of Matlab files -also proprietary- it is best to publish data as simple txt (ascii) so it can be used by many different software. However, be aware that conversion may distort the data structure, so retain an original copy of any structured data (e.g. Matlab, Excel files) before attempting conversions and then check between the two for fidelity. In addition, you may publish both the proprietary and the open format, and/or consult the Data Curation Primers to find out how to better curate research data.
+## Selecting Files & Data { #selecting }
 
-**Q: What does DesignSafe recommend for zip files?**  
-**A**: If you uploaded your data as zip files, you should unzip before publishing. Zip files prevent others from directly viewing and understanding your data in the cloud. You may upload zip files to your "MyData" and unzip them using the [Extract utility](https://www.designsafe-ci.org/workspace/extract) before copying them to your project.
+/// details | What are the best file formats for data publications?
 
-**Q: My project has many individual files. It will be cumbersome for a user to download them one by one. What do you suggest?**  
-**A**: Through the web interface, downloading a lot of individual files is cumbersome. However, DesignSafe offers a number of solutions for this issue. First, users may interact with data in the cloud, without the need to download, using Matlab scripts as well as Jupyter notebooks. In this case, users may find downloading large quantities of data to be unnecessary. If users want to download a large number of files from a project, we recommend that they use Globus or include zip files for your data files. However, if you include zip files you should include the unzipped files in your project as well. If you wish to make your data easy to download, it is best to aggregate small individual files into a smaller number of larger files when feasible.
+For long-term preservation purposes it is best to publish data in interoperable and open formats. For example, instead of Excel spreadsheet files -which are proprietary- it is best to convert them to CSV for publication. And, instead of Matlab files -also proprietary- it is best to publish data as simple txt (ascii) so it can be used by many different software. However, be aware that conversion may distort the data structure, so retain an original copy of any structured data (e.g. Matlab, Excel files) before attempting conversions and then check between the two for fidelity. In addition, you may publish both the proprietary and the open format, and/or consult the Data Curation Primers to find out how to better curate research data.
 
-**Q: Should I publish raw data?**  
-**A**: Raw data is that which comes directly from the recording instruments (camera, apps, sensors, scanners, etc.). When raw data is corrected, calibrated, reviewed, edited, or post-processed in any way for publication, it is called curated. Some researchers want to publish their raw data as well as their curated data; if this is your case, consider why it is necessary to publish both sets, and how another researcher would use it. Always clarify whether your data is raw or curated in the description or in a readme file, and use applicable methods to review the data for errors before publishing.
+///
+/// details | What does DesignSafe recommend for zip files?
 
-**Q: I will publish a large collection of images. What do I need to consider?**  
-**A**: Be selective with the images you choose to publish. Make sure they have a purpose and are illustrative of a process or a function. Use file tags to describe them. If the images include team members make sure they are comfortable with making their images public. If images include people that have been affected by the natural hazard, you should procure their authorization to make their pictures public.
+If you uploaded your data as zip files, you should unzip before publishing. Zip files prevent others from directly viewing and understanding your data in the cloud. You may upload zip files to your "MyData" and unzip them using the [Extract utility](https://www.designsafe-ci.org/workspace/extract){ target="_blank" } before copying them to your project.
 
-**Q: What type of Data projects can be published in DesignSafe?**  
-**A**: We have multiple data models and you may publish project types as "Experimental", "Simulation", "Hybrid Simulation", "Field Research" and "Other". Using the "Field Research" data model, you can publish both Engineering/Geosciences collections as well as Social Sciences collections. Stand-alone reports, presentations, software and white papers, as well as datasets that do not fit with the rest of the project types can be published in the project type "Other".
+///
+/// details | My project has many individual files. It will be cumbersome for a user to download them one by one. What do you suggest?
 
-**Q: How should I select data to be published in a project?**    
-**A**: While right now there is no limit to the amount of files that can be published in DesignSafe, the comprehension and reuse potential of the data should be important considerations when selecting what data can be published. This goes with the possibility to clearly describe the data and establish and document its completeness and validity. For all project types, you have the option to select a subset of the files uploaded to My Project that you wish to publish without the need to delete them from the Working Directory.
+Through the web interface, downloading a lot of individual files is cumbersome. However, DesignSafe offers a number of solutions for this issue. First, users may interact with data in the cloud, without the need to download, using Matlab scripts as well as Jupyter notebooks. In this case, users may find downloading large quantities of data to be unnecessary. If users want to download a large number of files from a project, we recommend that they use Globus or include zip files for your data files. However, if you include zip files you should include the unzipped files in your project as well. If you wish to make your data easy to download, it is best to aggregate small individual files into a smaller number of larger files when feasible.
 
-**Q: What should I consider before publishing Jupyter Notebooks?**  
-**A**: Please refer to our Jupyter User Guide document to find information on how to publish a Jupyter Notebook.
+///
+/// details | Should I publish raw data?
 
-### Organizing & Describing Your Dataset { #organizing }
+Raw data is that which comes directly from the recording instruments (camera, apps, sensors, scanners, etc.). When raw data is corrected, calibrated, reviewed, edited, or post-processed in any way for publication, it is called curated. Some researchers want to publish their raw data as well as their curated data; if this is your case, consider why it is necessary to publish both sets, and how another researcher would use it. Always clarify whether your data is raw or curated in the description or in a readme file, and use applicable methods to review the data for errors before publishing.
 
-**Q: How should I organize the data files to be published in a project?**
-**A**: For each type of project publication, the best way to organize your data is to map them to the organizational schema provided by the data models available for each research type (simulation, experimental, hybrid simulation and field research). These models were designed by experts and represent the main data and documentation components required for others to understand and reuse your dataset.
+///
+/// details | I will publish a large collection of images. What do I need to consider?
 
-**Q: Can I organize my data files into a hierarchy of folders in DesignSafe?**  
-**A**: DesignSafe offers methods for categorizing (organizing) and tagging (describing) your files. To enhance organization and description of large and complex projects, users can group files in folders. However, it is always best to avoid overly nesting because browsing through an extensive folder hierarchy on the web is slower than on your local computer. So to improve the user experience, you should try to use the smallest number of nested folders necessary. Instead, you may use categories, descriptions, and tags to indicate what the groupings are. This provides a method for users to identify and search your files efficiently.
+Be selective with the images you choose to publish. Make sure they have a purpose and are illustrative of a process or a function. Use file tags to describe them. If the images include team members make sure they are comfortable with making their images public. If images include people that have been affected by the natural hazard, you should procure their authorization to make their pictures public.
 
-**Q: How should I describe the dataset organization in a project type "Other"?**  
-**A**: In project type Other you will be able to tag individual files for ease of data understandability and reuse. If you publish many files and need to organize them in folders, we suggest providing a description of the organizational structure and naming convention that you use in your dataset in a "readme" file or a report. This file can simply be a text file or pdf file.
+///
+/// details | What type of Data projects can be published in DesignSafe?
 
-**Q: Why do you require a report/readme in all of your data publications?**  
-**A**: The "Experimental", "Simulation", "Hybrid Simulation", and "Field Research" project types provide a representation of the structure of the datasets. Still, you may need to clarify the meaning of the fields of your datasets, the functions of your files and their naming convention, the way you decided to organize them, or describe other reuse characteristics of your data. Providing a report/readme file and/or a data dictionary associated with your data is an ideal way to express this information.
+We have multiple data models and you may publish project types as "Experimental", "Simulation", "Hybrid Simulation", "Field Research" and "Other". Using the "Field Research" data model, you can publish both Engineering/Geosciences collections as well as Social Sciences collections. Stand-alone reports, presentations, software and white papers, as well as datasets that do not fit with the rest of the project types can be published in the project type "Other".
 
-**Q: How can I provide more contextual information about my published dataset?**  
-**A**: To enhance the knowledge surrounding your dataset, you can use the "Related Work" field at the project level to point to web-pages, publications, or datasets that are published within or outside DesignSafe and that you consider relevant to point to in your publication. For example, you may point to a separate published project in DesignSafe, or provide the title and DOI of an article that relates to your data. You may also use the description fields in the data model to include specific parameters or facts that you want to highlight (e.g. wind speed during a hurricane, earthquake magnitude, damage types, etc.). Adding tags, both from a controlled list available or by including a custom one, helps other users to find the files that they need within the data landing page.
+///
+/// details | How should I select data to be published in a project?
 
-**Q: How can I convey the quality of my data publication?**  
-**A**: Data quality, as entailed by the metadata, concerns the completeness of the data documentation and the validity and integrity of the data content. Following DesignSafe curation and documentation best practices, as well as the onboarding instructions on the curation and publication interfaces, and adding a data report or data dictionary enables publishing a complete dataset that others will understand. In addition, in the documentation and/or data description, it is important to clarify the processes conducted to assure the completeness and validity of the data content.
+While right now there is no limit to the amount of files that can be published in DesignSafe, the comprehension and reuse potential of the data should be important considerations when selecting what data can be published. This goes with the possibility to clearly describe the data and establish and document its completeness and validity. For all project types, you have the option to select a subset of the files uploaded to My Project that you wish to publish without the need to delete them from the Working Directory.
 
-**Q: I have another published work that is related to the project I am now planning to publish. How can I relate them?**  
-**A**: On the project landing page under Edit Project there is a "Related Work" field where you have the option to include one or more associated projects and publications to your current project. Here, you can provide the title as well as a link to that project or publication. This link can be a DOI or a URL for any content found inside or outside of DesignSafe. For DOIs, please make sure you are adding the entire DOI address starting with "http" to correctly link the webpage to the related project.
+///
+/// details | What should I consider before publishing Jupyter Notebooks?
 
-### Publishing { #publishing }
+Please refer to our Jupyter User Guide document to find information on how to publish a Jupyter Notebook.
 
-**Q: Which license is appropriate for my publication?**  
-**A**: Licenses indicate the conditions in which you, as a data creator, want the data to be used by others. Due to the variety of resources published in DesignSafe, we provide four different types of open licenses. These cover datasets, software, materials with intellectual property rights, and the different ways in which you want your work to be attributed. [Read more.](/user-guide/curating/bestpractices/#licensing)
+///
 
-**Q: What is a DOI?**  
-**A**: A Digital Object Identifier (DOI) is a unique alphanumeric string assigned by a registration agency (the International DOI Foundation) to identify a resource and provide a persistent link to its location on the Internet. You can find a registered resource by its DOI using the "Resolve a DOI Name" function at: [http://www.doi.org/](http://www.doi.org/){target="_blank"}. In addition, you may find the citation information for that DOI in DataCite at [https://search.datacite.org/](https://search.datacite.org/){target="_blank"}.
+## Organizing & Describing Your Dataset { #organizing }
 
-**Q: What is the relation between a DOI and a data citation?**  
-**A**: The DOI is a component of a citation for a work that is stored online. Therefore, it provides access to the permanent URL and the cited resource.
+/// details | How should I organize the data files to be published in a project?
 
-**Q: I have multiple experiments/simulations/missions to publish under one project. How should I do it?**  
-**A**: Projects with multiple experiments/simulations/missions (publication units) can be published sequentially over a large period of time. After one publication unit is completed, you may resume uploading files and will be able to publish another unit within the same project.  Each may have different authors and will receive individual DOIs.
+For each type of project publication, the best way to organize your data is to map them to the organizational schema provided by the data models available for each research type (simulation, experimental, hybrid simulation and field research). These models were designed by experts and represent the main data and documentation components required for others to understand and reuse your dataset.
 
-**Q: If the project type is "Experimental"/ "Simulation"/ "Field Research", how can I assign relevant authors to each experiment/simulation/mission?**  
-**A**: While creating experiments/simulations/missions, you have the option to assign authors to each one. Additionally, after successfully creating the publication, you can click on "Add (Experiment/Simulation/Mission)" on the Curation Directory page and then edit the authors and their order within the corresponding experiment/simulation/mission found in the inventory list.
+///
+/// details | Can I organize my data files into a hierarchy of folders in DesignSafe?
 
-**Q: How can I control the order of the authors for the published project and its citation?**  
-**A**: In the publication pipeline under "Order Authors" you will be able to arrange the order of authors for each publication using the arrow icons on the screen. This author order will be used in the citation that includes the DOI.
+DesignSafe offers methods for categorizing (organizing) and tagging (describing) your files. To enhance organization and description of large and complex projects, users can group files in folders. However, it is always best to avoid overly nesting because browsing through an extensive folder hierarchy on the web is slower than on your local computer. So to improve the user experience, you should try to use the smallest number of nested folders necessary. Instead, you may use categories, descriptions, and tags to indicate what the groupings are. This provides a method for users to identify and search your files efficiently.
 
-**Q: How can I give credit to DesignSafe?**  
-**A**: Please include the citation of the marker paper in the references/bibliography section of your publication. This is more effective than you providing in-text acknowledgements.
+///
+/// details | How should I describe the dataset organization in a project type "Other"?
+
+In project type Other you will be able to tag individual files for ease of data understandability and reuse. If you publish many files and need to organize them in folders, we suggest providing a description of the organizational structure and naming convention that you use in your dataset in a "readme" file or a report. This file can simply be a text file or pdf file.
+
+///
+/// details | Why do you require a report/readme in all of your data publications?
+
+The "Experimental", "Simulation", "Hybrid Simulation", and "Field Research" project types provide a representation of the structure of the datasets. Still, you may need to clarify the meaning of the fields of your datasets, the functions of your files and their naming convention, the way you decided to organize them, or describe other reuse characteristics of your data. Providing a report/readme file and/or a data dictionary associated with your data is an ideal way to express this information.
+
+///
+/// details | How can I provide more contextual information about my published dataset?
+
+To enhance the knowledge surrounding your dataset, you can use the "Related Work" field at the project level to point to web-pages, publications, or datasets that are published within or outside DesignSafe and that you consider relevant to point to in your publication. For example, you may point to a separate published project in DesignSafe, or provide the title and DOI of an article that relates to your data. You may also use the description fields in the data model to include specific parameters or facts that you want to highlight (e.g. wind speed during a hurricane, earthquake magnitude, damage types, etc.). Adding tags, both from a controlled list available or by including a custom one, helps other users to find the files that they need within the data landing page.
+
+///
+/// details | How can I convey the quality of my data publication?
+
+Data quality, as entailed by the metadata, concerns the completeness of the data documentation and the validity and integrity of the data content. Following DesignSafe curation and documentation best practices, as well as the onboarding instructions on the curation and publication interfaces, and adding a data report or data dictionary enables publishing a complete dataset that others will understand. In addition, in the documentation and/or data description, it is important to clarify the processes conducted to assure the completeness and validity of the data content.
+
+///
+/// details | I have another published work that is related to the project I am now planning to publish. How can I relate them?
+
+On the project landing page under Edit Project there is a "Related Work" field where you have the option to include one or more associated projects and publications to your current project. Here, you can provide the title as well as a link to that project or publication. This link can be a DOI or a URL for any content found inside or outside of DesignSafe. For DOIs, please make sure you are adding the entire DOI address starting with "http" to correctly link the webpage to the related project.
+
+///
+
+## Publishing { #publishing }
+
+/// details | Which license is appropriate for my publication?
+
+Licenses indicate the conditions in which you, as a data creator, want the data to be used by others. Due to the variety of resources published in DesignSafe, we provide [four different types of open licenses](/user-guide/curating/policies/#licenses). These cover datasets, software, materials with intellectual property rights, and the different ways in which you want your work to be attributed.
+
+///
+/// details | What is a DOI?
+
+A Digital Object Identifier (DOI) is a unique alphanumeric string assigned by a registration agency (the International DOI Foundation) to identify a resource and provide a persistent link to its location on the Internet. You can find a registered resource by its DOI using the "Resolve a DOI Name" function at: [http://www.doi.org/](http://www.doi.org/){target="_blank"}. In addition, you may find the citation information for that DOI in DataCite at [https://search.datacite.org/](https://search.datacite.org/){target="_blank"}.
+
+///
+/// details | What is the relation between a DOI and a data citation?
+
+The DOI is a component of a citation for a work that is stored online. Therefore, it provides access to the permanent URL and the cited resource.
+
+///
+/// details | I have multiple experiments/simulations/missions to publish under one project. How should I do it?
+
+Projects with multiple experiments/simulations/missions (publication units) can be published sequentially over a large period of time. After one publication unit is completed, you may resume uploading files and will be able to publish another unit within the same project.  Each may have different authors and will receive individual DOIs.
+
+///
+/// details | If the project type is "Experimental"/ "Simulation"/ "Field Research", how can I assign relevant authors to each experiment/simulation/mission?
+
+While creating experiments/simulations/missions, you have the option to assign authors to each one. Additionally, after successfully creating the publication, you can click on "Add (Experiment/Simulation/Mission)" on the Curation Directory page and then edit the authors and their order within the corresponding experiment/simulation/mission found in the inventory list.
+
+///
+/// details | How can I control the order of the authors for the published project and its citation?
+
+In the publication pipeline under "Order Authors" you will be able to arrange the order of authors for each publication using the arrow icons on the screen. This author order will be used in the citation that includes the DOI.
+
+///
+/// details | How can I give credit to DesignSafe?
+
+Please include the citation of the marker paper in the references/bibliography section of your publication. This is more effective than you providing in-text acknowledgements.
 
 > Rathje, E., Dawson, C. Padgett, J.E., Pinelli, J.-P., Stanzione, D., Adair, A., Arduino, P., Brandenberg, S.J., Cockerill, T., Dey, C., Esteva, M., Haan, Jr., F.L., Hanlon, M., Kareem, A., Lowes, L., Mock, S., and Mosqueda, G. 2017. "DesignSafe: A New Cyberinfrastructure for Natural Hazards Engineering," ASCE Natural Hazards Review, doi:10.1061/(ASCE)NH.1527-6996.0000246.
 
-### Data Reuse { #datareuse }
+///
 
-**Q: How can I contribute to the reuse of data?**  
-**A**: Datasets take a lot of work to produce; they are important research products. By creating a complete, clean, and clearly described data publication you are already inviting others to use and cite your data. Always cite your datasets and those of others that you have reused in the reference section of your papers using the citation language and DOI provided on DesignSafe, and encourage your peers and students to do the same. If you use social media or a presentation platform to talk about your research, always include the proper citation and DOI on your materials (ppts, abstracts, emails, etc.). Note that a researcher does not actually need to reuse a dataset to cite it, but rather may cite a dataset to reference something of note in the dataset (e.g., how it was collected, its uniqueness, etc.). This is similar to the process of citing other papers.
+## Data Reuse { #datareuse }
 
-**Q: How do I cite a dataset in a paper?**  
-**A**: A dataset is cited using the same format used to cite a journal article or a conference proceeding in the reference section of a paper. Conveniently, you should use the citation language and DOI provided by DesignSafe in the data publication’s landing page.
+/// details | How can I contribute to the reuse of data?
 
-**Q: I reuse data from other sources in my project. How should I credit the data creators in my publication?**  
-**A**: Frequently you reuse data from other sources in your research and sometimes you even want to re-publish it; it is important to make sure if and how you can do so. In addition, it is always good practice to give credit to the data creators. Please be aware of the following:
+Datasets take a lot of work to produce; they are important research products. By creating a complete, clean, and clearly described data publication you are already inviting others to use and cite your data. Always cite your datasets and those of others that you have reused in the reference section of your papers using the citation language and DOI provided on DesignSafe, and encourage your peers and students to do the same. If you use social media or a presentation platform to talk about your research, always include the proper citation and DOI on your materials (ppts, abstracts, emails, etc.). Note that a researcher does not actually need to reuse a dataset to cite it, but rather may cite a dataset to reference something of note in the dataset (e.g., how it was collected, its uniqueness, etc.). This is similar to the process of citing other papers.
 
-1. Be aware of the reused data original license and conditions of usage. The license will specify if and how you can modify, distribute, and cite the reused data.
+///
+/// details | How do I cite a dataset in a paper?
 
-1. If permitted you may also republish the reused data. This is feasible when the reused dataset is not very large. Else see 3 below.
+A dataset is cited using the same format used to cite a journal article or a conference proceeding in the reference section of a paper. Conveniently, you should use the citation language and DOI provided by DesignSafe in the data publication’s landing page.
 
-1. If you reuse data from other sources in your experiments or in your field research, you can point to it from the Referenced Data Title box so others can know about its provenance.
+///
+/// details | I reuse data from other sources in my project. How should I credit the data creators in my publication?
 
+Frequently you reuse data from other sources in your research and sometimes you even want to re-publish it; it is important to make sure if and how you can do so. In addition, it is always good practice to give credit to the data creators. Please be aware of the following:
+
+1. Be aware of the reused data original license and conditions of usage. The license will specify if and how you can modify, distribute, and cite the reused data.
+1. If permitted you may also republish the reused data. This is feasible when the reused dataset is not very large. Else see 3 below.
+1. If you reuse data from other sources in your experiments or in your field research, you can point to it from the Referenced Data Title box so others can know about its provenance.
 1. In projects type Other, you can point to the reused data from the Related Work box.
+1. If you have reused images from other sources (online, databases, publications, etc.), be aware that they may have copyrights. We recommend citing them according to [UBC Library Research Guides](https://guides.library.ubc.ca){target="_blank"}.
 
-1. If you have reused images from other sources (online, databases, publications, etc.), be aware that they may have copyrights. We recommend using the following instructions for how to cite them:
+///
+/// details | Are there any conditions regarding the usage of data published in DesignSafe?
 
-	[https://guides.library.ubc.ca](https://guides.library.ubc.ca){target="_blank"}
+Yes, users that download and reuse data agree to the [Data Usage Agreement](/user-guide/curating/policies/#data-usage-agreement). Those conditions outline the responsibilities of and expectations for data usage including aspects of data licensing, citation, privacy and confidentiality, and data quality.
 
-**Q: Are there any conditions regarding the usage of data published in DesignSafe?**
-**A**: Yes, users that download and reuse data agree to the Data Usage conditions published here: These conditions outline the responsibilities of and expectations for data usage including aspects of data licensing, citation, privacy and confidentiality, and data quality. 
+///
diff --git a/user-guide/docs/curating/guides.md b/user-guide/docs/curating/guides.md
index a224fd78..2017ad98 100644
--- a/user-guide/docs/curating/guides.md
+++ b/user-guide/docs/curating/guides.md
@@ -1,18 +1,17 @@
-## Guides
+# How to Curate Data?
 
-Below are step-by-step guides on how to create projects in the Data Depot, and curate and publish work/data across DesignSafe. We offer the following project types when publishing: Experimental, Simulation, Hybrid Simulation, Field Research, and Other. More information on Data Depot policies, project types, and curation/publication can be found at:
+We offer step-by-step guides on how to create projects in the Data Depot, and curate and publish work/data across DesignSafe: [**Experimental**](#experimental), [**Simulation**](#simulation), [<del>**Hybrid Simulation**<del>](#hybrid), [**Field Research**](#fieldresearch), [**Other**](#other). For more information: [Policies](/user-guide/curating/policies), [Best Practices](/user-guide/curating/bestpractices/), [Frequently Asked Questions](/user-guide/curating/faq/).
 
-* <a href="#policies">Data Depot Repository (DDR) Policies</a></li>
-* <a href="#best-practices/">Best Practices</a></li>
-* <a href="#curation-publication-faq">Curation &amp; Publication FAQs</a>.</li>
+## Experimental
 
-### Experimental
+!!! important "Not Up to Date"
+    Anticipate a different user interface and experience.
 
-#### 1. Add a Project { #experimental-step1 }
+### 1. Add a Project { #experimental-step1 }
 
 You can start a project at the very beginning of its lifespan, upload and curate data incrementally, then publish sets of data at your convenience.
 
-To add a new project, click <strong>+ Add</strong>, then select <strong>New Project</strong>.
+To add a new project, click **+ Add**, then select **New Project**.
 
 ![](./imgs/guide-allguides-1a.jpg)
 
@@ -24,15 +23,15 @@ PIs and project members have the same level of access to the project, but the PI
 
 You can edit all these fields later if you make any mistakes.
 
-Once finished, click <strong>+</strong> <strong>Add Project</strong> and you will be taken to your new project in the My Projects tab.
+Once finished, click **+ Add Project** and you will be taken to your new project in the My Projects tab.
 
-#### 2. Add an Experiment { #step2 }
+### 2. Add an Experiment { #step2 }
 
-To begin curation and add an experiment, click on the <strong>Curation Directory</strong> and select <strong>Experimental</strong> as your Project Type.
+To begin curation and add an experiment, click on the **Curation Directory** and select **Experimental** as your Project Type.
 
 ![](./imgs/guide-experimental-2a.png)
 
-Go through the overview and fill out additional required fields in the <strong>Edit Project</strong> window, click <strong>Update Project, </strong>then click <strong>Add Experiments</strong>.
+Go through the overview and fill out additional required fields in the **Edit Project** window, click **Update Project**, then click **Add Experiments**.
 
 Adding an experiment involves filling out high level information about the files you will be publishing. Each experiment will receive its own DOI. Add multiple experiments if any of this information changes or you want multiple DOIs. Do not add another experiment if you are testing multiple models and this information stays the same. Instead, you can add multiple models to one experiment.
 
@@ -42,33 +41,45 @@ Fill out the required and optional fields using the advice given to create conci
 
 Also, assign authorship from a list of the project members and PIs. You can order the authors later when it is time to publish.
 
-Click <strong>+</strong> <strong>Add Experiment</strong> when you are done and it will appear below in your inventory.
+Click **+ Add Experiment** when you are done and it will appear below in your inventory.
 
 You can edit an experiment from the inventory.
 
-#### 3. Add Categories { #step3 }
+### 3. Add Categories { #step3 }
 
-Click <strong>Add Categories</strong> to begin.
+Click **Add Categories** to begin.
 
 ![](./imgs/guide-experimental-3.png)
 
 Categories group files together based on a shared purpose in an experiment. Be sure and read the definitions of each category to understand what files belong to each.
 
-<span style="color: #145ec2;"><strong>Model Configuration</strong></span> Files describing the design and layout of what is being tested (some call this a specimen).
+<style id="step3-style">
+#step3 ~ dl dt:nth-of-type(1) { color: #145ec2; }
+#step3 ~ dl dt:nth-of-type(2) { color: #3b9b92; }
+#step3 ~ dl dt:nth-of-type(3) { color: #ac8804; }
+#step3 ~ dl dt:nth-of-type(4) { color: #4cb8db; }
+</style>
 
-<strong><span style="color: #3b9b92;">Sensor Information</span></strong> Files about the sensor instrumentation used in a model configuration to conduct one or more event.
+Model Configuration
+:   Files describing the design and layout of what is being tested (some call this a specimen).
 
-<span style="color: #ac8804;"><strong>Event</strong></span> Files from unique occurrences during which data are generated.
+Sensor Information
+:   Files about the sensor instrumentation used in a model configuration to conduct one or more event.
 
-<strong><span style="color: #4cb8db;">Analysis</span></strong> Tables, graphs, visualizations, Jupyter Notebooks, or other representations of the results.
+Event
+:   Files from unique occurrences during which data are generated.
 
-<strong>Report</strong> Written accounts made to convey information about an entire project or experiment.
+Analysis
+:   Tables, graphs, visualizations, Jupyter Notebooks, or other representations of the results.
 
-After filling out the fields, click <strong>+ Add Category</strong> and it will appear below in your inventory. If you make any mistakes, expand the category and click <strong>Edit</strong>.
+Report
+:   Written accounts made to convey information about an entire project or experiment.
 
-#### 4. Relate Data { #step4 }
+After filling out the fields, click **+ Add Category** and it will appear below in your inventory. If you make any mistakes, expand the category and click **Edit**.
 
-Click <strong>Relate Data</strong> to begin.
+### 4. Relate Data { #step4 }
+
+Click **Relate Data** to begin.
 
 ![](./imgs/guide-experimental-4.png)
 
@@ -76,21 +87,21 @@ Relating Data allows you to relate categories to each other and to an experiment
 
 When published, this diagram will help others understand the structure of your experiment at a glance.
 
-#### 5. Assign Categories to Files { #step5 }
+### 5. Assign Categories to Files { #step5 }
 
 ![](./imgs/guide-experimental-5a.png)
 
-As you create categories, they will appear in a dropdown by each file. This allows you to group files in each category. Click <strong>Save</strong> to confirm the category.
+As you create categories, they will appear in a dropdown by each file. This allows you to group files in each category. Click **Save** to confirm the category.
 
 If you categorize a folder, then all files within that folder will belong to the category of the folder. <br>
 <br>
 A file can belong to one or more categories.
 
-Click <strong>Remove</strong> if you make any mistakes.
+Click **Remove** if you make any mistakes.
 
 ![](./imgs/guide-experimental-5b.png)
 
-#### 6. Tag Files { #step6 }
+### 6. Tag Files { #step6 }
 
 ![](./imgs/guide-experimental-6.png)
 
@@ -100,9 +111,9 @@ The natural hazards community has contributed to creating these agreed upon term
 
 These tags are optional, but recommended.
 
-If you do not see a file tag that fits, you can select <strong>Other</strong> and write in your own.
+If you do not see a file tag that fits, you can select **Other** and write in your own.
 
-#### 7. Publication Preview { #step7 }
+### 7. Publication Preview { #step7 }
 
 ![](./imgs/guide-experimental-7a.png)
 
@@ -112,7 +123,7 @@ All of the curation work is done in the Curation Directory, while the Publicatio
 
 Look through the Publication Preview early and often to catch any mistakes. If you are working collaboratively with others, this is a good way to proofread changes they make.
 
-#### 8. Prepare to Publish { #step8 }
+### 8. Prepare to Publish { #step8 }
 
 When you are satisfied with how your work is curated and wish to publish it, select Prepare to Publish in the Publication Preview.
 
@@ -121,27 +132,30 @@ When you are satisfied with how your work is curated and wish to publish it, sel
 There are 6 stages in the publication process: <br>
 Selection, Proofread Project, Proofread Experiment, Proofread Categories, Order Authors, and Licenses
 
-In <strong>Selection</strong>, select which experiment you want to publish. You can only publish one at a time.
+In **Selection**, select which experiment you want to publish. You can only publish one at a time.
 
-In <strong>Proofread Project</strong>,<strong> Experiment</strong>,<strong> &amp; Categories</strong>, take time to proofread all the descriptions and metadata you have entered. You cannot make changes after publishing.
+In **Proofread Project**, **Experiment**, & **Categories**, take time to proofread all the descriptions and metadata you have entered. You cannot make changes after publishing.
 
-In <strong>Order Authors</strong>, order the authors of the experiment and preview how your citation will appear.
+In **Order Authors**, order the authors of the experiment and preview how your citation will appear.
 
-In <strong>Licenses</strong>, select one or more licenses that best fit your data.
+In **Licenses**, select one or more licenses that best fit your data.
 
-Finally, click <strong>Request DOI &amp; Publish</strong> and agree to the agreement to publish your work.
+Finally, click **Request DOI & Publish** and agree to the agreement to publish your work.
 
 ---
 
-### Simulation { #simulation }
+## Simulation
+
+!!! important "Not Up to Date"
+    Anticipate a different user interface and experience.
 
-Read the [Simulation Data Best Practices Guide](../../curating#bestpractices-simulationdata) prior to initiating your project.
+Read the [Simulation Data Best Practices Guide](/user-guide/curating/bestpractices) prior to initiating your project.
 
-#### 1. Add a Project { #simulation-step1 }
+### 1. Add a Project { #simulation-step1 }
 
 You can start a project at the very beginning of its lifespan, upload and curate data incrementally, then publish sets of data at your convenience.
 
-To add a new project, click <strong>+ Add</strong>, then select <strong>New Project</strong>.
+To add a new project, click **+ Add**, then select **New Project**.
 
 ![](./imgs/guide-allguides-1a.jpg)
 
@@ -153,15 +167,15 @@ You can edit all these fields later if you make any mistakes.
 
 ![](./imgs/guide-allguides-1b.png)
 
-Once finished, click <strong>+</strong> <strong>Add Project</strong> and you will be taken to your new project in the My Projects tab.
+Once finished, click **+ Add Project** and you will be taken to your new project in the My Projects tab.
 
-#### 2. Add a Simulation { #simulation-step2 }
+### 2. Add a Simulation { #simulation-step2 }
 
-To begin curation and add a simulation, click on the <strong>Curation Directory</strong> and select <b>Simulation</b> as your Project Type.
+To begin curation and add a simulation, click on the **Curation Directory** and select _Simulation_ as your Project Type.
 
 ![](./imgs/guide-simulation-2a.png)
 
-Go through the overview and fill out additional required fields in the <strong>Edit Project</strong> window, click <strong>Update Project, </strong>then click <strong>Add Simulations</strong>.
+Go through the overview and fill out additional required fields in the **Edit Project** window, click **Update Project,** then click **Add Simulations**.
 
 Adding a simulation involves filling out high level information about the files you will be publishing. Each simulation will receive its own DOI. Add multiple simulations if any of this information changes or you want multiple DOIs. Do not add another simulation if you are testing multiple models and this information stays the same. Instead, you can add multiple models to one simulation.
 
@@ -171,34 +185,46 @@ Fill out the required and optional fields using the advice given to create conci
 
 Also, assign authorship from a list of the project members and PIs. You can order the authors later when it is time to publish.
 
-Click <strong>+</strong> <strong>Add Simulation</strong> when you are done and it will appear below in your inventory.
+Click **+ Add Simulation** when you are done and it will appear below in your inventory.
 
 You can edit a simulation from the inventory.
 
-#### 3. Add Categories { #simulation-step3 }
+### 3. Add Categories { #simulation-step3 }
 
-Click <strong>Add Categories</strong> to begin.
+Click **Add Categories** to begin.
 
 Categories group files together based on a shared purpose in a simulation. Be sure and read the definitions of each category to understand what files belong to each.
 
 ![](./imgs/guide-simulation-3.png)
 
-<span style="color: #145ec2;"><strong>Simulation Model</strong></span> Files and/or information describing the design, geometry, and/or code of a simulation.
+<style id="simulation-step3-style">
+#simulation-step3 ~ dl dt:nth-of-type(1) { color: #145ec2; }
+#simulation-step3 ~ dl dt:nth-of-type(2) { color: #3b9b92; }
+#simulation-step3 ~ dl dt:nth-of-type(3) { color: #ac8804; }
+#simulation-step3 ~ dl dt:nth-of-type(4) { color: #4cb8db; }
+</style>
+
+Simulation Model
+:   Files and/or information describing the design, geometry, and/or code of a simulation.
 
-<strong><span style="color: #3b9b92;">Simulation Input</span></strong> Files containing the parameters of the simulation.
+Simulation Input
+:   Files containing the parameters of the simulation.
 
-<font color="#ac8804"><b>Simulation Output</b></font> Files containing the results of a simulation.
+Simulation Output
+:   Files containing the results of a simulation.
 
-<strong><span style="color: #4cb8db;">Analysis</span></strong> Tables, graphs, visualizations, Jupyter Notebooks, or other representations of the results.
+Analysis
+:   Tables, graphs, visualizations, Jupyter Notebooks, or other representations of the results.
 
-<strong>Report</strong> Written accounts made to convey information about an entire project or simulation.
+Report
+:   Written accounts made to convey information about an entire project or simulation.
 
-After filling out the fields, click <strong>+ Add Category</strong> and it will appear below in your inventory. If you make any mistakes, expand the category and click <strong>Edit</strong>.
+After filling out the fields, click **+ Add Category** and it will appear below in your inventory. If you make any mistakes, expand the category and click **Edit**.
 
-#### 4. Relate Data { #simulation-step4 }
+### 4. Relate Data { #simulation-step4 }
 
 
-Click <strong>Relate Data</strong> to begin.
+Click **Relate Data** to begin.
 
 Relating Data allows you to relate categories to each other and to an simulation, which determines the layout and order of categories in your publication. You can reorder the categories if needed.
 
@@ -206,9 +232,9 @@ Relating Data allows you to relate categories to each other and to an simulation
 
 When published, this diagram will help others understand the structure of your simulation at a glance.
 
-#### 5. Assign Categories to Files { #simulation-step5 }
+### 5. Assign Categories to Files { #simulation-step5 }
 
-As you create categories, they will appear in a dropdown by each file. This allows you to group files in each category. Click <strong>Save</strong> to confirm the category.
+As you create categories, they will appear in a dropdown by each file. This allows you to group files in each category. Click **Save** to confirm the category.
 
 ![](./imgs/guide-simulation-5.png)
 
@@ -216,9 +242,9 @@ If you categorize a folder, then all files within that folder will belong to the
 <br>
 A file can belong to one or more categories.
 
-Click <strong>Remove</strong> if you make any mistakes.
+Click **Remove** if you make any mistakes.
 
-#### 6. Tag Files { #simulation-step6 }
+### 6. Tag Files { #simulation-step6 }
 
 After putting files in categories, dropdowns will appear to allow you to tag specific files.
 
@@ -228,9 +254,9 @@ The natural hazards community has contributed to creating these agreed upon term
 
 These tags are optional, but recommended.
 
-If you do not see a file tag that fits, you can select <strong>Other</strong> and write in your own.
+If you do not see a file tag that fits, you can select **Other** and write in your own.
 
-#### 7. Publication Preview { #simulation-step7 }
+### 7. Publication Preview { #simulation-step7 }
 
 All of the curation work is done in the Curation Directory, while the Publication Preview lets you examine the layout of your publication to give you a peace of mind about how your work will appear to other researchers once published.
 
@@ -240,7 +266,7 @@ Look through the Publication Preview early and often to catch any mistakes. If y
 
 ![](./imgs/guide-simulation-7b.png)
 
-#### 8. Prepare to Publish { #simulation-step8 }
+### 8. Prepare to Publish { #simulation-step8 }
 
 ![](./imgs/guide-simulation-8a.png)
 
@@ -251,35 +277,37 @@ When you are satisfied with how your work is curated and wish to publish it, sel
 There are 6 stages in the publication process: <br>
 Selection, Proofread Project, Proofread Simulation, Proofread Categories, Order Authors, and Licenses
 
-In <strong>Selection</strong>, select which simulation you want to publish. You can only publish one at a time.
+In **Selection**, select which simulation you want to publish. You can only publish one at a time.
 
-In <strong>Proofread Project</strong>,<strong> Simulation</strong>,<strong> &amp; Categories</strong>, take time to proofread all the descriptions and metadata you have entered. You cannot make changes after publishing.
+In **Proofread Project**, **Simulation**, & **Categories**, take time to proofread all the descriptions and metadata you have entered. You cannot make changes after publishing.
 
-In <strong>Order Authors</strong>, order the authors of the simulation and preview how your citation will appear.
+In **Order Authors**, order the authors of the simulation and preview how your citation will appear.
 
-In <strong>Licenses</strong>, select one or more licenses that best fit your data.
+In **Licenses**, select one or more licenses that best fit your data.
 
-Finally, click <strong>Request DOI &amp; Publish</strong> and agree to the agreement to publish your work.
+Finally, click **Request DOI & Publish** and agree to the agreement to publish your work.
 
 ---
 
-### Hybrid Simulation { #hybrid }
+## Hybrid Simulation { #hybrid }
 
-<b>Hybrid Simulation User Guide in progress.</b>
+!!! important "Not Yet Written"
+    If you need help, please [create a ticket](https://designsafe-ci.org/help){ target="_blank" } or contact us during our [virtual office hours](https://www.designsafe-ci.org/facilities/virtual-office-hours/).
 
 ---
 
-### Field Research { #fieldresearch }
+## Field Research { #fieldresearch }
 
-<b><i>Field Research User Guide is in progress.</i></b>
+!!! important "Not Up to Date"
+    Anticipate a different user interface and experience.
 
-#### 1. Add a Project { #fieldresearch-step1 }
+### 1. Add a Project { #fieldresearch-step1 }
 
 ![](./imgs/guide-allguides-1a.jpg)
 
 You can start a project at the very beginning of its lifespan, upload and curate data incrementally, then publish sets of data at your convenience.
 
-To add a new project, click <strong>+ Add</strong>, then select <strong>New Project</strong>.
+To add a new project, click **+ Add**, then select **New Project**.
 
 ![](./imgs/guide-allguides-1b.png)
 
@@ -289,15 +317,15 @@ PIs and project members have the same level of access to the project, but the PI
 
 You can edit all these fields later.
 
-Once finished, click <strong>+</strong> <strong>Add Project</strong> and you will be taken to your new project in the My Projects tab.
+Once finished, click **+ Add Project** and you will be taken to your new project in the My Projects tab.
 
-#### 2. Add a Mission { #fieldresearch-step2 }
+### 2. Add a Mission { #fieldresearch-step2 }
 
-To begin curation, click on the <strong>Curation Directory</strong> and select <strong>Field Research</strong> as your Project Type.
+To begin curation, click on the **Curation Directory** and select **Field Research** as your Project Type.
 
 Please, read the overview, it has information that will clarify and guide you through the curation process.
 
-Fill out required fields in the <strong>Edit Project </strong>window. Without this information your project will not be published. Click <strong>Update Project, </strong>then click <strong>Add Missions</strong>.
+Fill out required fields in the **Edit Project** window. Without this information your project will not be published. Click **Update Project**, then click **Add Missions**.
 
 
 ![](./imgs/guide-fieldresearch-2a.jpg)
@@ -313,40 +341,33 @@ Each mission will receive a unique DOI. Add multiple missions if any of this hig
 
 Fill out the required and optional fields using the advice given to create concise and understandable descriptions. You can order the authors later when it is time to publish.
 
-Click <strong>+</strong> <strong>Add Mission</strong> when you are done and it will appear below in your inventory.
+Click **+ Add Mission** when you are done and it will appear below in your inventory.
 
 You can edit a mission from the mission inventory.
 
-<a name="step4d"> </a>
+### 3. Add Collections { #fieldresearch-step3 }
 
-#### 3. Add Collections { #fieldresearch-step3 }
-
-Click <strong>Add Collections</strong> to begin.
+Click **Add Collections** to begin.
 
 Collections group files together based on a shared purpose in a mission. There are three different collection types in field research data model:
 
-<u>Research Planning Collection:</u>
-
-A group of files related to planning and logistics, study design and administration, design, Institutional Review Board (IRB) procedures, or permits.
+Research Planning Collection
+:   A group of files related to planning and logistics, study design and administration, design, Institutional Review Board (IRB) procedures, or permits.
 
-<u>Engineering/Geosciences Collection:</u>
+Engineering/Geosciences Collection
+:   A group of related data and associated materials from the engineering/geosciences domain.
 
-A group of related data and associated materials from the engineering/geosciences domain.
-
-<u>Social Sciences Collection:</u>
-
-A group of related data and associated materials from the social sciences domain.
-
-When defining a collection, there are several information that are required to be filled for curation and publication purposes such as collection title, observation type, data of collection, data collector, collection site location, the instrument and a summarized description.
-
-After filling out the fields, click <strong>+ Add Collection</strong> and it will appear below in your collection inventory. If you make any mistakes, expand the category and click <strong>Edit</strong>.
+Social Sciences Collection
+:   A group of related data and associated materials from the social sciences domain.
+:   When defining a collection, there are several information that are required to be filled for curation and publication purposes such as collection title, observation type, data of collection, data collector, collection site location, the instrument and a summarized description.
+:   After filling out the fields, click **+ Add Collection** and it will appear below in your collection inventory. If you make any mistakes, expand the category and click **Edit**.
 
 ![](./imgs/guide-fieldresearch-3.png)
 
 
-#### 4. Relate Data { #fieldresearch-step4 }
+### 4. Relate Data { #fieldresearch-step4 }
 
-Click <strong>Relate Data</strong> to begin.
+Click **Relate Data** to begin.
 
 Relating Data allows you to relate collections to missions, which determines the organization of your dataset. You can also establish the order of your collections.
 
@@ -356,15 +377,15 @@ When published, this diagram will help others understand the structure of your F
 
 ![](./imgs/guide-fieldresearch-4.png)
 
-#### 5. Assign Collections to Files { #fieldresearch-step5 }
+### 5. Assign Collections to Files { #fieldresearch-step5 }
 
-As you create collections, they will appear in a dropdown next to each file. This allows you select collections for any file in your project and group them under each collection. Click <strong>Save</strong> to confirm the collection.
+As you create collections, they will appear in a dropdown next to each file. This allows you select collections for any file in your project and group them under each collection. Click **Save** to confirm the collection.
 
 If you assigned a collection to a folder, then all files within that folder will belong to the collection of the folder.
 
 A file can belong to one or more collections.
 
-Click <strong>Remove</strong> if you make any mistakes.
+Click **Remove** if you make any mistakes.
 
 
 ![](./imgs/guide-fieldresearch-5a.jpg)
@@ -373,7 +394,7 @@ Click <strong>Remove</strong> if you make any mistakes.
 ![](./imgs/guide-fieldresearch-5b.png)
 
 
-#### 6. Tag Files { #fieldresearch-step6 }
+### 6. Tag Files { #fieldresearch-step6 }
 
 After putting files in collections, dropdowns will appear to allow you to tag/describe unique files.
 
@@ -381,13 +402,13 @@ The natural hazards community has contributed to creating these agreed upon term
 
 These tags are optional, but recommended.
 
-If you do not see a file tag that fits, you can select <strong>Other</strong> and write in your own descriptive tag.
+If you do not see a file tag that fits, you can select **Other** and write in your own descriptive tag.
 
 
 ![](./imgs/guide-fieldresearch-6.png)
 
 
-#### 7. Publication Preview { #fieldresearch-step7 }
+### 7. Publication Preview { #fieldresearch-step7 }
 
 All of the curation work is done in the Curation Directory. The Publication Preview lets you examine the layout of your publication so you can visualize/verify how your work will appear once published.
 
@@ -400,34 +421,37 @@ Look through the Publication Preview early and often to make changes or catch mi
 ![](./imgs/guide-fieldresearch-7b.png)
 
 
-#### 8. Prepare to Publish { #fieldresearch-step8 }
+### 8. Prepare to Publish { #fieldresearch-step8 }
 
 When you are satisfied with how your work is curated and wish to publish it, select Prepare to Publish in the Publication Preview.
 
 There are 6 stages in the publication process:   
 Selection, Proofread Project, Proofread Mission, Proofread Collections, Order Authors, and Licenses
 
-In <strong>Selection</strong>, select which mission you want to publish. At this time, you can only publish one mission at a time.
+In **Selection**, select which mission you want to publish. At this time, you can only publish one mission at a time.
 
-In <strong>Proofread Project</strong>,<strong> Missions</strong>,<strong> &amp; Collections</strong>, take time to read all the descriptions and metadata you have entered. You will not be able to make changes after publishing.
+In **Proofread Project**, **Missions**, & **Collections**, take time to read all the descriptions and metadata you have entered. You will not be able to make changes after publishing.
 
-In <strong>Order Authors</strong>, order the authors of the mission and preview how your citation will appear.
+In **Order Authors**, order the authors of the mission and preview how your citation will appear.
 
-In <strong>Licenses</strong>, select one or more licenses that best fit your data.
+In **Licenses**, select one or more licenses that best fit your data.
 
-Please see the <a href="#best-practices">Data Publication Guidelines</a> for more information.
+Please see the [Data Publication Guidelines](/user-guide/curating/bestpractices) for more information.
 
-Finally, click <strong>Request DOI &amp; Publish</strong> and agree to the agreement to publish your work.
+Finally, click **Request DOI & Publish** and agree to the agreement to publish your work.
 
 ![](./imgs/guide-fieldresearch-8.jpg)
 
 ---
 
-### Other
+## Other
+
+!!! important "Not Up to Date"
+    Anticipate a different user interface and experience.
 
-#### 1. Add a Project { #other-step1 }
+### 1. Add a Project { #other-step1 }
 
-To add a new project, click <strong>+ Add</strong>, then select <strong>New Project</strong>.
+To add a new project, click **+ Add**, then select **New Project**.
 
 ![](./imgs/guide-allguides-1a.jpg)
 
@@ -439,19 +463,19 @@ PIs and project members have the same level of access to the project, but the PI
 
 You can edit all these fields later if you make any mistakes.
 
-Once finished, click <strong>+</strong> <strong>Add Project</strong> and you will be taken to your new project in the My Projects tab.
+Once finished, click **+ Add Project** and you will be taken to your new project in the My Projects tab.
 
-#### 2. Begin Curation { #other-step2 }
+### 2. Begin Curation { #other-step2 }
 
-To begin curating and tagging your files, click on the <strong>Curation Directory</strong> and select <b>Other</b> as your Project Type.
+To begin curating and tagging your files, click on the **Curation Directory** and select _Other_ as your Project Type.
 
 ![](./imgs/guide-other-step2a.png)
 
-Fill out additional required fields in the <strong>Edit Project</strong> window, including a Data Type, then click <strong>Update Project </strong>and you will be brought to the <strong>Curation Directory. </strong>
+Fill out additional required fields in the **Edit Project** window, including a Data Type, then click **Update Project** and you will be brought to the **Curation Directory.**
 
 ![](./imgs/guide-other-step2b.png)
 
-#### 3. Tag Files { #other-step3 }
+### 3. Tag Files { #other-step3 }
 
 Dropdowns will appear by each file to allow you to tag specific files.
 
@@ -459,9 +483,9 @@ Dropdowns will appear by each file to allow you to tag specific files.
 
 These tags are optional, but recommended. The help other users understand your data and discover it in searches.
 
-If you do not see a file tag that fits, you can select <strong>Other</strong> and write in your own.
+If you do not see a file tag that fits, you can select **Other** and write in your own.
 
-#### 4. Prepare to Publish { #other-step4 }
+### 4. Prepare to Publish { #other-step4 }
 
 When you are satisfied with your work and wish to publish it and recieve a DOI, click Prepare to Publish in the Publication Preview.
 
@@ -473,13 +497,13 @@ Selection, Proofread Project, Proofread Data, Order Authors, and Licenses
 
 ![](https://www.designsafe-ci.org/media/filer_public_thumbnails/filer_public/d5/cb/d5cb572c-4546-4988-8441-f03691dacd81/82_licenses.png__418x410_q85_subsampling-2.png)
 
-In <strong>Selection</strong>, select which files you want to publish.
+In **Selection**, select which files you want to publish.
 
-In <strong>Proofread Project</strong> <strong>&amp; Data</strong>, take time to proofread all the metadata and tags you have entered. You cannot make changes after publishing.
+In **Proofread Project**, & **Data**, take time to proofread all the metadata and tags you have entered. You cannot make changes after publishing.
 
-In <strong>Order Authors</strong>, order the authors of the publication and preview how your citation will appear.
+In **Order Authors**, order the authors of the publication and preview how your citation will appear.
 
-In <strong>Licenses</strong>, select one or more licenses that best fit your data.
+In **Licenses**, select one or more licenses that best fit your data.
 
-Finally, click <strong>Request DOI &amp; Publish</strong> and agree to the agreement to publish your work.
+Finally, click **Request DOI & Publish** and agree to the agreement to publish your work.
 
diff --git a/user-guide/docs/curating/metrics.md b/user-guide/docs/curating/metrics.md
index 3ec4001a..27ad0285 100644
--- a/user-guide/docs/curating/metrics.md
+++ b/user-guide/docs/curating/metrics.md
@@ -1,56 +1,51 @@
-## Metrics
+# Data Dissemination and Impact
 
-### Data Metrics { #data }
+Data metrics indicate research impact, allowing researchers to assess the repercussions and influence of their work. Citation and usage metrics are included, and are visible on the landing page of each dataset publication. 
 
-Data metrics are research impact indicators complementary to other forms of evaluation such as number of paper citations, allowing researchers to assess the repercussions and influence of their work.
+Except for projects categorized as “Other,” a project can encompass more than one dataset publication in the Data Depot Repository (DDR). Different creators may produce projects at different times, and have different DOIs. We report metrics per published dataset with a DOI. 
 
-Metrics available in DesignSafe follow the Make your Data Count  <a href="https://www.projectcounter.org/code-practice-research-data/" target="_blank">Counter Code of Practice for Research Data.</a> This is a community standard to count data usage transparently and in a normalized way. For more information about this approach please visit <a href="https://makedatacount.org/data-metrics-2/" target="_blank">Make your Data Count Metrics</a>.
+## Data Usage Metrics
 
-In Natural Hazards, a research project can encompass more than one data publication which can be produced at different times by different creators and have different DOIs. In DesignSafe, project types are: Other, Experimental, Simulation, Hybrid Simulation, and Field Research. In turn, each has different data publications. Project type "Other" only has one data publication and DOI, while the rest may have more than one data publication and therefore multiple DOIs per project.
+Usage metrics published in the DDR follow the Make Data Count (MDC) [Counter Code of Practice for Research Data](https://www.projectcounter.org/code-practice-research-data/). This is a community standard to count data usage transparently and in a normalized way. (For more information about this approach please visit [Make Data Count Metrics](https://makedatacount.org/learn-about-us/#section-1).) Towards normalization, a session is an important concept to understand.
 
-<strong>Data Publications:</strong>
+Session: All data usage activity during one clock hour from a single IP address and user-agent (a string that identifies the user's browser and operating system.). This is used as a proxy for distinct users to count unique requests and unique investigations.
 
-Experiment (in Experimental projects)
+Descriptions of each usage metric reported by DDR are below.
 
-Mission and Document collection (in Field Research projects)
+- **File Preview**: Examining data from an individual data publication (clicking on a file name, for example) brings up a modal window that previews the files. Those file previews are counted. However, not all document types can be previewed. Text files, spreadsheets, graphics, and code files can be previewed (e.g. .txt, .doc, .docx, .csv, .xlsx, .pdf, .jpg, .m, .ipynb). Binary executables, MATLAB containers, compressed files, and video files cannot be previewed (eg. .bin, .mat, .zip, .tar, mp4, .mov). Only previewable files are counted. Users will see a count of all the files that have been previewed in the data publication.
+- **File Download**: Copying a file to the user’s machine, or to a storage device that the machine has access to. This can be done by ticking the checkbox next to a file and selecting "Download" at the top of the project page. With files that can be previewed, clicking "Download" at the top of the preview modal window has the same effect. Downloads are counted on an individual file basis. We also consider counts when users tick the checkbox next to a file and select "Copy" at the top of the project page. The counts of copying a file from the published project can be to the user's My Data or My Projects to Tools and Applications in the Workspace, or to one of the connected spaces (Box, Dropbox, Google Drive).
+- **Total Requests**: Total file downloads + total file previews. This is counted for each data publication that has a DOI (eg. Simulation, Experiment, Mission, Hybrid simulation , Documents Collection and Project Type Other).
+- **Unique Requests**{#unique-requests}: Sessions in which one or more files are downloaded or previewed. Any downloads, previews, copies of files, or project downloads from a single data publication (DOI) by a user in a single session counts as one Unique Request. This is counted for each data publication with a single DOI including Simulations, Hybrid Simulations, Experiments, Missions, Documents Collection and Project Type Other. 
+- **Unique Investigations**{#unique-investigations}: Sessions in which any project or publications metadata is viewed, or one or more files is downloaded or previewed. Any viewing of metadata as well as any downloads, previews, copies of files, or project downloads from a single data publication (DOI) by a user in a single session counts as one Unique Investigation. This is counted for each data publication with a single DOI including Simulations, Hybrid Simulations, Experiments, Missions, Documents Collection and type Other projects.
 
-Simulation (in Simulation projects)
+Usage metrics are displayed in the citation modal underneath “Download Citation” as “Unique Requests” and “Unique Investigations.” Clicking on “Details” to the right enables a modal window that displays the metrics, including their definitions, in aggregates and per quarter for researchers to assess impact over time. 
 
-Hybrid Simulation (in Hybrid Simulation projects)
+Usage metrics date back to January 2022 and are updated monthly.
 
-Other-type project (these encompass only one data publication and thus one level of metrics).
+## Interpreting Data Metrics
 
-Because of the structure of the research projects in DesignSafe we report metrics at the project and at the data publication levels. Metrics at the project level allow researchers to assess the overall impact of the projects because it aggregates the usage of all the data publications. Instead, data publication metrics provide granular information about the usage of each publication that has a DOI within a project.
+Dataset citations and usage are complementary metrics. The former account for the creation, reference to, or reuse of datasets as demonstrated in a publication. Similarly to web page hits and downloads of resources, the latter represents the attention to particular resources on the web. We aggregate and inform users of citations and datasets on a quarterly basis on the [DesignSafe Impact](https://designsafe-ci.org/use-designsafe/impact/) page. Both aggregated and individual metrics can be considered as they evolve over time and in context with similar data types, hazard types, and discipline. 
 
-Data Metrics is a work in progress and we add measurements on an ongoing basis. We started counting Project Metrics in March 2021 And Data Publication Metrics in January 2022.
+## Citation Metrics
 
-Below are descriptions of each type of metric and what is counted at the project and at the data publication levels.
+Dataset citations are references to a dataset in published materials including journal papers, books and chapters, conference proceedings, and thesis and dissertations. Citation counts per a dataset's DOI varies depending on the source providing the information. The DDR uses the Data [Citation Index from Clarivate](https://clarivate.com/academia-government/scientific-and-academic-research/research-discovery-and-referencing/web-of-science/data-citation-index/) as a source of citations. Clarivate only harvests citations from the reference section of peer-reviewed publications. Google Scholar, on the other hand, harvests citations and mentions from any part of a publication available via the Web. This includes presentations, bulletins, and reports, making it too difficult to automate the count of precise citations.
 
-### Project Metrics { #project }
+Two types of citations are counted: platform citations and dataset citations. 
 
-<strong>File Preview: </strong>Examining data in any data publication within a project such as clicking on a file name brings up a modal window that allows previewing the files. However, not all data types can be previewed. Among those that can are: text, spreadsheets, graphics and code files. (example extensions: .txt, .doc, .docx, .csv, .xlsx, .pdf, .jpg, .m, .ipynb). Those that can't include binary executables, MATLAB containers, compressed files, and video (eg. .bin, .mat, .zip, .tar, mp4, .mov). Only those files that can be previewed are counted. Users will get a count of all the files that have been previewed in the entire project.
+Platform citations are citations to marker papers written about DesignSafe such as:
 
-<strong>File Download: </strong>Copying a file to the machine the user is running on, or to a storage device that the machine has access to. This can be done by ticking the checkbox next to a file and selecting "Download" at the top of the project page. With files that can be previewed, clicking "Download" at the top of the preview modal window has the same effect. Downloads are counted per project. We also consider counts when users tick the checkbox next to a document and select "Copy" at the top of the project page. The counts of copying a file from the published project can be to the user's My data, My projects, to Tools and Applications in the Workspace, or to one of the connected spaces (Box, Dropbox, Google Drive). Users will get a count of all the files that have been downloaded in the entire project.
+Rathje, E., Dawson, C. Padgett, J.E., Pinelli, J.-P., Stanzione, D., Adair, A., Arduino, P., Brandenberg, S.J., Cockerill, T., Dey, C., Esteva, M., Haan, Jr., F.L., Hanlon, M., Kareem, A., Lowes, L., Mock, S., and Mosqueda, G. 2017. “DesignSafe: A New Cyberinfrastructure for Natural Hazards Engineering,” ASCE Natural Hazards Review, doi:10.1061/(ASCE)NH.1527-6996.0000246.
 
-<strong>File Requests: </strong>Total file downloads + total file previews. This is counted and aggregated for all data publications that have a DOI within a project (eg. Simulation, Experiment, Mission, Hybrid simulation and Documents Collection). Users will get a count of all the files that have been requested in the entire project.
+Dataset citation counts appear in the citation modal beneath the Download Citation links. They include citations to original or reused datasets, reports, survey instruments, poster presentations, and meeting proceedings published in the DDR.
 
-<strong>Total Investigations: </strong>File requests + metadata views. Viewing the main project information / metadata in the landing page counts as an investigation of each DOI included in the project. Opening a data publication (eg. simulation, experiment, documents collection, mission, hybrid simulation) counts as one investigation of that specific data publication.Requests and metadata views at the data publication level are counted and aggregated at the project level metrics.
+![](https://lh7-rt.googleusercontent.com/docsz/AD_4nXe-nm1trTn5yB0MQRdu5fMDrQuCYlWpYUqu_-zOOH2XNtdBpPTqCLpdsWthkzJxi-DXAzDO89OjrbrrftCmASAQL2lEPuiGQ3KYjQgyOVEirNjZMXvfEcN7rThIWrtfdpBb4ciiOQ?key=5Dna0b-2yhoGiwcpYmzxUA)
 
-<strong>Project Downloads: </strong>Total downloads of a compressed entire project and its metadata to a user's machine.
+Original citations are from papers in which a researcher cites their own data in the DDR as a part of the original research project, and data reuse is a citation to datasets available in DesignSafe after the original project is over. 
 
-### Data Publication Metrics { #publication }
+Citations are updated through the last month of the prior quarter. 
 
-<strong>File Preview:</strong> Examining data from an individual data publication such as clicking on a file name brings up a modal window that allows previewing files. Those file previews are counted. However, not all document types can be previewed. Among those that can are: text, spreadsheets, graphics and code files. (example extensions: .txt, .doc, .docx, .csv, .xlsx, .pdf, .jpg, .m, .ipynb). Those that can't include binary executables, MATLAB containers, compressed files, and video (eg. .bin, .mat, .zip, .tar, mp4, .mov).  Only those files that can be previewed are counted. Users will get a count of all the files that have been previewed in the data publication.
+## Marketing Datasets
 
-<strong>File Download: </strong>Copying a file to the machine the user is running on, or to a storage device that the machine has access to. This can be done by ticking the checkbox next to a file and selecting "Download" at the top of the project page. With files that can be previewed, clicking "Download" at the top of the preview modal window has the same effect. Downloads are counted per individual files. We also consider counts when users tick the checkbox next to a file and select "Copy" at the top of the project page. The counts of copying a file from the published project can be to the user's My data, My projects, to Tools and Applications in the Workspace, or to one of the connected spaces (Box, Dropbox, Google Drive).
-
-<strong>File Requests: </strong>Total file downloads + total file previews. This is counted for each data publication that has a DOI (eg. Simulation, Experiment, Mission, Hybrid simulation and Documents Collection).
-
-<strong>Session: </strong>All activity during one clock hour from a single IP address and user-agent (a string that identifies the user's browser and operating system.).  This is used as a proxy to define a session to count unique requests and unique investigations.
-
-<strong>Unique Requests: </strong>Any downloads, previews, copies of files, or project downloads from a single data publication (DOI) by a user in a single session counts as 1 Unique Request. This is counted for each data publication with a single DOI including Simulations, Hybrid Simulations, Experiments, Missions, Documents Collection and type Other projects.
-
-<strong>Total Investigations: </strong>File requests + metadata views. Reading the metadata (information about the project and or the data publication) on the landing page counts as an investigation of each data publication with a DOI included in a project. Opening a data publication counts as one investigation of that data publication.
-
-<strong>Unique Investigations: </strong>Any viewing of metadata and any downloads, previews, copies of files or project downloads from a single data publication (DOI) by a user in a single session counts as 1 Unique Investigation. This is counted for each data publication with a single DOI including Simulations, Hybrid Simulations, Experiments, Missions, Documents Collection and type Other projects.
+Datasets take a lot of work to produce; they are important research products. By creating a complete, organized, and clearly described publication in DDR, users are inviting others to reuse and cite their data. Researchers using published data from DDR must cite it using the DOI, which relies on the [DataCite schema](http://schema.datacite.org/) for accurate citation. For convenience, users can retrieve a formatted citation from the published data landing page. It is recommended to insert the citations in the reference section of the paper to facilitate citation tracking and count.
 
+When using social media or any presentation platform to communicate research, it is important to include the proper citation and DOI on the presentations, emails, tweets, professional blog posts, etc.. A researcher does not actually need to reuse a dataset to cite it, but rather may cite it to point/review something about a dataset (e.g., how it was collected, its uniqueness, certain facts, etc.). This is similar to the process of citing other papers within a literary review section.
diff --git a/user-guide/docs/curating/policies.md b/user-guide/docs/curating/policies.md
index 6eb8dd6f..9fba29b7 100644
--- a/user-guide/docs/curating/policies.md
+++ b/user-guide/docs/curating/policies.md
@@ -1,313 +1,545 @@
-## Policies
+# Policies
 
-### DesignSafe Data Depot Repository Mission and History
+## Changes to Policies
 
-#### Mission { #mission }
+Our policies are regularly reviewed and updated as needed. Users will be notified in advance when policies will be updated.
 
-The Data Depot Repository (DDR) is the platform for curation and publication of datasets generated in the course of natural hazards research. The DDR is an <a href="https://www.budapestopenaccessinitiative.org/read">open access</a> data repository that enables data producers to safely store, share, organize, and describe research data, towards permanent publication, distribution and impact evaluation. The DDR allows data consumers to discover, search for, access, and reuse published data in an effort to accelerate research discovery.  The DDR is one component of the <a href="https://www.designsafe-ci.org/about/designsafe/">DesignSafe </a>cyberinfrastructure, which represents a comprehensive research environment that provides cloud-based tools to manage, analyze, understand, and publish critical data for research to understand the impacts of natural hazards.  DesignSafe is part of the NSF-supported Natural Hazards Engineering Research Infrastructure <a href="https://www.designsafe-ci.org/about/">(NHERI)</a>, and aligns with its mission to provide the natural hazards research community with <a href="https://doi.org/10.17603/ds2-4s85-mc54">open access, shared-use scholarship, education, and community resources</a> aimed at supporting civil infrastructure <a href="https://doi.org/10.17603/ds2-1f7x-9a52">prior to, during, and following natural disasters</a>. However, DesignSafe also supports the broader natural hazards research community that extends beyond the NHERI network.
+## Continuity of Access
 
-#### History { #history }
+As an NSF funded project, DesignSafe is subject to renewal every 5 years. As a requirement of the current award, there is a contingency plan to transfer all the DDR data, metadata, and corresponding DOIs to a new awardee - should one be selected - without interruption of services and access to data. The portability plan is confirmed and updated in the Operations Project Execution Plan that we present annually to the NSF.
 
-The DDR has been in operation since 2016 and is currently supported by NSF through 2025.  The DDR preserves natural hazards research data published since its inception in 2016, and also provides access to legacy data dating from about 2005.  These legacy data were generated as part of the NSF-supported Network for Earthquake Engineering Simulation (NEES), a predecessor to NHERI.  Legacy data and metadata belonging to NEES were transferred to the DDR for continuous preservation and access. <a href="https://www.designsafe-ci.org/data/browser/public-legacy/">View the published NEES data here</a>.
+If the NSF and/or other community stakeholders discontinue the NHERI program or a subsequent data repository, we will continue to preserve the published data and provide access through TACC, DesignSafe’s host at the University of Texas at Austin. TACC has formally committed to preserving the data with landing pages and corresponding DOIs indefinitely. TACC’s User Services team and curators will attend to users’ requests and help tickets related to the data. Because TACC is constantly updating its high-performance storage resources and security mechanisms, data will be preserved at the same preservation level that is currently available. Since DOIs are supported through the University of Texas Libraries, and web services and data reside within TACC’s managed resources, access to data will not be interrupted. [Fedora](https://fedorarepository.org/) is now part of TACC’s software suite and we will continue its maintenance as our preservation repository. Like all systems at TACC, we will revisit its versioning and continuity and make decisions based on state-of-the-art practices. If resources become too constrained, TACC will continue to keep an archive copy on [Ranch](https://tacc.utexas.edu/systems/ranch/), with landing pages on online storage, for as long as TACC remains a viable entity.
 
-#### Community { #community }
+## Data Embargoes
 
-The DDR serves the broader natural hazards research community both as data producers and consumers.  This research community includes, but is not limited to, the facilities that make up NHERI network - for which we are the designated data repository.  We work with each component of the NHERI network to meet the requirements and commitments of their distinct research focus and functions. As the only repository for open natural hazards research data, we welcome data produced in other national and international facilities and organizations.  At large, the repository serves a broad national and international audience of natural hazard researchers, students, practitioners, policy makers, as well as the general public.
+A data embargo is a period of time during which a dataset has a DOI but is not made broadly accessible, awaiting review and acceptance by a journal publication. Many researchers request a DOI (digital object identifier) for their dataset prior to its publication to include in papers submitted to journals for review. 
 
+DDR  does not provide data embargoes because a DOI is a digital identifier that points to a permanent location on the web. Datasets need to be fully curated in order to be granted a DOI. If datasets are not published, the DOI in the references is not a working DOI and directs to an error page. Users should publish their datasets prior to submitting their papers including the formal dataset citation so that the citation works properly if reviewers want to evaluate the dataset.  In addition, DDR does not offer capabilities for enabling single or double blind peer review. 
 
+DDR continues working with users to:
 
-### Governance
+* Provide access to reviewers via My Project before the dataset is published. There is no DOI involved and the review is not anonymous.
+* Help users curate and publish their datasets so they are publicly available for reviewers in the best possible form.
+* Provide amends and versioning so that prompt changes can be made to data and metadata upon receiving feedback from the reviewers or at any other time.
 
-Policies for the DDR are driven by the Natural Hazards (NH) scientific community and informed by best practices in library and information sciences. The DDR operates under the leadership of the DesignSafe Management Team (DSMT), who establishes and updates policies, evaluates and recommends best practices, oversees its technical development, and prioritizes activities. The broad organizational structure under which the DDR operates is <a href="https://www.designsafe-ci.org/about/designsafe/">here</a>.
+## Data Preservation
 
-#### Repository Team { #repositoryteam }
+Data preservation encompasses activities carried out by all the stakeholders involved in the lifecycle of data, from data management planning to data curation, publication and long-term archiving.
 
-An interdisciplinary repository team (RT) carries out ongoing design, development and day-to-day operations, gathering requirements and discussing solutions through formal monthly and bi-weekly meetings with the NHERI community and maintaining regular communications with members of the network, including monthly meetings with the<a href="https://www.designsafe-ci.org/facilities/experimental/"> Experimental Facilities</a>, <a href="https://rapid.designsafe-ci.org/">RAPID</a>, and <a href="https://rapid.designsafe-ci.org/">CONVERGE</a> staff. Based on these fluid communications, the RT designs functionalities, researches and develops best-practices, and implements agreed-upon solutions. The figure below shows the current formation of the RT, including their expertise.
+Data in the (DDR) is preserved according to state-of-the art digital library standards and best practices. DesignSafe is implemented within the reliable, secure, and scalable storage infrastructure at the [Texas Advanced Computing Center (TACC)](https://tacc.utexas.edu/), with more than 20 years of experience and innovation in High Performance Computing. TACC has operated a digital data archive continuously since 1986 - currently implemented in the [Corral](https://www.tacc.utexas.edu/systems/corral) data management system and the [Ranch](https://www.tacc.utexas.edu/systems/ranch) tape archive -, with capacity of approximately half an exabyte. Corral and Ranch hold the data for the DDR and hundreds of other research data collections. These storage resources are reliable, secure, monitored 24/7, and under a rigorous maintenance and update schedule, operated in production by a large team of professional staff. Public user guides document the capabilities and hardware, and internal configuration management is managed via Redmine, visible only to systems staff. Between those systems there are multiple layers of data protection and reliability, including snapshots, server redundancy, distributed RAID, and replication to the tape archive.
 
-![](./imgs/Data_Repository_Team_DataTeam.png){: width="322" }
+Within the storage infrastructure a dedicated [Fedora](https://duraspace.org/fedora/) 5.x digital repository, considered a standard for digital libraries, assures the authenticity and integrity of the published datasets by maintaining provenance, fixity, and preservation metadata in accordance to [standard schemas](/user-guide/dictionary/#experimental) and the relationships between data and corresponding metadata for each published research project. Specifically, Fedora was chosen as a repository because the flexibility of its model allows managing the structure of the DDR’s different project types.
 
-Formal mechanisms are in place for external evaluators to gather feedback and conduct structured assessments, in the form of usability studies and yearly user surveys, to ensure that the repository is meeting the community’s expectations and needs. To track development the DDR curator meets every other week with the DesignSafe PI and with the head of the development team. All DDR activities are reported to the National Science Foundation on a quarterly and annual basis in terms of quantitative and qualitative progress.
+The DDR-Fedora workflow is as follows. Once a dataset is curated and the user has agreed to the last step in the publication process, published files are hashed for fixity - integrity- and file formats are identified - preservation using OPF-FIDO. The integrity and preservation information about each file is added to a manifest file. Files are stored on Corral in a secure location that is also recorded on the manifest file. Ingestion of metadata from the web-visible storage into Fedora takes place under automated control when the publication workflow executes. At that point, user contributed metadata is mapped to the standard descriptive and data citation schemas DublinCore, DDI, and DataCite, and data model metadata for each project type is mapped to PROV to reflect the relations between different components of the datasets and to the research project.  The manifest file and the metadata that the user has been inputting throughout the curation process is sent to Fedora. For each individual file, Fedora maintains preservation metadata in the standard [PREMIS](https://www.loc.gov/standards/premis/) format.
 
-#### Community Norms for DDR { #norms }
+Both the front-end copies and the Fedora repositories are in systems that implement de-clustered RAID and have sufficient redundancy to manage up to 3 drive failures for a single file stripe. The file system itself is mirrored daily between two datacenters. The primary data is also periodically backed up to the tape archive for a third copy. The database that manages metadata in Fedora is also quiesced, snapshotted, and backed to tape on a regular automated schedule.In case of failure where data is compromised, the system can be restored from the replication.
 
-Within the broader conditions of use for DesignSafe we have established a set of Community Norms specific for DDR which have to be agreed upon at the point of registering an account on the platform. These norms, highlighting our existing policies, are the following:
+The underlying storage systems for the DDR are managed in-house at TACC. All the storage systems used by DesignSafe are shared multi-tenant systems, hosting many projects concurrently in addition to DesignSafe – the front-end disk system currently has ~20PB of data, with the [tape archive](https://www.tacc.utexas.edu/systems/ranch) containing roughly 80PB. This preservation environment allows maintaining data in secure conditions at all times, before and after publication, comply with [NDSA Preservation Level 1](https://ndsa.org/publications/levels-of-digital-preservation/), attain and maintain the required representation and descriptive information about each file, and be ready at any time to transfer custody of published data and metadata in an orderly and validated fashion. 
 
-Users who either publish and use data in DDR must abide by both the <a href="https://portal.tacc.utexas.edu/tacc-usage-policy">TACC Acceptable Use Policy</a> and the <a href="https://www.designsafe-ci.org/account/terms-conditions/">DesignSafe Terms of Use</a>.
+Each published dataset has a [Digital Object Identifier (DOI)](https://www.doi.org/the-identifier/what-is-a-doi/) that provides a persistent link to the published data. The DOI is available in the dataset landing page, along with all the required metadata and documentation.
 
-##### For users curating and publishing data in DDR: { #norms-curators }
+While at the moment DDR is committed to preserve data in the format in which it is submitted, we procure the necessary authorizations from users to conduct further preservation actions as well as to transfer the data to other organizations if applicable. These permissions are granted through our [Data Publication Agreement](/user-guide/curating/policies/#data-publication-agreement), which authors acknowledge and have the choice to agree to at the end of the publication workflow and prior to receiving a DOI for their dataset.
 
-* Users understand that their data submissions to the DDR should follow our Data Policies and our Curation and Publication Best Practices to the best of their ability. 
-* Users agree to use DDR to publish only <a href="https://www.budapestopenaccessinitiative.org/read">open access </a>data, which they must document in a manner that does not hinder the ability of other users to reuse or reproduce it. 
-* Users publishing or reusing data of others in their data publications must properly cite the datasets in accordance with the <a href="https://www.force11.org/datacitationprinciples">Joint Declaration of Data Citation Principles</a> using the fields provided in the DDR interface. 
-* Users agree to provide all the needed licenses and permissions to make data available for archiving and for reuse by others. 
-* Users publishing human subjects data should abide by our Protected Data Best Practices. 
-* Using DDR to publish data is entirely voluntary. None of these terms supersede any prior contractual obligations to confidentiality or proprietary information the user may have with third parties; thus, the user is entirely responsible for what they upload or share with DDR. .
-* Publications that do not fall within these norms may be removed.
+The DDR has been operational since 2016 and is currently supported by the NSF from October 1st, 2020 through September 30, 2025. During this award period, the DDR will continue to preserve the natural hazards research data published since its inception  as well as supporting preservation of and access to legacy data and the accompanying metadata from the Network for Earthquake Engineering Simulation (NEES), a NHERI predecessor, dating from 2005. The [legacy data comprising 33 TB, 5.1 million files,2 and their metadata](https://www.designsafe-ci.org/data/browser/public-legacy/) was transferred to DesignSafe in 2016 as part of the conditions of the [original grant](https://www.nsf.gov/pubs/2014/nsf14605/nsf14605.htm). Our [Continuity of Access Policy](/user-guide/curating/policies/#continuity-of-access) presents the preservation and access alternatives that can be implemented at the end of the award period.
 
-##### For users using data published in DDR: { #norms-users }
+## Dataset Quality
 
-* Users accessing and using DDR data agree to the following Data Use Agreement. 
-* Users agree to use DDR resources in accessing and reusing open access data in ways that respect the licenses established in the publications. 
-* Users agree to properly cite the datasets they use in their works in accordance with the <a href="https://www.force11.org/datacitationprinciples">Joint Declaration of Data Citation Principles</a> using the citations provided in the published datasets landing pages. 
-* We reserve the right to ask users to suspend their use of DDR should we receive complaints or note violations of these Community Norms.
+DDR is a self-publication repository which means that authors are ultimately responsible for the quality of the dataset that they share with the world. However,  we understand that producing and sharing quality datasets  is a collaborative effort between researchers and the DDR and we partner with users to publish [FAIR](https://www.go-fair.org/fair-principles/) (Findable, Accessible, Interoperable, and Reusable) datasets. In consultation with the larger NHERI network we are continuously observing and defining [best practices](/user-guide/curating/bestpractices/) that emerge from our community's understanding and standards. These are communicated through onboarding instructions in the curation and publication pipeline, our policies and  best practices recommendations,  our guidance during [virtual office hours](https://www.designsafe-ci.org/facilities/virtual-office-hours/), and through our help ticketing system. 
 
-### Data Collections Development
+We address data quality from a variety of perspectives:
 
-#### Data Types { #types }
+Metadata quality: Metadata is fundamental to data explainability and reuse. To support metadata quality we provide onboarding descriptions of all metadata elements, indicate which ones are required, and suggest how to complete them. [Requirements for core metadata elements](/user-guide/curating/policies/#metadata-schema-and-requirements) are automatically reinforced during the publication pipeline, and the dataset will not be published if requirements are not met. 
 
-We accept engineering datasets, as well as social and behavioural sciences datasets, derived from research conducted in the context of natural hazards. In the area of engineering the primary focus is on data generated through simulation, hybrid simulation, experimental and field research methods regarding the impacts of wind, earthquake, and storm surge hazards. We also accept data reports, publications of Jupyter notebooks, code, scripts, lectures, and learning materials. In social and behavioural sciences (SBE), accepted datasets encompass the study of the human dimensions of hazards and disasters. As the field and the expertise of the community evolves we have expanded our focus to include datasets related to COVID-19, Fire Hazards, and Sustainable Material Management.
+Dataset content quality: Different groups in the NHERI network have developed guidelines for data quality assurance, including [StEER](https://www.steer.network/resources), [CONVERGE](https://converge.colorado.edu/data/data-management) and [RAPID](https://rapid.designsafe-ci.org/using-rapid/publishing-guidelines). In turn, each [NHERI Experimental Facility](https://designsafe-ci.org/facilities/experimental/) has methods and criteria in place for ensuring the quality of the data they generate from experiments. Most of the data curated and published in the DDR are related to peer-reviewed research projects and papers, speaking to the relevance and standards of their design and outputs. Still, the community acknowledges that opportunities for detailed quality assessment often emerge after publication. Because work in many projects continues after publication, both for the data producers and reusers, the community can version datasets.
 
-Users that deposit data that does not correspond to the accepted types will be alerted when possible prior to publication so they can remove their data from DDR, and will not be allowed to publish it. If a dataset non-compliant with the Collections Development policy gets published with a corresponding DOI, we will contact the authors and work with them to remove the data and leave a <a href="https://support.datacite.org/docs/tombstone-pages">tombstone</a> explaining why the data is not available. Curators review both in process and published data on a monthly basis. In both cases we will work with the authors to find an adequate repository for their dataset.
+Dataset completeness: We understand data completeness as the presence of all relevant files that enable reproducibility, understandability, and reuse. This may include readme files, data dictionaries and data reports, as well as data files. The DDR complies with data completeness by recommending and requesting users to include required data to fulfill the corresponding data model categories. During the publication process the system verifies that those categories have data assigned to them. The View Data Diagram link on the landing page reflects the data categories  present in each dataset. 
 
-#### Data Size { #size }
+Dataset quality statement: We ask users to include a brief statement if and about how they verify the quality and completeness of their data including processes such as validation, calibration, performance evaluation, resolution, transformations, etc. 
 
-Researchers in the natural hazards community generate very large datasets during large-scale experiments, simulations, and field research projects. At the moment the DDR does not pose limitations on the amount of data to be published, but we do recommend to be selective and publish data that is relevant to a project completeness and is adequately described for reuse. Our <a href="/user-guide/curating/bestpractices/#data-curation">Data Curation Best Practices</a> include recommendations to achieve a quality data publication. We are observing trends in relation to sizes and subsequent data reuse of these products, which will inform if and how we will implement data size publication limit policies.
+Dataset publication review: Data curators review new publications on a regular basis. These reviews show how the community understands and uses the data models and the metadata fields, and allows verifying the overall quality of the published datasets. If curation problems that cannot be automatically detected are identified (e.g. insufficient or unclear descriptions, file or category misplacement, etc.) the dataset authors are contacted and work along with the curator on amending and or versioning their datasets.  
 
-#### Data Formats { #formats }
+Statement of data quality: We ask that data producers include a statement of dataset quality indicating if and how they verified the data quality, or if they published the raw data as is. 
 
-We do not pose file format restrictions. The natural hazards research community utilizes diverse research methods to generate and record data in both open and proprietary formats, and there is continual <a href="https://rapid.designsafe-ci.org/equipment-portfolio/">update of equipment</a> used in the field. We do encourage our users to convert to open formats when possible. The DDR follows the <a href="https://www.loc.gov/preservation/resources/rfs/TOC.html">Library of Congress Recommended Format Statement</a> and has guidance in place to convert proprietary formats to open formats for long term preservation; see our [Accepted and Recommended Data Formats](/user-guide/curating/bestpractices/#acceptedfileformats) for more information. However, conversion can present challenges; Matlab, for example, allows saving complex data structures, yet not all of the files stored can be converted to a csv or a text file without losing some clarity and simplicity for handling and reusing the data. In addition, some proprietary formats such as jpeg, and excel have been considered standards for research and teaching for the last two decades. In attention to these reasons, we allow users to publish the data in both proprietary and open formats. Through our Fedora repository we keep file format identification information of all the datasets stored in DDR.
-### Data Curation
+Meeting the dataset quality requirement: In cases in which the authors do not comply with these data quality requirements, DDR abides by the [Tombstone policy](/user-guide/curating/policies/#tombstone) and may permanently remove the dataset. 
 
-Data curation involves the organization, description, representation, permanent publication, and preservation of datasets in compliance with community best practices and <a href="https://www.go-fair.org/fair-principles/">FAIR</a> data principles. In the DDR, data curation is a joint responsibility between the researchers that generate data and the DDR team. Researchers understand better the logic and functions of the datasets they create, and our team's role is to help them make these datasets FAIR-compliant.
 
-Our goal is to enable researchers to curate their data from the beginning of a research project and turn it into publications through interactive pipelines and consultation with data curators. The DDR has and continues to invest efforts in developing and testing curation and publication pipelines based on data models designed with input from the NHERI community.
 
-#### Data Management Plan { #management }
+## Data Publication Agreement
 
-For natural hazards researchers submitting proposals to the NSF using any of the NHERI network facilities/resources, or alternative facilities/resources, we developed Data Management guidelines that explain how to use the DDR for data curation and publication. See Data Management Plan at: <a href="/user-guide/managingdata/datamanagementplan/">Data Management Plan</a> and <a href="https://converge.colorado.edu/data/data-management">https://converge.colorado.edu/data/data-management</a>
+This agreement must be read and accepted by the user prior to publishing a dataset:
 
-#### Data Models { #models }
+This submission represents my original work and meets the policies and requirements established by the DesignSafe. I grant the Data Depot Repository (DDR) all required permissions and licenses to make the work I publish available for archiving and continued access. These permissions include allowing DesignSafe to:
 
-To facilitate data curation of the diverse and large datasets generated in the fields associated with natural hazards, we worked with experts in natural hazards research to develop [five data models](/user-guide/curating/guides/) that encompass the following types of datasets: experimental, simulation, field research, hybrid simulation, and other data products (See: 10.3390/publications7030051; 10.2218/ijdc.v13i1.661) as well as lists of specialized vocabulary. Based on the <a href="http://icatproject-contrib.github.io/CSMD/">Core Scientific Metadata Model</a>, these data models were designed considering the <a href="https://www.youtube.com/watch?v=iYzvYi-SY8Q">community's research practices and workflows</a>, <a href="https://www.youtube.com/watch?v=xUyFJwZmyqM">the need for documenting these processes</a> (provenance), and using terms common to the field. The models highlight the structure and components of natural hazards research projects across time, tests, geographical locations, provenance, and instrumentation. Researchers in our community have presented on the design, implementation and use of these models broadly.
+1. Disseminate the content in a variety of distribution formats according to the DDR Policies and Best Practices.
+2. Promote and advertise the content publicly in DesignSafe.
+3. Store, translate, copy, or re-format files in any way to ensure their future preservation and accessibility.
+4. Modify the dataset interface representation for improved usability.
+5. Exchange and or incorporate metadata or documentation in the content into public access catalogues.
+6. Transfer data and metadata with respective unique digital object identifier (DOI)  to another institution for long-term accessibility if needed for continuous access.
 
-In the DDR web interface the data models are implemented as interactive functions with instructions that guide the researchers through the curation and publication tasks. As researchers move through the tion pipelines, the interactive features reinforce data and metadata completeness and thus the quality of the  publication. The process will not move forward if requirements for metadata are not in place (See [Metadata in Best Practices](/user-guide/curating/bestpractices/#metadata)), or if key files are missing.
+I understand the type of license I choose to distribute my data, and I guarantee that I am entitled to grant the rights contained in them. I agree that when this submission is made public with a DOI, this DOI cannot be discarded, even if the dataset is [tombstoned](/user-guide/curating/policies/#tombstone). If the dataset requires revision, a new version of the dataset will be published under the same DOI.
 
-#### Metadata { #metadata }
+I warrant that I am lawfully entitled and have full authority to license the content submitted, as described in this agreement. None of the above supersedes any prior contractual obligations with third parties that require any information to be kept confidential.
 
-Up to date, there is no standard metadata schema to describe natural hazards data. In DDR we follow a combination of standard metadata schemas and expert-contributed vocabularies to help users describe and find data.
+If applicable, I warrant that I am following the IRB agreements in place for my research and following the [Protected Data Policy](/user-guide/curating/policies/#protected-data). 
 
-Embedded in the DDR data models are categories and terms as metadata elements that experts in the NHERI network contributed and deemed important for data explainability and reuse. Categories reflect the structure and components of the research dataset, and the terms describe these components.  The structure and components of the published datasets are represented on the dataset landing pages and through the Data Diagram presented for each dataset.
+I understand that using the DDR to publish datasets is entirely voluntary and that I am solely responsible for all possible confidentiality, privacy, data quality and data content  issues that may arise from the publication. These terms do not supersede any prior third party contractual obligations to confidentiality or proprietary information. 
 
-Due to variations in their research methods, researchers may not need all the categories and terms available to describe and represent their datasets. However, we have identified a core set of metadata that allows proper data representation, explainability, and citation. These sets of core metadata are shown for each data model in our <a href="/user-guide/curating/bestpractices/#metadata">Metadata Requirements in Best Practices. </a>
+## Data Types
 
-To further describe datasets, the curation interface offers the possibility to add both predefined and custom file tags. Predefined file tags are specialized terms provided by the natural hazard community; their use is optional, but highly recommended. The lists of tags are evolving for each data model, continuing to be expanded, updated, and corrected as we gather feedback and observe how researchers use them in their publications.
+We accept engineering and social and behavioural sciences datasets, reports, research software and presentations derived from research conducted in the context of natural hazards regarding the impacts of wind, earthquake, storm surge, wildfires, and sustainable materials management. Specifically in the area of engineering, the primary focus is on data generated through simulation, hybrid simulation, experimental, machine learning, and field research methods. In social and behavioural sciences (SBE), accepted datasets and research instruments encompass the study of the human dimensions of hazards and disasters and we expanded our focus to include datasets related to COVID-19. Users who submit datasets that do not match the accepted data types will be notified whenever possible before publication so that they can remove their data. If a noncompliant dataset is published with a DOI, we will abide by the [Tombstone Policy](/user-guide/curating/policies/#tombstone), and a curator will work with the user to find a repository adequate for their needs. As the field and the expertise of the community evolves we may expand the data types accepted.
 
-For purposes of metadata exchange and interoperability, the elements and tags in the data models are mapped to widely-used, standardized metadata schemas. These are: <a href="https://www.dublincore.org/specifications/dublin-core/dcmi-terms/">Dublin Core</a> for description of the dataset project, <a href="https://ddialliance.org/products/overview-of-current-products">DDI (Data Documentation Initiative)</a> for social science data, <a href="https://datacite.org/dois.html">DataCite</a> for DOI assignment and citation, and <a href="https://www.w3.org/2001/sw/wiki/PROV">PROV-O</a> to record the structure of the dataset. Metadata mapping is substantiated as the data is ingested into Fedora. Users can download the standardized metadata in the publications landing page.
+## Data Usage Agreement
 
-#### Metadata and Data Quality { #dataquality }
+Users who access, preview, download or reuse data and metadata from the DesignSafe Data Depot Repository (DDR) agree to the following norms. If some or any of these norms are not followed, we will notify the user of the infringement and may cancel their DesignSafe account.
 
-The diversity and quantity of research methods, instruments, and data formats in natural hazards research is vast and highly specialized. For this reason, we conceive of data quality as a collaboration between the researchers and the DDR.  In consultation with the larger NHERI network we are continuously observing and defining best practices that emerge from our community's understanding and standards.
+* Use of the data includes, but is not limited to, viewing parts or the whole of the content; comparing with data or content in other datasets; verifying research results, and using any part of the content in other projects, publications, or other related work products.
+* Users will not use the data in any way prohibited by applicable laws, distribution licenses, and permissions explicit in the dataset publication landing page.
+* The data are provided “as is,” and its use is at the users' risk. While the DDR promotes data and metadata quality, the datasets authors and publishers do not guarantee that:
 
-We address data quality from a variety of perspectives:
+1. the materials are accurate, complete, reliable or correct;
+2. any defects or errors will be corrected;
+3. the materials and accompanying files are free of viruses or other harmful components; or
+4. the results of using the data will meet the user’s requirements.
 
-Metadata quality: Metadata is fundamental to data explainability and reuse. To support metadata quality we provide onboarding descriptions of all metadata elements, indicate which ones are required, and suggest how to complete them. Requirements for core metadata elements are automatically reinforced within the publication pipeline and the dataset will not be published if those are not fulfilled.  Metadata can be accessed by users in standardized formats on the projects’ landing pages.
+* Use of data in the DDR abides by  DesignSafe's  Personal Data Privacy Policy. The DDR does not gather IP addresses about public users that preview or download files from the DDR. The system logs file actions completed by registered users in the DDR including previewing, downloading or copying published data to My Data or My Projects. This  information is only used in aggregate for metrics purposes and is not linked to the user’s identity.
+* Users should not obtain personal information associated with DDR data that results in directly or indirectly identifying research subjects, individuals, or organizations with the aid of other information acquired elsewhere.
+* Users will not hold the DDR or the data authors liable for any and all losses, costs, expenses, or damages arising from use of DDR data or any other violation of this agreement, including infringement of licenses, intellectual property rights, and other rights of people or entities contained in the data.
+* Users are responsible for complying with the restrictions outlined by the dataset's authors in their publications' landing pages and by this agreement, but they are not responsible for any restrictions not otherwise explicitly described here  or in the landing pages.
 
-Data content quality: Different groups in the NHERI network have developed benchmarks and guidelines for data quality assurance, including <a href="https://www.steer.network/resources">StEER</a>, <a href="https://converge.colorado.edu/data/data-management">CONVERGE</a> and <a href="https://rapid.designsafe-ci.org/media/filer_public/b3/82/b38231fb-21c9-41f8-b658-f516dfee87c8/rapid-designsafe_curation_guidelines_v3.pdf">RAPID</a>. In turn, each NHERI Experimental Facility has methods and criteria in place for <a href="https://drive.google.com/file/d/1b9epjfTc_dRodKizRl2dIc2eAB252KH6/view">ensuring and assessing data quality</a> during and after experiments are conducted. Most of the data curated and published <a href="https://drive.google.com/file/d/15EO6WfrUlq8vnrKMebYJQgTWEIw7aNFc/view">along NHERI guidelines</a> in the DDR are related to peer-reviewed research projects and papers, speaking to the relevance and standards of their design and outputs. Still, the community acknowledges that for very large datasets the opportunity for detailed quality assessment emerges after publication, as data are analyzed and turned into knowledge. Because work in many projects continues after publication, both for the data producers and reusers, the community has the opportunity to version datasets.
 
-Data completeness and representation: We understand data completeness as the presence of all relevant files that enable reproducibility, understandability, and therefore reuse. This may include readme files, data dictionaries and data reports, as well as data files. The DDR complies with data completeness by recommending and requesting users to include required data to fullfill the data model required categories indispensable for a publication understandibility and reuse. During the publication process the system verifies that those categories have data assigned to them.The Data Diagram on the landing page reflects which relevant data categories are present in each publication. A similar process happens for metadata during the publication pipeline; metadata is automatically vetted against the research community's <a href="/user-guide/curating/bestpractices/#metadata">Metadata Requirements </a>before moving on to receive a DOI for persistent identification.
 
-We also support citation best practices for datasets reused in our publications. When users reuse data from other sources in their data projects, they have the opportunity to include them in the metadata through the Related Works and Referenced Data fields.
+## Dataset Sizes
 
-Data publications review: Once a month, data curators meet to review new publications. These reviews show us how the community is using and understanding the models, and allows verifying the overall quality of the data publications. When we identify curation problems (e.g. insufficient or unclear descriptions, file or category  misplacement, etc.) that could not be automatically detected, we contact the researchers and work on solving these issues. Based on the feedback, users have the possibility to amend/improve their descriptions and to version their datasets (See amends and version control).
+Currently we do not impose restrictions on the size of the datasets that can be published. This approach recognizes the necessity of comprehensive data collection and the increasingly large sizes of datasets in natural hazards research. Largest published datasets in DDR are ~5 TB. However, we recommend researchers to be selective and to publish data that is relevant to research reproducibility and that is adequately organized and described so that other researchers interested in reusing the data can find what they need. For datasets larger than 1 TB we suggest that users include research software (ex. Jupyter Notebook) to access, visualize, or subset the dataset. 
 
-#### Curation and Publication Assistance  { #assistance }
+## DOIs and Data Citation
 
-We believe that researchers are best prepared to tell the story of their projects through their data publications; our role is to enable them to communicate their research to the public by providing flexible and easy to use curation resources and guidance that abide by publication best practices. To support researchers organizing, categorizing and describing their data, we provide interactive pipelines with onboarding instructions, different modes of training and documentation, and one-on-one help.
+In the DDR DOIs are assigned at the Mission, Simulation, Hybrid Simulation, and Experiment levels as well as to the Other type of publication. Thus, each published dataset has a distinct DOI and corresponding citation. DOIs rely on the [DataCite schema](https://schema.datacite.org/) for complete citation information.
 
-Interactive pipelines: The DDR interface is designed to facilitate large scale data curation and publication through interactive step-by-step capabilities aided by onboarding instructions. This includes the possibility to categorize and tag multiple files in relation to the data models, and to establish relations between categories via diagrams that are intuitive to data producers and easy to understand for data consumers. Onboarding instructions including vocabulary definitions, suggestions for best practices, availability of controlled terms, and automated quality control checks are in place.
+The DDR abides by and promotes the [Joint Declaration of Data Citation Principles](https://force11.org/info/joint-declaration-of-data-citation-principles-final/) amongst its users. For researchers publishing data in DDR, we enable referencing papers that cite the published dataset, and data or software reused for the production of the dataset by providing Related Work and Referenced Data and Software fields. For researchers reusing data from DDR, we encourage and facilitate citing the published datasets using the DOI and the citation language available in their corresponding  landing page. When imputed by authors, both Related Works and Referenced Data and Software information is sent by our pipeline to DataCite so that credits are accounted for as  citations to the published dataset or as citations to  the resources that were reused. 
 
-One-on-one support: We hold <a href="https://www.designsafe-ci.org/facilities/virtual-office-hours/">virtual office hours</a> twice a week during which a curator is available for real-time consulting with individuals and teams. Other virtual consulting times can be scheduled on demand. Users can also submit Help tickets, which are answered within 24 hours, as well as send emails to the curators. Users also communicate with curatorial staff via the DesignSafe Slack channel. The curatorial staff includes a natural hazards engineer, a data librarian, and a USEX specialist. Furthermore, developers are on call to assist when needed.
+The expectations of DDR and the responsibilities of users in relation to compliance with data citation are included in the DesignSafe Terms of Use, the [Data Usage Agreement](#data-usage-agreement), and the [Data Publication Agreement](#data-publication-agreement). In the event that we note or are notified that citation policies are not followed, we will ask the authors to include the corresponding citations, all of which is possible after publication by amending the publicationHowever, since it is not easy to know with certainty if users comply with data citation, our approach is to educate our community by reinforcing citation in a positive way. For this we implement outreach strategies to stimulate data citation. Through FAQs, Q&As, webinars, and via emails, we regularly train our users on data citation best practices. And, by tracking and publishing citation  information we demonstrate the value of the datasets and further stimulate publishing and citing data.
 
-Guidance on Best Practices: Curatorial staff prepares <a href="https://youtube.com/playlist?list=PL2GxvrdFrBlkwHBgQ47pZO-77ZLrJKYHV">guides</a> and <a href="https://www.youtube.com/playlist?list=PL2GxvrdFrBlkwHBgQ47pZO-77ZLrJKYHV">video tutorials</a>, including special training materials for <a href="https://youtu.be/nQqRoFusEsU">Undergraduate Research Experience</a> students and for <a href="/user-guide/managingdata/experimentalfacilitychecklist/">Graduate Students working at Experimental Facilities</a>.
+## File Formats
 
-Webinars by Researchers: Various researchers in our community contribute to our curation and publication efforts by conducting webinars in which they relay their data curation and publication experiences. Some examples are webinars on curation and publication of <a href="https://www.youtube.com/watch?v=iYzvYi-SY8Q&amp;list=PL2GxvrdFrBlk31A0BhTFUGidpAbyJPXi4&amp;index=13">hybrid simulations,</a> <a href="https://www.youtube.com/watch?v=xUyFJwZmyqM">field research </a>and <a href="https://www.youtube.com/watch?v=kTy3y5_XLJ0">social sciences</a> datasets.
+The natural hazards research community utilizes diverse research methods to generate and record data in open and proprietary formats, and there is continuous [update of equipment](https://rapid.designsafe-ci.org/resources/rapid-equipment-portfolio) used in the field. To encourage data publication DDR does  not have a hard file format restriction policy but we ask our users to convert proprietary file formats to open formats when possible.
 
-### Data Publication and Usage
+The DDR follows the [Library of Congress Recommended Format Statement](https://www.loc.gov/preservation/resources/rfs/TOC.html) which has recommended file formats to guide conversion from proprietary formats to open formats for long term preservation. Conversion from proprietary to open formats, however, can present challenges. Matlab, for example, allows saving complex data structures, yet not all of the files stored can be converted to a csv or a text file without losing some clarity and simplicity for handling and reusing the data. In addition, some proprietary formats such as jpeg and excel have been considered standards for research and teaching for the last two decades.  In attention to this, we allow users to publish the data in both proprietary and open formats. We keep file format identification information of all the datasets in the Fedora repository.
 
-#### Protected Data { #protecteddata }
+## Metadata
 
-Protected data are information subject to regulation under relevant privacy and data protection laws, such as <a href="https://www.hhs.gov/hipaa/for-professionals/privacy/laws-regulations/index.html">HIPAA</a>, <a href="https://studentprivacy.ed.gov/faq/what-ferpa">FERPA</a> and <a href="https://csrc.nist.gov/projects/risk-management/detailed-overview">FISMA</a>, as well as human subjects data containing <a href="https://security.utexas.edu/policies/irusp#definitions">Personally Identifiable Information (PII)</a> and data involving vulnerable populations and or containing <a href="https://en.wikipedia.org/wiki/Information_sensitivity">sensitive information</a>.
+Up to date, there is no standard metadata schema to describe natural hazards data. DDR developed metadata to describe natural hazards datasets through a combination of data models, standard metadata schemas, and expert contributed terms.  Embedded in the data models are named categories and elements that experts in the NHERI network deemed important for data explainability. The categories represent the structure of the research method used to generate the dataset and the elements are corresponding information components that authors need to fill out. The metadata elements for each data model are shown in [Metadata Schema and Requirements](#metadata-schema-and-requirements).
 
-Publishing protected data in the DDR involves complying with the requirements, norms, and procedures approved by the data producers Institutional Review Board (IRB) or equivalent body regarding human subjects data storage and publication, and managing <a href="https://www.cdc.gov/nchs/training/confidentiality/training/page581.html">direct and indirect identifiers </a>in accordance with accepted means of <a href="https://dimewiki.worldbank.org/wiki/De-identification#De-identifying_PII_Necessary_for_Analysis">data de-identification</a>. In the DDR protected data issues are considered at the onset of the curation and publication process and before storing data. Researchers working with protected data in DDR have the possibility to  communicate this to the curation team when they select a project type in DDR and the curator gets in touch with them to discuss options and procedures.
+To form the metadata schema of the different project types in DDR, the category names and elements are combined with widely-used standards. These are: [Dublin Core](https://www.dublincore.org/specifications/dublin-core/usageguide/2001-04-12/generic/#relation) for description of the dataset project, [DDI (Data Documentation Initiative)](https://ddialliance.org/ddi-codebook) for social and behavioral science datasets, [DataCite](https://schema.datacite.org/) for DOI assignment and citation, and PROV-O to record the structure of the datasets. During the data publication process  metadata is ingested to the Fedora repository and mapped to its data model so that  relationships between data files and categories are substantiated. Users can download the metadata in json format from the datasets landing page. DataCite metadata can be accessed by users in standardized format from the dataset citation. 
 
-Unless approved by an IRB, most forms of protected data cannot be published in DesignSafe. No direct identifiers and only up to three indirect identifiers are allowed in published datasets. However, data containing PII can be published in the DDR with proper consent from the subject(s) and documentation of that consent in the project's IRB paperwork. In all publications involving human subjects, researchers should include and publish their IRB documentation showing the agreement.
+To further describe datasets, the curation interface offers the possibility to add predefined and custom file tags. Predefined file tags are specialized terms provided by the natural hazard community and custom tags are made by the datasets authors. While use of tags is optional, it is highly recommended as tags improve the browsing experience. The lists of predefined tags are evolving for each data model, continuing to be expanded, updated, and corrected as we gather feedback and observe how researchers use them in their publications.
 
-If as a consequence of data de-identification the data looses meaning, it is possible to publish a description of the data, the corresponding IRB documents,  the data instruents if applicable, and obtain a DOI and a citation for the dataset. In this case, the dataset will show as with Restricted Access. In addition, authors should include information of how to reach them in order to gain access or discuss more information about the dataset. The responsibility to maintain the protected dataset in compliance with the IRB comitements and for the long term will lie on the authors, and they can use <a href="https://www.tacc.utexas.edu/protected-data-service">TACC's Protected Data Services</a> if they need to. For more information on how to manage this case see our [Protected Data Best Practices](/user-guide/curating/bestpractices/#protecteddata).
+Due to variations in their methodology, researchers may not need all the categories and terms available to describe and represent their datasets. We have identified a core set of required metadata that allows proper data representation, explainability, and citation. If required elements are not  completed during the curation and publication process, the pipeline will not proceed.
 
-It is the user’s responsibility to adhere to these policies and the procedures and standards of their IRB or other equivalent institution, and DesignSafe will not be held liable for any violations of these terms regarding improper publication of protected data. User uploads that we are notified of that violate this policy may be removed from the DDR with or without notice, and the user may be asked to suspend their use of the DDR and other DesignSafe resources. We may also contact the user’s IRB and/or other respective institution with any cases of violation, which could incur in an <a href="https://www.fda.gov/regulatory-information/search-fda-guidance-documents/institutional-review-boards-frequently-asked-questions#IRBProcedures">active audit</a> (See 24) of the research project, so users should review their institution’s policies regarding publishing with protected data before using DesignSafe and DDR.
+## Licenses
 
-For any data not subject to IRB oversight but may still contain PII, such as Google Earth images containing images of people not studied in the scope of the research project, we recommend blocking out or blurring any information that could be considered PII before publishing the data in the DDR. We still invite any researchers that are interested in seeing the raw data to contact the PI of the research project to try and attain that. See our [Protected Data Best Practices](/user-guide/curating/bestpractices/#protecteddata) for information on how to manage protected data in DDR.
+DDR provides users with licensing options to accommodate the variety of research outputs that are published on the DDR including datasets, reports, survey instruments, presentations, learning materials, and research software. The licenses were selected after discussions within our community. 
 
-#### Subsequent Publishing { #publishing }
+As an open repository, DDR offers licenses with few - expect attribution - to no restrictions - do not expect attribution -  which provide less demands on reusers and are more effective enabling reproducible science. 
 
-Attending to the needs expressed by the community, we enable the possibility to publish data and other products subsequently within a project, each with a DOI. This arises from the longitudinal and/or tiered structure of some research projects such as experiments and field research missions which happen at different time periods, may involve multiple distinct teams, have the need to publish different types of materials or to release information promptly after a natural hazards event and later publish related products. Subsequent publishing is enabled in My Project interface where users and teams manage and curate their active data throughout their projects' lifecycle.
+During the publication process users have the option of selecting one license per publication with a DOI after identifying which license best fits their needs and institutional standards. Note that datasets are not copyrightable materials, but works such as reports, instruments, presentations and learning objects are. Available Licenses for Publishing Datasets in DDR are: 
 
-#### Timely Data Publication   { #timely }
+### Datasets
 
-Although no firm deadline requirements are specified for data publishing, as an NSF-funded platform we expect researchers to publish in a timely manner, so we provide recommended timelines for publishing different types of research data in our [Timely Data Publication Best Practices](/user-guide/curating/bestpractices/#data-publication).
+If you are publishing **data**, such as **simulation**, **reconaissance**, or **experimental data**, choose between:
 
-#### Peer Review { #peerreview }
+/// html | section.grid
+//// html | div
+///// html | article.card--plain
+      markdown: block
 
-Users that need to submit their data for revision prior to publishing and assigning a DOI have the opportunity to do so by: a) adding reviewers to their My Project, when there is no need for annonymous review, or b) by contacting the DesignSafe data curator through a Help ticket to obtain a Public Accessibility Data Delay (See below). Note that the data must be fully curated prior to requesting a Public Accessibility Delay.
+#### [Open Data Commons Attribution (ODC-By)](https://opendatacommons.org/licenses/by/summary/) {odc-by}
 
-#### Public Accessibility Delay   { #accessiblity }
+* You allow others to freely share, reuse, and adapt your data/database.
+* You expect to be attributed for any public use of the data/database.
 
-Many researchers request a DOI for their data before it is made publicly available to include in papers submitted to journals for review. In order to assign a DOI in the DDR, the data has to be curated and ready to be published. Once the DOI is in place, we provide services to researchers with such commitments to delay the public accessibility of their data publication in the DDR, i.e. to make the user's data publication, via their assigned DOI, not web indexable through DataCote and or not publicly available in DDR's data browser until the corresponding paper is published in a journal, or for up to one year after the data is deposited. The logic behind this policy is that once a DOI has been assigned, it will inevitably be published, so this delay can be used to provide reviewers access to a data publication before it is broadly distributed. Note that data should be fully curated, and that while not broadly it will be eventually indexed by search engines. Users that need to amend/correct their publications will be able to do so via version control. See our [Data Delay Best Practices](/user-guide/curating/bestpractices/#accessibilitydelay) for more information on obtaining a public accessibility delay.
+/////
 
-#### Data Licenses { #licenses }
+_Recommended for Datasets._
 
-DDR provides users with 5 licensing options to accommodate the variety of research outputs generated and how researchers in this community want to be attributed. The following licenses were selected after discussions within our community. In general, DDR users are keen about sharing their data openly but expect attribution. In addition to data, our community issues reports, survey instruments, presentations, learning materials, and code. The licenses are: Creative Commons Attribution (CC-BY 4.0), Creative Commons Public Domain Dedication (CC-0 1.0), Open Data Commons Attribution (ODC-BY 1.0), Open Data Commons Public Domain Dedication (ODC-PPDL 1.0), and GNU General Public License (GNU-GPL 3).  During the publication process  users have the option of selecting one license per publication with a DOI. More specifications of these license options and the works they can be applied to can be found in [Licensing Best Practices](/user-guide/curating/bestpractices/#data-publication).
+////
+//// html | div
+///// html | article.card--plain
+      markdown: block
 
-DDR also requires that users reusing data from others in their projects do so in compliance with the terms of the data original license.
+#### [Open Data Commons Public Domain Dedication and License (PDDL)](https://opendatacommons.org/licenses/pddl/summary/) {pddl}
 
-The expectations of DDR and the responsibilities of users in relation to the application and compliance with licenses are included in the DesignSafe Terms of Use, the Data Usage Agreement, and the Data Publication Agreement. As clearly stated in those documents, in the event that we note or are notified that the licencing policies and best practices are not followed, we will notify the user of the infringement and may cancel their DesignSafe account.
+* You allow others to freely share, modify, and use this data/databse for any purpose without any restrictions.
+* You do not expect to be attributed.
 
-#### Data Citation { #citation }
+/////
+////
+///
 
-DDR abides by and promotes the <a href="https://www.force11.org/datacitationprinciples">Joint Declaration of Data Citation Principles</a> amongst its users.
+### Works
 
-We encourage and facilitate researchers using data from the DDR to cite it using the DOI and citation language available in the datasets landing page. The DOI relies on the <a href="https://datacite.org/">DataCite</a> schema for citation and accurate access.
+If you are publishing **papers**, **presentations**, **learning objects**, **workflows**, **designs**, **etc**, choose between:
 
-For users publishing data in DDR, we enable referencing works and or data reused in their projects. For this we provide two fields, Related Work and Referenced Data, for citing data and works in their data publication landing page.
+/// html | section.grid
+//// html | div
+///// html | article.card--plain
+      markdown: block
 
-The expectations of DDR and the responsibilities of users in relation to the application and compliance with data citation are included in the DesignSafe Terms of Use, the Data Usage Agreement, and the Data Publication Agreement. As clearly stated in those documents, in the event that we note or are notified that citation policies and best practices are not followed, we will notify the user of the infringement and may cancel their DesignSafe account.
+#### [Creative Commons Attribution (CC BY 4.0)](https://creativecommons.org/licenses/by/4.0/) {cc-by}
 
-However, given that it is not feasible to know with certainty if users comply with data citation, our approach is to educate our community by reinforcing citation in a positive way.  For this we implement outreach strategies to stimulate data citation.  Through diverse [documentation](/user-guide/curating/guides/), [FAQs](/user-guide/curating/faq/), <a href="https://www.designsafe-ci.org/community/news/2017/importance-data-publishing-ellen-rathje/">Q&As</a>, webinars, and via emails, we regularly train our users on data citation best practices. And, by tracking and publishing information about the <a href="https://www.designsafe-ci.org/use-designsafe/impact-of-data-reuse/">impact and science contributions </a>of the works they publish citing the data that they use, we demonstrate the value of data reuse and further stimulate publishing and citing data.
+* You allow others to freely share, reuse, and adapt your work.
+* You expect to be attributed for any public use of your work.
+* You retain your copyright. 
 
-#### Data Publication Agreement { #agreement }
+/////
 
-This agreement is read and has to be accepted by the user prior to publishing a dataset.
+_Recommended for reports, instruments, learning objects, etc. This license requires attribution._
 
-This submission represents my original work and meets the policies and requirements established by the DesignSafe [Policies](/user-guide/curating/policies/) and [Best Practices](/user-guide/curating/bestpractices/). I grant the Data Depot Repository (DDR) all required permissions and licenses to make the work I publish in the DDR available for archiving and continued access.  These permissions include allowing DesignSafe to:
+////
+//// html | div
+///// html | article.card--plain
+      markdown: block
 
-1. Disseminate the content in a variety of distribution formats according to the DDR [Policies](/user-guide/curating/policies/) and [Best Practices](/user-guide/curating/bestpractices/).
-2. Promote and advertise the content publicly in DesignSafe.
-3. Store, translate, copy, or re-format files in any way to ensure its future preservation and accessibility, 
-4. Improve usability and/or protect respondent confidentiality.
-5. Exchange and or incorporate metadata or documentation in the content into public access catalogues.
-6. Transfer data, metadata with respective DOI to other institution for long-term accessibility if needed for continuos access.
+#### [Creative Commons Public Domain Dedication (CC0 1.0)](https://creativecommons.org/publicdomain/zero/1.0/) {cc0}
 
-I understand the type of license I choose to distribute my data, and I guarantee that I am entitled to grant the rights contained in them. I agree that when this submission is made public with a unique digital object identifier (DOI), this will result in a publication that cannot be changed. If the dataset requires  revision, a new version of the data publication will be published under the same DOI.
+* You allow others to freely share, modify, and use this work for any purpose without restrictions.
+* You do not expect to be attributed for it.
+* You relinquish any rights to the work.
 
-I warrant that I am lawfully entitled and have full authority to license the content submitted, as described in this agreement. None of the above supersedes any prior contractual obligations with third parties that require any information to be kept confidential.
+/////
+
+_Carefully read and consider this license, as it does not require attribution._
+
+////
+///
+
+## Research Software
+
+DDR requires that users reusing data from others in their projects do so in compliance with the terms of the resource's original license.
+
+The expectations of DDR and the responsibilities of users with respect to licenses are included in the [DesignSafe Terms of Use](https://www.designsafe-ci.org/account/terms-conditions/), the [Data Usage Agreement](/user-guide/curating/policies/#data-usage-agreement), and the [Data Publication Agreement](/user-guide/curating/policies/#data-publication-agreement). In the event that we note or are notified that the licensing policies and best practices are not followed, we will notify the user of the infringement and will apply the [Tombstone Policy](/user-guide/curating/policies/#tombstone).
+
+## Metadata Schema and Requirements { #metadatareqs }
+
+For each project type, the metadata elements including those that are required and recommended are shown below. For more details, consult the full metadata [Dictionaries](/user-guide/dictionary/).
+
+<style id="dict-tree-style">
+/* To align "view full metadata" link with tree title if wrapped */
+.dict-tree small { display: block; translate: 1em; }
+/* To add space to bottom of card (typically provided by its content) */
+.dict-tree.card--plain { padding-bottom: var(--global-space--pattern-pad); }
+/* To add space above list */
+.dict-tree.card--plain > ul { margin-top: 1em; }
+/* To remove space below list (added by Core-Styles card) */
+.dict-tree.card--plain ul { margin-bottom: 0; }
+/* To remove space added by Core-Styles to card */
+.dict-tree.card--plain li { margin-top: 0; }
+</style>
+
+/// html | section.grid
+
+//// details | **Experimental Research Project** <small>([view full dictionary](/user-guide/dictionary/#experimental))</small>
+    attrs: {class: dict-tree card--plain}
+
+* DOI
+* Project Title
+* Author (PIs/Team Members)\*
+* Participant Institution\*
+* Project Type\*
+* Description
+* Publisher†
+* Date of Publication†
+* Licenses
+* Related Works\*$
+* Award\*
+* Keywords
+* //// details | Experiment\*
+
+    * Report
+    * DOI†
+    * Experiment Title
+    * Author (PIs/Team Members)\*
+    * Experiment Description
+    * Date of Publication†
+    * Dates of Experiment
+    * Experimental Facility
+    * Experiment Type
+    * Equipment Type\*
+    * Model Configuration\*
+    * Sensor Information\*
+    * Event\*
+    * Experiment Report$
+  ////
+* //// details | Analysis\*$
+
+    * Analysis Title
+    * Description
+    * Referenced Data\*
+
+  ////
+
+////
+//// details | **Simulation Research Project** <small>([view full dictionary](/user-guide/dictionary/#simulation))</small>
+    attrs: {class: dict-tree card--plain}
+
+* DOI†
+* Project Title
+* Author (PIs/Team Members)\*
+* Participant Institution\*
+* Project Type\*
+* Description
+* Publisher†
+* Date of Publication†
+* Licenses
+* Related Works\*$
+* Award\*
+* Keywords
+* //// details | Simulation\*
+
+    * Report
+    * Simulation Title
+    * Author (PIs/Team Members)\*
+    * Description
+    * Simulation Type
+    * Simulation Model
+    * Simulation Input\*
+    * Simulation Output\*
+    * Referenced Data\*
+    * Simulation Report$
+
+  ////
+* //// details | Analysis\*$
+
+    * Analysis Title
+    * Description
+    * Referenced Data\*
+
+  ////
+
+////
+//// details | **Hybrid Simulation Research Project** <small>([view full dictionary](/user-guide/dictionary/#hybrid))</small>
+    attrs: {class: dict-tree card--plain}
+
+* DOI†
+* Project Title
+* Author (PIs/Team Members)\*
+* Participant Institution\*
+* Project Type\*
+* Description
+* Publisher†
+* Date of Publication†
+* Licenses
+* Related Works\*$
+* Award\*
+* Keywords
+* //// details | Hybrid Simulation\*
+
+    * Report
+    * //// details | Global Model
+        * Global Model Title
+        * Description
+
+      ////
+    * //// details | Master Simulation Coordinator
+        * Master Simulation Coordinator Title
+        * Application and Version
+        * Substructure Middleware
+
+      ////
+    * //// details | Simulation Substructure\*
+        * Simulation Substructure Title
+        * Application and Version
+        * Description
+
+      ////
+    * //// details | Experiment Substructure\*
+        * Experiment Substructure Title
+        * Description
+
+      ////
+  ////
+
+////
+//// details | **Field Research Project** <small>([view full dictionary](/user-guide/dictionary/#field))</small>
+    attrs: {class: dict-tree card--plain}
+
+* Project Title
+* PI/Co-PI(s)\*
+* Project Type
+* Description
+* Related Work(s)\*$
+* Award(s)\*$
+* Keywords
+* Natural Hazard Event
+* Natural Hazard Date
+* //// details | Documents Collection\*$
+
+    * Author(s)\*
+    * Date of Publication†
+    * DOI†
+    * Publisher†
+    * License(s)\*
+    * Referenced Data\*$
+    * Description
+
+  ////
+* //// details | Mission\*
+
+    * Mission Title
+    * Author(s)\*
+    * Date(s) of Mission
+    * Mission Site Location
+    * Date of Publication
+    * DOI†
+    * Publisher†
+    * License(s)\*
+    * Mission Description
+    * //// details | Research Planning Collection\*$
+
+        * Collection Title
+        * Data Collector(s)\*
+        * Referenced Data\*$
+        * Collection Description
+
+      ////
+    * //// details | Social Sciences Collection\*
+
+        * Collection Title
+        * Unit of Analysis$
+        * Mode(s) of Collection\*$
+        * Sampling Approach(es)\*$
+        * Sample Size$
+        * Date(s) of Collection
+        * Data Collector(s)\*
+        * Collection Site Location
+        * Equipment\*
+        * Restriction$
+        * Referenced Data\*$
+        * Collection Description
+
+      ////
+    * //// details | Engineering/Geosciences Collection\*
+
+        * Collection Title
+        * Observation Type\*
+        * Date(s) of Collection
+        * Data Collector(s)\*
+        * Collection Site Location
+        * Equipment\*
+        * Referenced Data\*$
+        * Collection Description
+
+      ////
+  ////
+
+////
+//// details | **Other** <small>([view full dictionary](/user-guide/dictionary/#other))</small>
+    attrs: {class: dict-tree card--plain}
+
+* DOI†
+* Project Title
+* Author(s)\*
+* Data Type
+* Description
+* Publisher†
+* Date of Publication†
+* License(s)
+* Related Works\*$
+* Award\*
+* Keywords
+
+////
 
-If applicable, I warrant that I am following the IRB agreements in place for my research and following [Protected Data Best Practices](/user-guide/curating/bestpractices/#protecteddata).
+///
 
-I understand that the DDR does not approve data publications before they are posted; therefore, I am solely responsible for the submission, publication, and all possible confidentiality/privacy issues that may arise from the publication.
+## Personal Data Privacy
 
-#### Data Usage Agreement { #datausage }
+This policy explains what information DesignSafe collects through the use of DDR and how we treat that information. While the DDR website may contain links to other websites, applications and/or software, we are not responsible for the privacy practices of these third parties. Users should read through their practices before clicking or using them.
 
-Users who access, preview, download or reuse data and metadata from the DesignSafe Data Depot Repository (DDR) agree to the following policies. If these policies are not followed, we will notify the user of the infringement and may cancel their DesignSafe account.
+The DesignSafe DDR is hosted at the University of Texas at Austin, Texas Advanced Computing Center (TACC). A DesignSafe user account is a TACC user account. When registering for an account, TACC collects users' name, email address, institution, and country of citizenship. Additionally, after account approval and subsequent login to DesignSafe, DesignSafe collects your Natural Hazard Interests, Technical Domain, Professional Level and Research Activities.
 
-<ul>
-	<li>Use of the data includes, but is not limited to, viewing parts or the whole of the content; comparing with data or content in other datasets; verifying research results and using any part of the content in other projects, publications, or other related work products.</li>
-	<li>Users will not use the data in any way prohibited by applicable laws, distribution licenses, and permissions explicit in the data publication landing pages.</li>
-	<li>The data are provided “as is,” and its use is at the users' risk. While the DDR promotes data and metadata quality, the data authors and publishers do not guarantee that:
-	<ol>
-		<li>the materials are accurate, complete, reliable or correct;</li>
-		<li>any defects or errors will be corrected;</li>
-		<li>the materials and accompanying files are free of viruses or other harmful components; or</li>
-		<li>the results of using the data will meet the user’s requirements.</li>
-	</ol>
-	</li>
-	<li>Use of data in the DDR abides by the DesignSafe Privacy Policy.</li>
-	<li>Users are responsible for abiding by the restrictions outlined by the data author in their publications' landing pages and by the DDR in this agreement, but they are not responsible for any restrictions not otherwise explicitly described here or in the landing pages.</li>
-	<li>Users will not obtain personal information associated with DDR data that results in directly or indirectly identifying research subjects, individuals, or organizations with the aid of other information acquired elsewhere.</li>
-	<li>Users will not in any event hold the DDR or the data authors liable for any and all losses, costs, expenses, or damages arising from use of DDR data or any other violation of this agreement, including infringement of licenses, intellectual property rights, and other rights of people or entities contained in the data.</li>
-	<li>We do not gather IP addresses about public users that preview or download files from the DDR.</li>
-	<li>Our system logs file actions completed by registered users in the DDR including previewing, downloading or copying published data to My Data or My Projects. We only use this information in aggregate for metrics purposes and do not link it to the user’s identity.</li>
-</ul>
+When users publish data or other products as authors and co-authors, their names, email address, and institution become publicly available in the dataset's landing page. This facilitates establishing contact with authors about the particulars of their datasets publications.
 
-#### Amends and Version Control { #versioncontrol }
+When a user accesses DesignSafe, the web server software generates log files of the IP address of their computer and the user-agent, which contains minimal information about their browser and operating system. If the user is logged to DesignSafe, their username is also recorded. When a user downloads a file from the DDR, our software collects the aforementioned data and accompanying download data such as the time of the download and files downloaded. The aforementioned data is available to DesignSafe web programmers and data analysts to help diagnose problems, manage the repository, respond to users requests and measure datasets usage.
 
-Users can amend and version their data publications. Since the DDR came online, we have helped users correct and or improve the metadata applied to their datasets after publication. Most requests involve improving the text of the descriptions, changing the order of the authors, and adding references of papers publised using the data in the project; users also required the possibility to version their datasets. Our amends and version control policy derives from meeting our users needs.
+Data collected during downloads, views, or copies of published datasets are used solely in aggregate to comply with [Make Data Count](https://makedatacount.org/learn-about-us/)) usage reporting standards. This information is processed and made publicly available in the datasets landing pages as [Unique Requests](/user-guide/curating/metrics#unique-requests) and [Unique Investigations](/user-guide/curating/metrics#unique-investigations) for purposes of showing the datasets usage. All data is retained in the logs and DDR's internal database as needed for business purposes. We do not share any personally identifiable information we collect or develop about users to any third parties for any purpose, unless required by law. Any reports we may share externally use unidentifiable, aggregated data.
 
-Changes allowed during amends are:
+DesignSafe only uses first-party cookies for authentication. We use cookies so that users don't have to re-authenticate every time they refresh the page and no PII is stored in those cookies. There are Google Analytics cookies that collect metrics about visitors, but the personally identifying pieces like IP addresses are anonymized. Users browsing habits are not tracked for advertising or marketing purposes.
 
-<ul>
-	<li>Adding Related Works such as a paper they published after the data.</li>
-	<li>Correct typos and or improve the abstract and the keyword list. </li>
-	<li>Correct or add an award.</li>
-	<li>Change the order of the authors.</li>
-</ul>
+Users are required to use [Multi-Factor Authentication (MFA)](https://docs.tacc.utexas.edu/basics/mfa/) as an additional security measure when logging to DDR. DDR has security measures to prevent loss of the data and information. See the [DesignSafe Cyber Security Policy](/user-guide/tools/advanced/cybersecurity/) for more details.
 
-If users need to add or delete files or change the content of the files, they have the opportunity to version their data publication. The following are the
+## Project Types / Data Models
 
-<ul dir="ltr">
-	<li>Versions will have the same DOI, and the title will indicate the version number. The decision to maintain the same DOI was agreed upon by our community to facilitate DOI management to data publishers and users.</li>
-	<li>Users will be able to view all existing versions in the publication's landing page. </li>
-	<li>The DOI will always resolve in the latest version of the publication. </li>
-	<li>Versions are documented by data publishers so other users understand what changed and why. The documentation is publicly displayed </li>
-</ul>
+To publish their datasets users should select a project type that best represents the research method that they used to generate their dataset. Project types facilitate data curation and enable a uniform publication experience and representation of natural hazards datasets. Project types are based on five data models encompassing: experimental, simulation, field research, hybrid simulation, research software, and other datasets as well as lists of specialized vocabulary.  Loosely based on the [Core Scientific Metadata Model](http://icatproject-contrib.github.io/CSMD/), these models were designed in collaboration with natural hazards researchers considering the [community's use of different research methods and workflows](https://www.youtube.com/watch?v=iYzvYi-SY8Q), and [the need to document the processes](https://www.youtube.com/watch?v=xUyFJwZmyqM) from which data derives using professional terms. 
 
-Documentation of versions requires including the name of the file/s changed, removed or added, and identifying within which category they are located. We include guidance on how to document versions within the curation and publication onboarding instruction.
+Data models are implemented as interactive functions in the DDR web interface and include onboarding  instructions that guide the researchers through the curation and publication tasks. As researchers move through curating and publishing, the interactive features reinforce data and metadata completeness and thus enhance the quality of the datasets. The process will not move forward if requirements for metadata are not fulfilled or if key files are missing.
 
-The Fedora repository manages all amends and versions so there is a record of all changes. Version number is passed to DataCite as metadata.
+Data models are reviewed and improved upon regularly for changes or additions. 
 
-More information about the reasons for amends and versioning are in [Publication Best Practices](/user-guide/curating/bestpractices/#data-publication).
+## Protected Data
 
-#### Leave Data Feedback { #feedback }
+Protected data are information subject to regulations under relevant privacy and data protection laws, such as [HIPAA](https://www.hhs.gov/hipaa/for-professionals/privacy/laws-regulations/index.html), [FERPA](https://studentprivacy.ed.gov/faq/what-ferpa) and [FISMA](https://csrc.nist.gov/projects/risk-management/detailed-overview), as well as human subjects data containing [Personally Identifiable Information (PII)]https://cloud.wikis.utexas.edu/wiki/spaces/utldigitalstewardship/pages/43060649/Identifying+and+removing+personally+identifiable+information+PII) and data containing [sensitive information](https://en.wikipedia.org/wiki/Information_sensitivity). 
 
-Users can click a “Leave Feedback” button on the projects’ landing pages to provide comments on any publication. This feedback is forwarded to the curation team for any needed actions, including contacting the authors. In addition, it is possible for users to message the authors directly as their contact information is available via the authors field in the publication landing pages. We encourage users to provide constructive feedback and suggest themes they may want to discuss about the publication in our [Leave Data Feedback Best Practices](/user-guide/curating/bestpractices/#feedback).
+In the DDR protected data issues are considered at the onset of the curation and publication process and before data is uploaded to the repository. Researchers working with human subjects data are prompted to respond if they are working with protected data  at the moment of selecting field research and other project types to curate and publish their data. If the answer is yes  a curator will get  in touch with them to discuss options and procedures.
 
-#### Data Impact { #impact }
+Considerations about protected data emerge both during data management prior to and during curation and publication stages . 
 
-We understand data impact as a strategy that includes complementary efforts at the crossroads of data discoverability, usage metrics, and scholarly communications.
+### Managing Protected Data
 
-<strong>Search Engine Optimization (SEO)</strong>
+Managing protected data in the DDR involves complying with the data storage and publication procedures approved by the authors' Institutional Review Board (IRB) or equivalent body regarding human subjects research.
 
-We have in place SEO methods to enhance the web visibility of the data publications. To increase discoverability and indexing of our publications  we follow guidance from <a href="https://developers.google.com/search/docs">Google Search Console</a> and <a href="https://developers.google.com/search/docs/data-types/dataset">Google Data Search</a>.
+Protected data should be anonymized before uploading to DDR. 
 
-<strong>Data Usage Metrics</strong>
+DesignSafe My Data and My Projects are secure spaces to store  protected data as long as it is not under HIPAA, FERPA or FISMA regulations. If data needs to comply with these regulations, researchers must evaluate the need to use [TACC‘s Protected Data Service](https://www.tacc.utexas.edu/protected-data-service). Very sensitive data, PII data prior to anonymization, and data that will never be anonymized can also be stored and processed within TACC's Protected Data Service. Researchers requiring this service are welcome to send a [ticket](http://www.designsafe-ci.org/help/new-ticket) or join [curation office hours](https://www.designsafe-ci.org/facilities/virtual-office-hours/)
 
-Our metrics follow the Make your Data Count <a href="https://www.projectcounter.org/code-practice-research-data/">Counter Code of Practice for Research Data.</a>
+Note that the responsibility to maintain datasets within TACC’s Protected Data Service  lies on the authors. 
 
-Below are the definitions for each metric:
+### Publishing Protected Data
 
-<strong>File Preview:</strong> Examining data in the portal such as clicking on a file name brings up a modal window that allows previewing files. Not all document types can be previewed. Among those that can are: text, spreadsheets, graphics and code files. (example extensions: .txt, .doc, .docx, .csv, .xlsx, .pdf, .jpg, .m, .ipynb). Those that can't include binary executables, MATLAB containers, compressed files, and video (eg. .bin, .mat, .zip, .tar, mp4, .mov).
+Do not publish HIPAA, FERPA, FISMA, PII data, data including sensitive information, and any related documentation (reports, planning documents, field notes, etc.) data unless you have obtained the proper informed consents, and have abided by the permissions and requirements established by your IRB. 
 
-<strong>File Download:</strong> Copying a file to the machine the user is running on, or to a storage device that machine has access to. This can be done by ticking the checkbox next to a document and selecting "Download" at the top of the project page. With documents that can be previewed, clicking "Download" at the top of the preview modal window has the same effect. Downloads are counted per project and per individual files. We also consider counts of copying a file from the published project to the user's My data, My projects, or to Tools and applications in DesignSafe or one of the connected spaces (Box, Dropbox, Google Drive). Tick the checkbox next to a document and select "Copy" at the top of the project page.
+Protected data can only be published if identifying information is removed. No direct identifiers and up to three indirect identifiers are allowed. Direct identifiers include items such as participant names, participant initials, facial photographs, home addresses, phone number, email, vehicle identifiers, biometric data, names of relatives, social security numbers and dates of birth or other dates specific to individuals. Indirect identifiers are identifiers that, taken together, could be used to deduce someone’s identity. Examples of indirect identifiers include gender, household and family compositions, places of birth, or year of birth/age, ethnicity, general geographic indicators like postal code, socioeconomic data such as occupation, education, workplace or annual income.
 
-<strong>File Requests: </strong>Total file downloads + total file previews.
+Researchers should also publish the documentation showing the IRB resolution.  If a researcher has obtained consent from the subjects to publish PII, it should be clearly stated in the publication description. In this way users can clearly understand the restrictions imposed on the protected data. 
 
-<strong>Project Downloads: </strong>Total downloads of a compressed entire project to a user's machine.
+Providing that any form of protected information is removed, the corresponding research instruments such as questionnaires and surveys should be published along with the data so that other users understand the data provenance. 
 
-We report the metrics in the publications landing pages. To provide context to the metrics, we indicate the total amount of files in each publication.
+If a researcher needs to restrict public access to data because it includes HIPAA, FERPA, or other sensitive information, or if de-identification precludes the data from being meaningful, it is possible to publish the dataset as Restricted. The Restricted dataset publication will include metadata,  a summary or aggregation of the data,  as well as corresponding research instruments and code book if applicable. IRB documentation should be also included.  In cases where the authors wish to share the datasets with other researchers under certain conditions, they can consult with the DDR curator  and publish those conditions. Users interested in the restricted dataset can contact the project PI and other members through their published email address to request access to the data and to discuss the conditions for its reuse. Note that the responsibility of maintaining and managing a restricted dataset lies on the authors
 
-We started counting since May 17, 2021. We update the reports on a monthly basis and we report data metrics to NSF every quarter. Currently we are in the process of formatting the reports to participate in the Make your Data Count initiative.
+For an example of restricted access and conditions see the following dataset: 
 
-<strong>Data Vignettes</strong>
+Errett, N., C. Hartwell, J. Randazza, G. Bratman, D. Eisenman, B. Ellis, E. Goodsell, C. Levy (2023). "An Exploratory Study of Perspectives from Forest Therapy Guides in a Wildfire Affected Community.", in Forest therapy as a trauma-informed approach to disaster recovery \[Version 2\]. DesignSafe-CI. [https://doi.org/10.17603/ds2-sffr-0489](https://doi.org/10.17603/ds2-sffr-0489)
 
-Since 2020 we conduct <a href="https://www.designsafe-ci.org/use-designsafe/impact-of-data-reuse/">Data Reuse Vignettes</a>. For this, we identify published papers and interview researchers that have reused data published in DDR. In this context, reuse means that researchers are using data published by others for purposes different than those intended by the data creators. During the interviews we use a semi-structured questionnaire to discuss the academic relevance of the research, the ease of access to the data in DDR, and the understandability of the data publication in relation to metadata and documentation clarity and completeness.  We feature the data stories on the DesignSafe website and use the feedback to make changes and to design new reuse strategies. The methodology used in this project was presented at the International <a href="http://qqml.org/event/qqml-2020/">Qualitative and Quantitative Methods in Libraries 2020 International Conference</a>. See <a href="http://qqml.org/wp-content/uploads/2017/09/Book-of-Abstracts-26-5-2020-.pdf">Perspectives on Data Reuse from the Field of Natural Hazards Engineering</a>.
+In DDR, data with granular geographical locations including images that capture humans that are not the focus of the research and would not fall under the purview of an IRB (e.g. StretView, Geolocated imagery) are  considered sensitive and its publication needs to be discussed with the data curator. For example, researchers conducting field observations may capture human subjects in their documentation including work crews, passersby, or people affected by the disaster. If camera instruments capture people that are in the observed areas incidentally, we recommend that their faces and any [PII](https://www.technology.pitt.edu/help-desk/how-to-documents/guide-identifying-personally-identifiable-information-pii) is anonymized/blurred before publishing. In the case of images of team members, make sure they are comfortable with making their images public. Do not include roofing/remodeling records containing any form of PII. When those are public records, researchers should point to the site from which they are obtained using the Referenced Data and Software field. 
 
-<strong>Data Awards</strong>
+It is the user’s responsibility to adhere to these policies and the standards and resolution of their IRB. DesignSafe will not be held liable for any violation regarding improper publication of protected data. User uploads that we are notified of that violate this policy may be removed from the DDR with or without notice, and the user may be asked to suspend their use of the DDR and other DesignSafe resources. We may also contact the user’s IRB and/or other respective institution with any cases of violation, which could incur in an active audit of the research project, so users should review their institution’s policies regarding publishing with protected data before using DesignSafe and DDR. For clarification purposes researchers should contact DDR through a [help ticket](http://www.designsafe-ci.org/help/new-ticket) or join [curation office hours](https://www.designsafe-ci.org/facilities/virtual-office-hours/) any time across the curation of this type of data .
 
-In 2021 we launched the first<a href="https://www.designsafe-ci.org/community/news/2020/december/designsafe-announces-data-publishing-awards/"> Data Publishing Award</a> to encourage excellence in data publication and to stimulate reuse. Data publications are nominated by our user community based on contribution to scientific advancement and curation
-### Data Preservation
+## Publication Granularity  
 
-Data preservation encompasses diverse activities carried out by all the stakeholders involved in the lifecycle of data, from data management planning to data curation, publication and long-term archiving. Once data is submitted to the Data Depot Repository (DDR) we have functionalities and [Guidance](/user-guide/curating/policies/#data-preservation) in place to address the long-term preservation of the submitted data.
+Based on the way in which research methods and projects are implemented in the natural hazards community, the DDR’s data model structure considers  a research project type at the top level, and the possibility to publish one or more dataset within each project. The exception to this policy is  project type Other which allows only one dataset publication with a DOI. In addition users can publish Research Software and Document Collections including reports and survey instruments, as stand alone publications with their own DOI. The former within any project type, and the latter only within the Field Research type. 
 
-The DDR has been operational since 2016 and is currently supported by the NSF from October 1st, 2020 through September 30, 2025. During this award period, the DDR will continue to preserve the natural hazards research data published since its inception, as well as supporting preservation of and access to legacy data and the accompanying metadata from the Network for Earthquake Engineering Simulation (NEES), a NHERI predecessor, dating from 2005. The legacy data comprising 33 TB, 5.1 million files,2 and their metadata was transferred to DesignSafe in 2016 as part of the conditions of the <a href="https://www.nsf.gov/pubs/2014/nsf14605/nsf14605.htm">original grant</a>. See NEES data <a href="https://www.designsafe-ci.org/data/browser/public-legacy/" target="_blank">here</a>.
+To enhance contextual information by pointing to the relations of the published datasets, users can link between internal and external datasets, corresponding publications and software, and other references through the fields Related Work and Referenced Data and Software. 
 
-Data in the  (DDR) is preserved according to state-of-the art digital library standards and best practices. DesignSafe is implemented within the reliable, secure, and scalable storage infrastructure at the Texas Advanced Computing Center (TACC), with 20 years of experience and innovation in High Performance Computing. TACC is currently over 20 years old, and TACC and its predecessors have operated a digital data archive continuously since 1986 – currently implemented in the <a href="https://www.tacc.utexas.edu/systems/corral" target="_blank">Corral</a> Data Management system and the <a href="https://www.tacc.utexas.edu/systems/ranch" target="_blank">Ranch</a> tape archive system, with capacity of approximately half an exabyte. Corral and Ranch hold the data for DesignSafe and hundreds of other research data collections. For details about the digital preservation architecture and procedures for DDR go to [Data Preservation Best Practices](/user-guide/curating/bestpractices/#data-preservation).
+## Subsequent Publishing
 
-Within TACC’s storage infrastructure a <a href="https://duraspace.org/fedora/" target="_blank">Fedora</a> repository, considered a standard for digital libraries, manages the preservation of the published data. Through its functionalities, Fedora assures the authenticity and integrity of the digital objects, manages versioning, identifies file formats, records preservation events as metadata, maintains RDF metadata in accordance to standard schemas, conducts audits, and maintains the relationships between data and metadata for each published research project and its corresponding datasets. Each published dataset in DesignSafe has a Digital Object Identifier, whose maintenance we understand as a firm commitment to data persistence.
+DDR enables  publishing datasets subsequently within a project, and each dataset will bear a unique DOI. This arises from the longitudinal and tiered structure of some research projects such as experiments and field research missions which may happen over time, may involve different teams, and may require the publication of different types of resources ( software, documentation, or subsequent datasets). While users may publish more than one dataset at the same time, subsequent publications are enabled in My Project where users can create new experiments, simulations, missions, document collections, or hybrid simulations and publish them over time. Project type Other does not allow subsequent publishing. 
 
-While at the moment DDR is committed to preserve data in the format in which it is submitted, we procure the necessary authorizations from users to conduct further preservation actions as well as to transfer the data to other organizations if applicable. These permissions are granted through our [Data Publication Agreement](/user-guide/curating/policies/#agreement), which authors acknowledge and have the choice to agree to at the end of the publication workflow and prior to receiving a DOI for their dataset.
+## Timely Data Publication
 
-Data sustainability is a continuous effort that DDR accomplishes along with the rest of the NHERI partners. In the natural hazards space, data is central to new advances, which is evidenced by the data reuse record of our community and the following initiatives:
+As an NSF-funded platform we expect researchers to publish in a timely manner. Recommended time limits for publishing different project types were crafted considering time required for curating the data as well as the urgency with which field research datasets are required by users.
 
-<ul>
-	<li>Data reuse cases: <a href="https://www.designsafe-ci.org/use-designsafe/impact-of-data-reuse/" target="_blank">https://www.designsafe-ci.org/use-designsafe/impact-of-data-reuse/</a></li>
-	<li>DesignSafe Dataset Awards: <a href="https://www.designsafe-ci.org/community/news/2021/march/dataset-awards/" target="_blank">www.designsafe-ci.org/community/news/2021/march/dataset-awards</a></li>
-	<li>Data requirements for AI Session at: “Workshop on Artificial Intelligence in Natural Hazards Engineering.”<a href="https://doi.org/10.17603/ds2-f1nd-9s05" target="_blank"> https://doi.org/10.17603/ds2-f1nd-9s05</a></li>
-	<li>Converge Data Ambassadors: <a href="https://converge.colorado.edu/data/events/publish-your-data/data-ambassadors" target="_blank"> https://converge.colorado.edu/data/events/publish-your-data/data-ambassadors</a></li>
-	<li>Identifying Data Guideline Needs for Community and Regional Resilience Modelling Workshop: <a href="http://resilience.colostate.edu/files/DATA/Agenda_DATA_20210316.pdf" target="_blank">http://resilience.colostate.edu/files/DATA/Agenda_DATA_20210316.pdf</a></li>
-</ul>
+Recommended Publishing Timeline for Different Data Types:
 
-#### Continuity of Access { #continuity }
+| Project/Data Type | Recommended Publishing Timeline |
+| --- | --- |
+| Experimental | Up to 12 months from completion of experiment |
+| Simulation | Up to 12 months from completion of simulations |
+| Reconnaissance: Immediate Post-Disaster | Up to 3 months from returning from the field |
+| Reconnaissance: Follow-up Research | Up to 6 months from returning from the field |
 
-As part of the requirements of the current award we have a contingency pan in place to transfer all the DDR data, metadata and corresponding DOIs to a new awardee (should one be selected) without interruption of services and access to data. Fedora has <a href="https://wiki.lyrasis.org/display/FEDORA50/Import+and+Export+Tools">export capabilities </a>for transfer of data and metadata to another repository in a complete and validated fashion. The  portability plan is confirmed and updated in the Operations Project Execution Plan that we present anually to the NSF.
+For guidelines specific to RAPID reconnaissance data, see [Using RAPID: Publishing Guidelines](https://rapid.designsafe-ci.org/using-rapid/publishing-guidelines). 
 
-In the  case in which the NSF and/or the other stakeholders involved in this community decide not to continue the NHERI program or a subsequent data repository, we will continue to preserve the published data  and provide access to it through TACC, DesignSafe’s host at the University of Texas at Austin. TACC has formally committed to preserving the data with landing pages and corresponding DOIs indefinitely. TACC has on permanent staff a User Services team as well as curators that will attend users’ requests /and help tickets related to the data. Because TACC is constantly updating its high-performance storage resources and security mechanisms, data will be preserved at the same  preservation level that is currently available. Considering that DOIs are supported through the University of Texas Libraries and that the web services and the data reside within TACC’s managed resources, access to data will not be interrupted. Fedora is now part of TACC’s software suite and we will continue its maintenance as our preservation repository. Like with all systems at TACC, we will revisit its versioning and continuity and make decisions based on state-of-the-art practices. Should funding constraints ever make this no longer possible, TACC will continue to keep an archive copy on Ranch (with landing pages on online storage) for as long as TACC remains a viable entity.
+## Tombstone
 
+A tombstone is a landing page that describes a dataset that has been removed from public access. Removal of datasets can be caused because of research retraction, because the data is not compliant with the accepted Data Types, or upon curation review because it does not meet with one or more Curation Policy or Best Practices. In the latter case the curator reviewing the dataset will first alert the author/s to improve their publication within 30 days, upon which the dataset will be tombstoned. A tombstoned landing page contains the data citation and the DOI, but the dataset is not accessible.
diff --git a/user-guide/docs/data-depot/curate-and-publish.md b/user-guide/docs/data-depot/curate-and-publish.md
new file mode 100644
index 00000000..a1980d93
--- /dev/null
+++ b/user-guide/docs/data-depot/curate-and-publish.md
@@ -0,0 +1,5 @@
+# What is Data Curation?
+
+Data curation involves the organization, description, quality control, preservation, accessibility, and ease of reuse of data, with the goal of making your data publication [FAIR](https://www.go-fair.org/fair-principles/) and assuring that it will be useful for generations to come.
+
+Step-by-step data curation instructions can be found in [How to Curate Data?](/user-guide/curating/guides.md), and we strongly recommend following the onboarding instructions in the My Project curation and publication interface. We are available for additional help during our [Virtual Office Hours](https://www.designsafe-ci.org/facilities/virtual-office-hours/) and via [help tickets](https://www.designsafe-ci.org/help/submit-ticket/). The [DDR Policies](/user-guide/curating/policies/) communicate requirements for managing and publishing data. General curation best practices exist for [Curation Quality](/user-guide/curating/bestpractices/#curation-quality) and [Curating Various Types of Research Data](/user-guide/curating/bestpractices/#curating-various-types-of-research-data).
diff --git a/user-guide/docs/data-depot/resources.md b/user-guide/docs/data-depot/resources.md
new file mode 100644
index 00000000..aab24f25
--- /dev/null
+++ b/user-guide/docs/data-depot/resources.md
@@ -0,0 +1,63 @@
+# Resources for Users
+
+!!! caution "Content Undecided"
+    Much of this page is incomplete. We might not use this page.
+
+## Frequently Asked Questions
+
+!!! caution "Content Undefined"
+    Should this introduce some F.A.Q. and/or link to it?
+
+## Data Management Plan
+
+Depositing your data and other resources such as documentation and research software in the DDR meets NSF requirements for data management. See our [Data Management Plan](/user-guide/getting-started/manage-data/#data-management-plan).
+
+## Data and Intellectual Property
+
+!!! caution "Content Undefined"
+    What content belongs here?
+
+## Support and Contact Information
+
+!!! caution "Content Undefined"
+    Should this introduce the Support and Contact Information and/or link to it?
+
+## DesignSafe Office Hours
+
+DesignSafe [Virtual Office Hours](https://designsafe-ci.org/facilities/virtual-office-hours/) is the newest way to connect with experts in the NHERI network.
+
+## Resources for Protected Data
+
+The following de-identification resources for processing protected data. The NISTIR 8053 publication [De-Identification of Personal Information](https://nvlpubs.nist.gov/nistpubs/ir/2015/NIST.IR.8053.pdf) provides all the definitions and approaches to reduce privacy risk and enable research. Another [NIST resource](https://www.nist.gov/itl/applied-cybersecurity/privacy-engineering/collaboration-space/focus-areas/de-id) including de-identification tools. John Hopkins Libraries Data Services [Applications to Assist in De-identification of Human Subjects Research Data](https://dataservices.library.jhu.edu/resources/applications-to-assist-in-de-identification-of-human-subjects-research-data/)
+
+CONVERGE has a series of [check sheets](https://converge.colorado.edu/resources/check-sheets/ethical-considerations/) that outline how researchers should manage data that could contain sensitive information; these check sheets have also been published in [the DDR](http://doi.org/10.17603/ds2-7r74-1021)
+
+!!! danger "Broken Link"
+    The [Data Curation Primers](https://datacurationnetwork.org/outputs/data-curation-primers/) link is broken yet this whole paragraph is about that resource...
+
+In addition, we suggest that users look into the [Data Curation Primers](https://datacurationnetwork.org/outputs/data-curation-primers/) from the Data Curation Network, which are "peer-reviewed, living documents that detail a specific subject, disciplinary area or curation task, and that can be used as a guidelines to curate research data. The primers include curation practices for documenting data types that while not open or recommended, are very established in the academic fields surrounding Natural Hazards research such as Matlab and Microsoft Excel.
+
+!!! caution "Needs Review"
+    How to introduce this random link?
+
+[https://www.copyright.gov/circs/circ33.pdf](https://www.copyright.gov/circs/circ33.pdf) 
+
+## Exemplary Datasets
+
+!!! caution "Needs Review"
+    "Need to review this list now." — M.E.
+
+Below are examples of good organization and description for different dataset types:
+
+!!! caution "Formatting Uncertain"
+    Should this be a nested list, a table, sub-headings and lists? Is it supposed to be [the user guide dictionaries](/user-guide/dictionary/)?
+
+* Experimental
+* Simulation
+* Hybrid Simulation
+* Field Research
+    * [Expert Survey on Community Resilience Testbed Use and Development (Social Science)](https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3333)
+* Interdisciplinary 
+* Other
+    * Pretell, R., S. Brandenberg, J. Stewart (2023). Consistently computed ground motion intensity measures for liquefaction triggering assessment. DesignSafe-CI. [https://doi.org/10.17603/ds2-6vj1-t096](https://doi.org/10.17603/ds2-6vj1-t096)
+    * Peek, L., E. Hines, M. Mathews, J. Gunderson, H. Wu (2020). Global Academic Hazards and Disaster Research Centers Data. DesignSafe-CI. [https://doi.org/10.17603/e9wq-gz57](https://doi.org/10.17603/e9wq-gz57)
diff --git a/user-guide/docs/datadepot.md b/user-guide/docs/datadepot.md
index 20d9632a..c8ca936f 100644
--- a/user-guide/docs/datadepot.md
+++ b/user-guide/docs/datadepot.md
@@ -1,14 +1,5 @@
-# DesignSafe Data Depot
+# Data Depot
 
-The <a href="https://www.designsafe-ci.org/data/browser/public/" target="_blank">Data Depot</a> is the data repository for DesignSafe. The web interface to the Data Depot allows you to browse, upload, download, share, curate and publish data stored within the repository. You are encouraged to use the Data Depot not only for curation and publication of research results, but as a working "scratch" area for any of your own data and work in progress. Scientific applications in the <a href="https://www.designsafe-ci.org/workspace/" target="_blank">Tools & Applications</a> area can access your Data Depot files, enabling data analysis directly in the DesignSafe portal that minimizes the need to transfer data to your laptop. The Data Depot hosts both public and private data associated with a project, with the following directories:
+{% include-markdown './redirect.md' %}
 
-* **My Data**: Private directory for your data.
-* **HPC Work**: Work directory on TACC HPC machines for use with Jupyter.
-* **My Projects**: Data to be curated and published must be in this directory. Also has group access that you control.
-* **Shared with Me**: DEPRECATED. Use My Projects. Legacy directory we are no longer utilizing, but some very early users may have data. 
-* **Box.com**: Access to your Box files for copying to DesignSafe.
-* **Dropbox.com**: Access to your Dropbox for copying to DesignSafe.
-* **Google Drive**: CURRENTLY NOT FUNCTIONAL. Google has made changes that we are working through to reenable.
-* **Published**: Curated data/projects with DOI's.
-* **Published (NEES)**: Curated data/projects from NEES program that ran from 1999 - 2015.
-* **Community Data**: Non-curated user-contributed data.
+- **Data Depot** section of the navigation
diff --git a/user-guide/docs/datadepotrepo/about.md b/user-guide/docs/datadepotrepo/about.md
index 4be0ee2c..b76d9924 100644
--- a/user-guide/docs/datadepotrepo/about.md
+++ b/user-guide/docs/datadepotrepo/about.md
@@ -1,40 +1,59 @@
-# About
+# About the Data Depot
+
 
 ## Mission
-The mission of the Data Depot Repository (DDR) is to provide data producers with an open repository to safely store, share, and curate natural hazards research data, ensuring its permanent publication, distribution, and impact evaluation. DDR enables users to discover, search, access, and reuse data, thereby accelerating research discoveries. DDR is a component of the DesignSafe cyberinfrastructure which represents a comprehensive open science research environment that provides cloud-based tools to manage, analyze, understand, and publish critical data to understand the impacts of natural hazards. DesignSafe is part of the NSF-supported [Natural Hazards Engineering Research Infrastructure (NHERI)](https://designsafe-ci.org/about/), and aligns with its mission to provide the  natural hazards research community with open access, shared resources aimed at supporting civil and social infrastructures prior to, during, and following natural disasters.
+
+The Data Depot Repository (DDR) is one component of the DesignSafe cyberinfrastructure, which represents a comprehensive research environment that provides cloud-based tools to manage, analyze, understand, and publish critical data for research to understand the impacts of natural hazards. DDR is the platform for curation and publication of datasets generated in the course of natural hazards research. It is an open access repository that enables data producers to safely store, share, organize, and describe research data, and assigns Digital Object Identifiers towards permanent publication and distribution of datasets. The DDR allows data consumers to discover, search for, access, and reuse published data to accelerate research discovery. DDR monitors datasets usage and citations over time to communicate their impact.  DesignSafe is part of the NSF-supported Natural Hazards Engineering Research Infrastructure (NHERI), and aligns with its mission to provide the natural hazards research community with open access, shared-use scholarship, education, and community resources aimed at supporting civil infrastructure prior to, during, and following natural disasters. DesignSafe also supports the broader natural hazards research community that extends beyond the NHERI network.
+
 
 ## History
-Founded in 2016, the DDR was established as an [open-access](https://www.openaccess.nl/en/what-is-open-access) data repository. Supported by the [National Science Foundation](https://www.nsf.gov/), it preserves and provides access to natural hazards research data including [legacy datasets](https://designsafe-ci.org/data/browser/public/nees.public) dating back to 2005 generated under the NSF-supported Network for Earthquake Engineering Simulation (NEES), the predecessor to NHERI. Since 2022 DDR is a [Core Trust Seal Certified Data Repository](https://www.coretrustseal.org/wp-content/uploads/2023/01/20230126-designsafe_final.pdf) ensuring the sustainability and trustworthiness of its infrastructure and the data it preserves. The certification is current until 2026.
 
-## Governance 
-DDR governance aims to ensure effective and secure data curation and publication in compliance with relevant regulations and best practices, supporting the discovery, access, preservation and reuse of critical research data. Governance is managed by the DesignSafe management team, which is responsible for setting and updating policies, recommending best practices, overseeing technical development, and prioritizing key activities and services encompassing datasets, systems, and processes associated with the DDR. All activities are driven by the research community of practice operationalized by the NHERI network, and informed by digital library standards. The broad organizational structure under which the DDR operates is shown on [About NHERI DesignSafe](https://designsafe-ci.org/about/designsafe/).
+The DDR has been in operation since 2016 and is currently supported by NSF through 2025. The DDR preserves natural hazards research data published since its inception, and also provides access to legacy data dating from about 2005. These legacy data were generated as part of the NSF-supported Network for Earthquake Engineering Simulation (NEES), a predecessor to NHERI. Legacy data and metadata belonging to NEES were transferred to the DDR for continuous preservation and access. [View the published NEES data.](https://designsafe-ci.org/data/browser/public/nees.public)
+
+
+## Governance
 
-An Advisory Board provides strategic guidance and feedback on DesignSafe's initiatives and activities. Established with 7 members representing the broader natural hazards community, the board holds bi-annual meetings and helps shape the DDR's direction, ensuring it meets the evolving needs and challenges of the natural hazards community. More information on the board can be found here.
+Policies for the DDR are driven by the Natural Hazards  scientific community and informed by best practices in library and information sciences. The DDR operates under the leadership of the DesignSafe Management Team, which establishes and updates policies, evaluates and recommends best practices, oversees its technical development, and prioritizes activities. The broad organizational structure under which the DDR operates is shown on [About NHERI DesignSafe](https://designsafe-ci.org/about/designsafe/).
 
-Formal mechanisms are in place for external evaluators to gather feedback and conduct structured assessments in the form of usability studies and yearly user surveys. To ensure that the repository is meeting the community’s needs there are different feedback mechanisms for users to provide input and suggest enhancements, and processes in place for evaluation of those requests and implementation of updates. All DDR activities are reported to the National Science Foundation on a quarterly and annual basis in terms of quantitative and qualitative progress.
 
 ## Infrastructure
-DesignSafe including DDR are hosted at the [Texas Advanced Computing Center](https://tacc.utexas.edu/)(TACC)at the [University of Texas at Austin](https://www.utexas.edu/). TACC provides access to high performance computing, visualization, and large scale data analysis computational resources, as well as to reliable large scale data management and storage solutions. Cloud and portal services further increase the ways in which users can access data and computational resources to advance their work.
 
-## Repository Team 
-An interdisciplinary repository team carries out ongoing design, development, and day-to-day operations of the DDR. The team gathers requirements and discusses solutions through bi-monthly meetings with members of the DesignSafe management team as well as with members of the [NHERI network](https://designsafe-ci.org/about/) to meet the requirements and commitments of their distinct research focus and functions. To track development the DDR curator meets every other week with the DesignSafe PI and with the head of the development team. Based on these fluid communications, the team designs functionalities, researches and develops best-practices, and implements agreed-upon solutions. The figure below shows the current formation of the repository team.
+DesignSafe including DDR are hosted at the [Texas Advanced Computing Center (TACC)](https://tacc.utexas.edu/) at the [University of Texas at Austin](https://www.utexas.edu/). TACC provides access to high performance computing, visualization, and large scale data analysis computational resources, as well as to reliable large scale data management and storage solutions. Their cloud and portal services further increase the ways in which DesignSafe users can access data and computational resources to advance their work.
+
+
+## Team
+
+An interdisciplinary repository team carries out ongoing design, development and day-to-day operations, gathering requirements and discussing solutions through formal monthly and bi-weekly meetings, and maintaining regular communications with members of the network, including monthly meetings with the Experimental Facilities, RAPID, and CONVERGE staff. Based on these fluid communications, the RT designs functionalities, researches and develops best-practices, and implements agreed-upon solutions. The figure below shows the current formation of the repository team, including their expertise.
+
+![DesignSafe Data Depot Team Organization](./imgs/team-org.png)
 
-![Data Depot Team](imgs/Data_Repository_Team_DataTeam.png)
+Formal mechanisms are in place for external evaluators to gather feedback and conduct structured assessments, in the form of usability studies and yearly user surveys, to ensure that the repository is meeting the community’s expectations and needs. To track development the DDR curator meets every other week with the DesignSafe PI and with the head of the development team. All DDR activities are reported to the National Science Foundation on a quarterly and annual basis in terms of quantitative and qualitative progress.
 
-## Community of Practice
-The DDR serves the natural hazards research community, both data producers and consumers. This research community includes primarely the facilities that make up the [NHERI network](https://designsafe-ci.org/about/), for which the DDR is the designated data repository. In addition DDR welcomes data produced in other national and international facilities and organizations. At large, the repository serves a broad national and international audience of natural hazard researchers, students, practitioners, policy makers, as well as the general public. By providing access to a broad range of natural hazards data, DDR aims to support and accelerate research, education, and informed decision-making on a global scale.
 
 ## Community Norms
-The following set of Community Norms encompassing DDR's [Policies](/user-guide/curating/policies/) and [Best Practices](/user-guide/curating/bestpractices/) inform the conditions of usage of the DDR.
-
-* Users of DDR must abide by the [TACC Acceptable Use Policy](https://tacc.utexas.edu/use-tacc/user-policies/) and the [DesignSafe-CI Terms of Use](https://www.designsafe-ci.org/account/terms-conditions/) .
-* Users agree to publish open-access data, this is data that is freely available for anyone to use. 
-* Datasets and other resources should be published in a manner that does not hinder the ability of other users to reuse data or reproduce research by following the [Curation and Publication Best Practices](/user-guide/curating/bestpractices/).
-* Users publishing human subjects data should abide by our [Protected Data Policies](/user-guide/curating/policies/#data-publication-and-usage) which can be implemented following the [Protected Data Best Practices](/user-guide/curating/bestpractices/#data-publication).
-* Users publishing data agree to provide the [type of license](/user-guide/curating/policies/#licenses) needed to make data available for archiving and for reuse by others.
-* Users understand that their data submissions to the DDR should accept the [Data Publication Agreement](/user-guide/curating/policies/#agreement).
-* Users accessing and using DDR data agree to the [Data Usage Agreement](/user-guide/curating/policies/#datausage).
-* Users agree to use DDR datasets in ways that respect [the licenses](/user-guide/curating/policies/#licenses) established in the publications.
-* Users agree to properly cite the datasets they use in their works in accordance with the [Joint Declaration of Data Citation Principles](https://force11.org/info/joint-declaration-of-data-citation-principles-final/) by using the citations provided in the published datasets landing pages.
-* Using DDR to publish data is entirely voluntary. None of these terms supersede any prior contractual obligations to confidentiality or proprietary information the user may have with third parties; thus, the user is entirely responsible for what they upload or share with DDR. 
+
+Within the broader conditions of use for DesignSafe we have established a set of Community Norms specific for DDR which have to be agreed upon at the point of registering an account on the platform. These norms, highlighting our existing policies, are the following:
+
+Users who either publish and use data in DDR must abide by both the [TACC Acceptable Use Policy](https://tacc.utexas.edu/use-tacc/user-policies/) and the [DesignSafe Terms and Conditions](https://www.designsafe-ci.org/account/terms-conditions/).
+
+For users curating and publishing data in DDR:
+
+* Users understand that their data submissions to the DDR should follow our [Data Depot Repository Policies](/user-guide/curating/policies/) and our [Best Practices for Curation and Publication](/user-guide/curating/bestpractices/) 
+* Users agree to use DDR to publish open access data, which they must document in a manner that enables data reuse and research reproducibility.
+* In accordance with the [Joint Declaration of Data Citation Principles](https://force11.org/info/joint-declaration-of-data-citation-principles-final/)  and the [Software Citation Principles](https://force11.org/info/software-citation-principles-published-2016/), users reusing data and or research software of others in their data publications must properly cite them in the Referenced Data and Software field provided in the DDR interface.
+* Users agree to provide all the needed licenses and permissions to make data available for archiving and for reuse by others.
+* Users publishing human subjects data should abide by our [Protected Data Policy](/user-guide/curating/policies/#protected-data).
+* Using DDR to publish data is entirely voluntary. None of these terms supersede any prior contractual obligations to confidentiality or proprietary information the user may have with third parties; thus, the user is entirely responsible for what they upload or share with DDR. 
+* Publications that do not fall within these norms may be removed.
+
+For users using data published in DDR:
+
+* Users accessing and using DDR data agree to the following [Data Usage Agreement](/user-guide/curating/policies/#data-usage-agreement).
+* Users agree to use DDR resources in accessing and reusing open access data in ways that respect the [licenses](/user-guide/curating/policies/#licenses) and access restrictions established in the publications.
+* Users agree to properly cite the datasets they use in their works in accordance with the [Joint Declaration of Data Citation Principles](https://force11.org/info/joint-declaration-of-data-citation-principles-final/) using the citations provided in the published datasets landing pages.
 * We reserve the right to ask users to suspend their use of DDR should we receive complaints or note violations of these Community Norms.
+
+
+## CoreTrustSeal Certification
+
+The Data Depot Repository is evaluated for the [CoreTrustSeal](https://www.coretrustseal.org/) certification every three years. Established in 2017, CoreTrustSeal is a non-profit dedicated to advancing sustainable data infrastructure in repository management. It achieves this by requiring adherence to a set of criteria developed collaboratively by the Data Seal of Approval (DSA) and the World Data System of the International Science Council (WDS), under the umbrella of the Research Data Alliance (RDA). A CoreTrustSeal certification assures users that a repository has implemented essential safeguards for long-term data preservation and has received endorsement of its trustworthiness through a transparent, independent evaluation.
diff --git a/user-guide/docs/managingdata/datadepot.md b/user-guide/docs/managingdata/datadepot.md
index 4b34b156..59de1928 100644
--- a/user-guide/docs/managingdata/datadepot.md
+++ b/user-guide/docs/managingdata/datadepot.md
@@ -1,21 +1,6 @@
-## DesignSafe Managing Data
+# Managing Your Data
 
-### Browsing, Upload, and Download { #browsing }
+{% include-markdown '../redirect.md' %}
 
-![Figure 1. Data Depot](./imgs/datadepotfigure.jpg)
-
-Figure 1. Data Depot "My Data" screenshot
-
-The Data Depot provides a user interface with a familiar desktop metaphor for manipulating files. The UI for a typical Data Depot window is shown in Figure 1 above. On the left is your directory tree (My Data, etc), and on the right are the files and folders within the currently selected directory. Folders can be navigated simply by clicking on the name of the folders. Clicking on the name of a file will pop up a preview of the file.
-
-The Data Depot is searchable using the "Find in <DirectoryName>" search box  (The global website search box "Search DesignSafe" is above and to the right).
-
-Alongside the search, buttons are available for a number of file and folder actions. The Rename, Move, Copy, Download, etc. actions all behave as one would expect.
-
-Click on the blue "+Add" button above the list of directories to create a New Folder, a New Project in My Projects, to do a File Upload or a Folder upload or for Bulk Data Transfer instructions. Note that only Chrome supports browser-based Folder uploads.
-
-A number of data transfer methods are supported for uploading and downloading files. The [Data Transfer Guide](/user-guide/managingdata/datatransfer/) provides details regarding the various methods and recommendations based on the quantity and size of your files.
-
-### Data Sharing, Collaboration, Curation & Publication { #sharing }
-
-My Projects is the simplest way to share data with your collaborators and to curate and ultimately publish your data and receive a Digital Object Identifier (DOI). Any team member in a project has both read and write access to the entire contents of the project. The Data Curation & Publication User Guide provides instructions for creating projects, managing team members, curating and publishing your data.
+- [Transferring Your Data](/user-guide/managingdata/datatransfer/)
+- [How to Curate Data?](/user-guide/curating/guides/)
diff --git a/user-guide/docs/managingdata/datamanagementplan.md b/user-guide/docs/managingdata/datamanagementplan.md
index 41c3e0b7..0e566822 100644
--- a/user-guide/docs/managingdata/datamanagementplan.md
+++ b/user-guide/docs/managingdata/datamanagementplan.md
@@ -1,5 +1,3 @@
-# Data Management Plan Guidance
+# Data Management Plan Template
 
-This document is intended as a Data Management Plan (DMP) guide that you can customize for the specific details of your research project that will use the NHERI DesignSafe cyberinfrastructure (CI). There is guidance on the five main DMP areas required by the National Science Foundation (NSF), along with information about the DesignSafe CI functionalities that can support your data management needs.
-
-[Data Management Plan](../documents/DesignSafe_Data_Management_Plan_Guidance.docx)
+You can customize our [DesignSafe **Data Management Plan** Template](/user-guide/documents/DesignSafe_Data_Management_Plan_Guidance.docx) for the specific details of your research project that will use the NHERI DesignSafe cyberinfrastructure (CI). There is guidance on the five main DMP areas required by the National Science Foundation (NSF), along with information about the DesignSafe CI functionalities that can support your data management needs.
diff --git a/user-guide/docs/managingdata/datatransfer.md b/user-guide/docs/managingdata/datatransfer.md
index 4d3f306d..09ea035f 100644
--- a/user-guide/docs/managingdata/datatransfer.md
+++ b/user-guide/docs/managingdata/datatransfer.md
@@ -1,83 +1,98 @@
-## Data Transfer
+# Transferring Your Data
 
 DesignSafe supports multiple ways of moving data in and out of the Data Depot, the data transfer method that is best for you will depend on the quantity of data you wish to move. There are two broad categories of data transfer methods available; we will refer to these categories as large data transfer methods and normal data transfer methods. Large data transfer methods are for situations where you want to move a large amount of data (&gt; 2GB), a large numbers of files (&gt; 25), or folders. Whereas normal data transfer methods are for situations where you wish to move a small amount of data (&lt; 2GB) stored across a small number of files (&lt; 25).
 
 This document provides a brief description of the various methods available for moving data to and from DesignSafe to assist you in identifying the right data transfer method for your research needs. Once you have selected your data transfer method, each description concludes with a link to detailed instructions for initiating your transfer.
 
-### Recommended Data Transfer Methods { #recommended }
+## Recommended Methods { #recommended }
 
-#### Recommended Large Data Transfer Methods { #recommended-largedatatransfer }
+### for Large Datasets { #recommended-largedatatransfer }
 
 We define a large data transfer here as any file transfer that is  &gt; 2GB, or &gt; 25 files or &gt; 2 folders.
 
-1. Globus
+/// html | article.card--plain
+    markdown: block
 
-	Globus supplies high speed, reliable, and asynchronous transfers to DesignSafe. Once set up, Globus will allow you to not only transfer files to and from DesignSafe, but also other cyberinfrastructure resources at TACC and other research centers. While the setup of Globus can take slightly longer than the other transfer methods, setup only needs to be performed once, making later transfers as fast (if not faster due to Globus' superior speed) than the other methods. For these reasons, Globus is the recommended approach for moving large quantities of data to and from DesignSafe.
+**1. [Cyberduck](#cyberduck)**
 
-	See the <a href="#globus">Globus Data Transfer Guide</a> for instructions. If you need to perform automated transfers using Globus, see the <a href="#globuscli">Globus CLI Automated Transfer Guide</a> for instructions.
+Cyberduck is an open-source client for file transfer protocols that allows you to securely connect to DesignSafe and other TACC resources without directly using the command line. Cyberduck presents a compromise between a shorter setup time than Globus but at the expense of Globus' superior speed and reliability.
 
-1. Cyberduck (recommended)
+///
+/// html | article.card--plain
+    markdown: block
 
-	Cyberduck is an open-source client for file transfer protocols that allows you to securely connect to DesignSafe and other TACC resources without directly using the command line. Cyberduck presents a compromise between a shorter setup time than Globus but at the expense of Globus' superior speed and reliability.
+**2. [Globus](#globus) or [Globus CLI](#globuscli)**
 
-	See the <a href="#cyberduck">Cyberduck Data Transfer Guide</a> for instructions.
+Globus supplies high speed, reliable, and asynchronous transfers to DesignSafe. Once set up, Globus will allow you to not only transfer files to and from DesignSafe, but also other cyberinfrastructure resources at TACC and other research centers. While the setup of Globus can take slightly longer than the other transfer methods, setup only needs to be performed once, making later transfers as fast (if not faster due to Globus' superior speed) than the other methods. For these reasons, Globus is the recommended approach for moving large quantities of data to and from DesignSafe.
 
-1. Command Line
+_For automated transfers using Globus, follow [Globus CLI automated data transfer guide](#globuscli)._
 
-	Common command-line utilities, such as scp and rsync, may also be used to transfer large amounts of data to DesignSafe. Command line tools require the shortest setup time (assuming you have a compatible terminal), however are generally found challenging for first-time users. Therefore, command line transfers are only recommended in specific circumstances where other tools have been tried and found to be insufficient.
+///
+/// html | article.card--plain
+    markdown: block
 
-	See the <a href="#cli">Command-Line Data Transfer Guide</a> for instructions.
+**3. [Command Line Interface](#cli)**
 
-#### Recommended Normal Data Transfer Methods { #recommended-normaldatatransfer }
+Common command-line utilities, such as `scp` and `rsync`, may also be used to transfer large amounts of data to DesignSafe. Command line tools require the shortest setup time (assuming you have a compatible terminal), however are generally found challenging for first-time users. Therefore, command line transfers are only recommended in specific circumstances where other tools have been tried and found to be insufficient.
+
+///
+
+### for Normal Datasets { #recommended-normaldatatransfer }
 
 We define a "normal" data transfer as &lt; 2GB or  &lt; 25 files or &lt; 2 folders
 
-1. Data Depot's Browser-Based Interface
+/// html | article.card--plain
+    markdown: block
+
+**1. [Data Depot via Web Browser](#datadepotbrowser)**
 
-	The Data Depot's browser interface allows you to conveniently upload and download small quantities of data as well as move and copy data between directories.
+The Data Depot's browser interface allows you to conveniently upload and download small quantities of data as well as move and copy data between directories.
 
-	See below <a href="#datadepotbrowser">Data Depot's Browser-Based Data Transfer Guide</a> for instructions.
+///
+/// html | article.card--plain
+    markdown: block
 
-1. JupyterHub's Browser-Based Interface
+**2. [JupyterHub via Web Browser](#jupyterbrowser)**
 
-	Similar to the Data Depot's browser interface, the DesignSafe JupyterHub provides a convenient way to upload and download small amounts of data.
+Similar to the Data Depot's browser interface, the DesignSafe JupyterHub provides a convenient way to upload and download small amounts of data.
 
-	See below <a href="#jupyterbrowser">JupyterHub's Browser-Based Data Transfer Guide</a> for instructions.
+///
+/// html | article.card--plain
+    markdown: block
 
-1. Cloud Storage Provider (Dropbox)
+**3. [Cloud Storage Provider](#cloud) (e.g. Dropbox)**
 
-	DesignSafe provides the ability to directly transfer data to and from a cloud storage provider. DesignSafe currently supports integration with Dropbox. Note that DesignSafe does not synchronize your data with the cloud storage provider, it only enables transfers.
+DesignSafe provides the ability to directly transfer data to and from a cloud storage provider. DesignSafe currently supports integration with Dropbox. Note that DesignSafe does not synchronize your data with the cloud storage provider, it only enables transfers.
 
-	See <a href="#cloud">Cloud Storage Data Transfer Guide</a> below for instructions.
+///
 
 ---
 
-### Globus Data Transfer Guide { #globus }
+## Globus { #globus data-subtitle="Data Transfer Guide" }
 
 Globus supplies high speed, reliable, and asynchronous transfers to DesignSafe. Once setup, Globus will allow you to not only transfer files to and from DesignSafe, but also other cyberinfrastructure resources at TACC and other research centers. While the setup of Globus can take slightly longer than the other transfer methods, it only needs to be performed once, making later transfers as fast (if not faster due to Globus' superior speed) than the other methods. For these reasons, Globus is the recommend approach for moving large quantities of data to and from DesignSafe.
 
 The following provides detailed instructions for setting up Globus access to DesignSafe.
 
-#### 1. Log in to CILogon.org { #globus-step1 }
+### 1. Log in to CILogon.org { #globus-step1 }
 
-Log in to the CILogon service (<a href="https://CILogon.org">https://CILogon.org</a>). If your institution is already a member of CILogon you can search for your institution and use your institutional credentials to log in. Otherwise, you can search for ACCESS CI (XSEDE) and proceed to create an ACCESS account.
+Log in to the [CILogon service](https://CILogon.org). If your institution is already a member of CILogon you can search for your institution and use your institutional credentials to log in. Otherwise, you can search for ACCESS CI (XSEDE) and proceed to create an ACCESS account.
 
-
-#### 2. Find the ePPN associated with your CILogon/Globus access { #globus-step2 }
+### 2. Find the ePPN associated with your CILogon/Globus access { #globus-step2 }
 
 Globus requires a unique identifier, called a eduPersonPrincipalName (ePPN), for each user.
 
 Find your ePPN associated with your Globus access by going to https://cilogon.org/ and logging in. You will find your ePPN under User Attributes
 
-#### 3. Associate your ePPN with your DesignSafe/TACC Account { #globus-step3 }
+### 3. Associate your ePPN with your DesignSafe/TACC Account { #globus-step3 }
 
 Login to your TACC user profile here: https://accounts.tacc.utexas.edu.
 Select ePPN on the left menu and then enter your ePPN in the field at the top of the page and save.
 Allow 30 minutes for the ePPN to propagate through TACC's systems.
 
-#### 4. Activate Your Desktop/Laptop as a Globus Endpoint and Connect { #globus-step4 }
+### 4. Activate Your Desktop/Laptop as a Globus Endpoint and Connect { #globus-step4 }
 
-After giving your ePPN time to propagate through the systems (up to 30 minutes), go to <a href="https://globus.org" target="_blank">https://globus.org</a> and log in.
+After giving your ePPN time to propagate through the systems (up to 30 minutes), go to [https://globus.org](https://globus.org){ target="_blank" } and log in.
 
 ![Globus Login](./imgs/globus-step4-a.png)
 
@@ -93,7 +108,7 @@ Download Globus Connect Personal using the link on the page. It should automatic
 
 ![Create a personal endpoint](./imgs/globus-step4-d.png)
 
-Download and Install the Globus Connect Personal client. When setting the "Collection Name" be sure to select a descriptive name. We will use "My Laptop" as the name of our endpoint.
+Download and Install the Globus Connect Personal client. When setting the "Collection Name", be sure to select a descriptive name. We will use "My Laptop" as the name of our endpoint.
 
 After installation and setup is complete return to the Globus online interface. Select the “File Manager” tab (upper left), then click on the search bar immediately to the right of the label "Collection".
 
@@ -105,7 +120,7 @@ You can now access the files on your desktop/laptop via Globus.
 
 ![Estabilish connection to local endpoint](./imgs/globus-step4-f.png)
 
-#### 5. Connect to the DesignSafe (TACC Corral3) Endpoint { #globus-step5 }
+### 5. Connect to the DesignSafe (TACC Corral3) Endpoint { #globus-step5 }
 
 To view both endpoints simultaneously, change the Globus' interface to the "two pane" view by toggling the buttons next to "Panels" in the upper right.
 
@@ -117,21 +132,21 @@ Corral3 is a large (40 PB), shared data resource, as such, the data stored on De
 
 To access your data on DesignSafe
 
-* For <strong>My Data</strong> set Path to <strong>/data/designsafe/mydata/&lt;username&gt;/</strong>
-* For <strong>My Projects</strong> set Path to <strong>/corral/projects/NHERI/projects/&lt;project-uid&gt;/</strong>
-* For <strong>Published </strong>DesignSafe projects set Path to <strong>/corral/projects/NHERI/published/&lt;PRJ-XXXX&gt;</strong>/
-* For <strong>Published (NEES)</strong> projects set Path to <strong>/corral/projects/NHERI/public/projects/&lt;NEES-XXXX-XXXX.groups&gt;/</strong>
-* For <strong>Community Data</strong> set Path to <strong>/corral/projects/NHERI/community/</strong>
+* For <strong>My Data</strong> set Path to `/data/designsafe/mydata/<username>/`
+* For <strong>My Projects</strong> set Path to `/corral/projects/NHERI/projects/<project-uid>/`
+* For <strong>Published </strong>DesignSafe projects set Path to `/corral/projects/NHERI/published/<PRJ-XXXX>`
+* For <strong>Published (NEES)</strong> projects set Path to `/corral/projects/NHERI/public/projects/<NEES-XXXX-XXXX.groups>`
+* For <strong>Community Data</strong> set Path to `/corral/projects/NHERI/community/`
 
-For more information on path selection please see the detailed guide on <a href="#setting-path-to-ds-on-corral">Setting the Path to DesignSafe on Corral</a>.
+For more information on path selection please see the detailed guide on [Setting the Path to DesignSafe on Corral](/user-guide/managingdata/settingpathtodesignsafe).
 
 After entering the appropriate path to DesignSafe on Corral, you are ready to perform your file transfer.
 
-<em>Note: For directories you connect to frequenctly, for example My Data, you can create a bookmark for easy access using the bookmark icon immediately to the right of the "Path" bar.</em>
+_**Note:** For directories you connect to frequenctly, for example My Data, you can create a bookmark for easy access using the bookmark icon immediately to the right of the "Path" bar._
 
 ![Establish connection to Corral endpoint](./imgs/globus-step5.png)
 
-#### 6. Perform Transfer between Your Local Enpoint and the DesignSafe (TACC Corral3) Endpoint { #globus-step6 }
+### 6. Perform Transfer between Your Local Enpoint and the DesignSafe (TACC Corral3) Endpoint { #globus-step6 }
 
 To begin your transfer, select the file/folder you wish to move to/from DesignSafe.
 
@@ -147,27 +162,27 @@ Globus will email you when the transfer is complete.
 
 ---
 
-### Globus CLI Automated Transfer Guide { #globuscli }
+## Globus CLI { #globuscli data-subtitle="Automated Data Transfer Guide" }
 
 Globus provides a command line interface (CLI), for those who need to perform automated data transfers. This data transfer method will likely be of most use to NHERI centers that need to bulk upload their data on a schedule.
 
-#### 1. Follow the steps 1-3 above in Globus Data Transfer Guide { #globuscli-step1 }
+### 1. Follow the steps 1-3 above in Globus Data Transfer Guide { #globuscli-step1 }
 
-To set up your Globus access, follow steps 1-3 above in the <a href="#globus-step1">Globus Data Transfer Guide</a> .
+To set up your Globus access, follow steps 1-3 above in the [Globus Data Transfer Guide](#globus-step1) .
 
-#### 2. Activate Your Desktop/Laptop as a Globus Endpoint and Connect { #globuscli-step2 }
+### 2. Activate Your Desktop/Laptop as a Globus Endpoint and Connect { #globuscli-step2 }
 
-If the data you wish to transfer is located on your local machine, follow <a href="#globus-step4">Step 4 of the Globus Data Transfer Guide</a> to create a personal endpoint.
+If the data you wish to transfer is located on your local machine, follow [Step 4 of the Globus Data Transfer Guide](#globus-step4) to create a personal endpoint.
 
 If the data you wish to transfer is located on a server operated by your organization and does not already have a Globus Endpoint available, talk to your system administrator about creating one.
 
-#### 3. Install the Globus CLI { #globuscli-step3 }
+### 3. Install the Globus CLI { #globuscli-step3 }
 
-Follow the instructions provided by Globus for installing the CLI (<a href="https://docs.globus.org/cli/">https://docs.globus.org/cli</a>)
+Follow the [instructions provided by Globus for installing the CLI](https://docs.globus.org/cli).
 
-*Note the recommended installation method requires a system with Python3 and the ability to run pip commands.*
+_**Note:** The recommended installation method requires a system with Python3 and the ability to run `pip` commands._
 
-#### 4. Settings for CLI Transfer { #globuscli-step4 }
+### 4. Settings for CLI Transfer { #globuscli-step4 }
 
 With the Globus CLI successfully installed on our local machine, we must now determine the endpoint information for DesignSafe.
 
@@ -175,51 +190,51 @@ Go to the Globus web interface &gt; select the search bar.
 
 ![Select Globus Search Bar](./imgs/globuscli-1.png)
 
-Search for <strong>TACC Corral3 with CILogon Authentication </strong>&gt; <strong>click the three vertical dots to the right</strong> to view endpoint details.
+Search for <strong>TACC Corral3 with CILogon Authentication</strong> &gt; <strong>click the three vertical dots to the right</strong> to view endpoint details.
 
 ![Search and Select Three Dots](./imgs/globuscli-2.png)
 
-<strong>Copy the Endpoint UUID </strong>and store for later reference.
+<strong>Copy the Endpoint UUID</strong> and store for later reference.
 
 ![Copy UUID](./imgs/globuscli-3.png)
 
 <strong>Repeat the process above to attain the UUID for your local endpoint.</strong>
 
-#### 5. Test Globus CLI Transfer { #globuscli-step5 }
+### 5. Test Globus CLI Transfer { #globuscli-step5 }
 
 With the endpoint IDs, we can now do a test transfer with the Globus CLI.
 
 Start by authenticating by entering the following:
 
-<code>globus login</code>
+`globus login`
 
 This will prompt you to authenticate through your web-browser and grant permissions to Globus-CLI.
 
 Next, we create our transfer command. The basic structure follows:
 
-<code>globus transfer [OPTIONS] SOURCE_ENDPOINT_ID[:SOURCE_PATH] DEST_ENDPOINT_ID[:DEST_PATH]</code>
+`globus transfer [OPTIONS] SOURCE_ENDPOINT_ID[:SOURCE_PATH] DEST_ENDPOINT_ID[:DEST_PATH]`
 
 An example transfer command:
 
-<code>globus transfer --recursive [endpoint uuid for your machine]:[path on your machine] [endpoint uuid for tacc corral3]:[path on tacc corral3 to your My Data or Project]</code>
+`globus transfer --recursive [endpoint uuid for your machine]:[path on your machine] [endpoint uuid for tacc corral3]:[path on tacc corral3 to your My Data or Project]`
 
-Fill out the variables in the example command with the UUIDs and paths and submit the transfer. If you are unsure of the appropriate Corral3 path, please refer to the guide on <a href="#setting-path-to-ds-on-corral">Setting the Path to DesignSafe on Corral</a> for more information.
+Fill out the variables in the example command with the UUIDs and paths and submit the transfer. If you are unsure of the appropriate Corral3 path, please refer to the guide on [Setting the Path to DesignSafe on Corral](/user-guide/managingdata/settingpathtodesignsafe).
 
 You will get a message stating whether your transfer was successful or not. If it was successful, you will receive the message:
 
-<code>Message: The transfer has been accepted and a task has been created and queued for executionTask ID: [taskid]</code>
+`Message: The transfer has been accepted and a task has been created and queued for executionTask ID: [taskid]`
 
-The full reference for the Globus CLI can found here: <a href="https://docs.globus.org/cli/reference/">https://docs.globus.org/cli/reference</a>.
+The full reference for the Globus CLI can found here: [https://docs.globus.org/cli/reference](https://docs.globus.org/cli/reference/).
 
-The full reference for the transfer command, including information on additional options that may be useful to you, can be found here: <a href="https://docs.globus.org/cli/reference/transfer/">https://docs.globus.org/cli/reference/transfer</a>.
+The full reference for the transfer command, including information on additional options that may be useful to you, can be found here: [https://docs.globus.org/cli/reference/transfer](https://docs.globus.org/cli/reference/transfer/).
 
-#### 6. Create an Automatic Transfer Script { #globuscli-step6 }
+### 6. Create an Automatic Transfer Script { #globuscli-step6 }
 
 We will now create a shell script to store the transfer details (i.e., UUIDs and paths) and globus-cli syntax to allow us to quickly and reliably initiate future transfers.
 
 Below is an example script you can modify for your transfers. Note that this does hard code the UUIDs and paths and therefore assumes you are always transferring to and from the same locations.
 
-``` { .bash }
+```sh
 #!/bin/bash
 
 GLOBUS_CLI_INSTALL_DIR="$(python -c 'import site; print(site.USER_BASE)')/bin"
@@ -246,38 +261,38 @@ label=$"YourLabelHere_${label}"
 globus transfer --recursive --label $label "$ep1" "$ep2"
 ```
 
-#### 7. Automate Script Execution with cron { #globuscli-step7 }
+### 7. Automate Script Execution with cron { #globuscli-step7 }
 
 To automate the transfer we wil use the Linux scheduling utility cron to call our transfer script on a specified schedule.
 
 An example cron table entry that you can use to automatically run your transfer every six hours is listed below:
 
-<code>0 */6 * * * /location/of/your/globustransfer.sh &gt; /dev/null</code>
+`0 */6 * * * /location/of/your/globustransfer.sh > /dev/null`
 
 
 ---
 
-### Cyberduck Data Transfer Guide { #cyberduck }
+## Cyberduck { #cyberduck data-subtitle="Data Transfer Guide" }
 
 Cyberduck is an open-source SSH File Transfer Protocal (sftp) client that allows you to securely connect from your laptop to DesignSafe and other Texas Advanced Computing Center (TACC) resources.
 
-#### 1. Set up MFA using the TACC Token App { #cyberduck-step1 }
+### 1. Set up MFA using the TACC Token App { #cyberduck-step1 }
 
-TACC requires multi-factor authentication (MFA) for logging directly into our resources. Go to the <a href="https://www.tacc.utexas.edu/portal/login" target="_blank">TACC user portal</a> and log in with your DesignSafe/TACC credentials, click on Manage Account on the left menu, and then pair a device with your account. If needed you can explore the full <a href="https://docs.tacc.utexas.edu/basics/mfa/" target="_blank">MFA instructions.</a>
+TACC requires multi-factor authentication (MFA) for logging directly into our resources. Go to the [TACC user portal](https://www.tacc.utexas.edu/portal/login){ target="_blank" } and log in with your DesignSafe/TACC credentials, click on Manage Account on the left menu, and then pair a device with your account. If needed you can explore the full [MFA instructions](https://docs.tacc.utexas.edu/basics/mfa/){ target="_blank" }.
 
-#### 2. Download and Install Cyberduck { #cyberduck-step2 }
+### 2. Download and Install Cyberduck { #cyberduck-step2 }
 
-<a href="https://cyberduck.io/download/" target="_blank">Download Cyberduck</a> and install.
+[Download Cyberduck](https://cyberduck.io/download/){ target="_blank" } and install.
 
 Note that Cyberduck is Free Software and as such is freely available to download (see link above). However, some approaches to downloading Cyberduck (such as through the Windows Store and Mac App Store) come with a registration key that disables a donation prompt. While you may purchase a registration key to support the development of Cyberduck if you wish, the **activation key is not required** to use the software for transfer files to and from DesignSafe.
 
-#### 3. Create a New Bookmark { #cyberduck-step3 }
+### 3. Create a New Bookmark { #cyberduck-step3 }
 
 Launch the Cyberduck app and select "Bookmark" &gt; "New Bookmark".
 
 ![Figure 1. Bookmark](./imgs/cyberduck-1.png)
 
-#### 4. Populate Bookmark { #cyberduck-step4 }
+### 4. Populate Bookmark { #cyberduck-step4 }
 
 Change the top dropdown to "SFTP (SSH File Transfer Protocol)".
 
@@ -287,7 +302,7 @@ Set "Server" to "designsafe.data.tacc.utexas.edu".
 
 Enter your DesignSafe/TACC username and password.
 
-For the "Path", refer to <a href="/user-guide/managingdata/settingpathtodesignsafe" target="_blank">Setting Path to DS on Corral</a>.
+For the "Path", refer to [Setting Path to DesignSafe on Corral](/user-guide/managingdata/settingpathtodesignsafe).
 
 If you do not see the "Path" option click the button "More Options" in the lower left.
 
@@ -297,7 +312,7 @@ When done close the bookmark. You will now see your newly created bookmark in th
 
 ![Figure 2. Bookmark Filled](imgs/cyberduck-2.png)
 
-#### 5. Perform Transfer { #cyberduck-step5 }
+### 5. Perform Transfer { #cyberduck-step5 }
 
 Right-click on your newly created bookmark and select "Connect to Server". You will be prompted for your TACC Token code.  Input the code from your TACC Token app.
 
@@ -309,73 +324,85 @@ To download files, select the file(s) you wish to download. Select "File" &gt; "
 
 ---
 
-### Command-Line Data Transfer Guide { #cli }
+## Command Line Interface { #cli data-subtitle="Data Transfer Guide" }
 
-Common command-line utilities, such as scp and rsync, may also be used to transfer large amounts of data to DesignSafe. Command line tools require the shortest setup time (assuming you have a compatible terminal), however are generally found challenging for first-time users as you will need to learn unix commands. Therefore, command line transfers are only recommended in specific circumstances where other tools have been tried and found to be insufficient.
+Common command-line utilities, such as `scp` and `rsync`, may also be used to transfer large amounts of data to DesignSafe. Command line tools require the shortest setup time (assuming you have a compatible terminal), however are generally found challenging for first-time users as you will need to learn unix commands. Therefore, command line transfers are only recommended in specific circumstances where other tools have been tried and found to be insufficient.
 
-#### 1. Set up MFA using the TACC Token App { #cli-step1 }
+### 1. Set up MFA using the TACC Token App { #cli-step1 }
 
-TACC requires multi-factor authentication (MFA) for logging directly into our resources. Go to the <a href="https://www.tacc.utexas.edu/portal/login" target="_blank">TACC user portal</a> and log in with your DesignSafe/TACC credentials, click on Manage Account on the left menu, and then pair a device with your account. If needed you can explore the full <a href="https://docs.tacc.utexas.edu/basics/mfa/" target="_blank">MFA instructions.
+TACC requires multi-factor authentication (MFA) for logging directly into our resources. Go to the [TACC user portal](https://www.tacc.utexas.edu/portal/login){ target="_blank" } and log in with your DesignSafe/TACC credentials, click on Manage Account on the left menu, and then pair a device with your account. If needed you can explore the full <a href="https://docs.tacc.utexas.edu/basics/mfa/" target="_blank">MFA instructions.
 
-#### 2. Select Transfer Utility and Perform Transfer { #cli-step2 }
+### 2. Select Transfer Utility and Perform Transfer { #cli-step2 }
 
-There are several different command-line based file transfer utilities. We detail two of them here: scp and rsync.
+There are several different command-line based file transfer utilities. We detail two of them here: [`scp`](#cli-step3-scp) and [`rsync`](#cli-step3-rsync).
 
-##### scp { #cli-step3-scp }
+#### `scp` { #cli-step3-scp data-subtitle="Secure Copy Protocol" }
 
-A data transfer can be performed using the secure copy (scp) utility between any Linux, Mac, or Windows (with Window's Subsystem for Linux) machine and DesignSafe.
+A data transfer can be performed using the Secure Copy Protocol (`scp`) utility between any Linux, Mac, or Windows (with Window's Subsystem for Linux) machine and DesignSafe.
 
 A file can be copied from your local system to the remote server by using the command:
 
-where **&lt;filename&gt;** is the name of the file you wish to copy, **&lt;username&gt;** is your DesignSafe/TACC username, and **&lt;/path/to/directory&gt;** is the path on Corral where you wish to send the copy of your file. For the "Path", refer to <a href="/user-guide/managingdata/settingpathtodesignsafe" target="_blank">Setting Path to DS on Corral</a>.
+where `<filename>` is the name of the file you wish to copy, `<username>` is your DesignSafe/TACC username, and `</path/to/directory>` is the path on Corral where you wish to send the copy of your file. For the "Path", refer to [Setting Path to DesignSafe on Corral](/user-guide/managingdata/settingpathtodesignsafe).
 
 An entire folder can be copied from your local system to the remote server by using the command:
 
-<em><b>scp -r &lt;/path/to/folder/&gt; &lt;username&gt;@designsafe.data.tacc.utexas.edu:&lt;/path/to/project/directory/&gt;</b></em>
+```sh
+scp -r </path/to/folder/> <username>@designsafe.data.tacc.utexas.edu:</path/to/project/directory/>
+```
 
-where the `-r` indicates the copy should be recursive, <b><i>&lt;/path/to/folder/&gt;</b></i>is the name of the folder you wish to copy (be sure to include the final "/", and all other terms defined previously.
+where the `-r` indicates the copy should be recursive, `</path/to/folder/>` is the name of the folder you wish to copy (be sure to include the final "/", and all other terms defined previously.
 
 For help execute:
 
-<em><strong>scp -h</strong></em>
+```sh
+scp -h
+```
 
 For more information execute:
 
-<em><strong>man scp</strong></em>
+```sh
+man scp
+```
 
-##### rsync { #cli-step3-rsync }
+#### `rsync` { #cli-step3-rsync data-subtitle="Remote Synchronization" }
 
-A data transfer can also be performed using the rsync utility between any Linux, Mac, or Windows (with Window's Subsystem for Linux) machine and DesignSafe. The rsync utility is different from the scp utility as it first compares the source and destination files prior to performing the transfer and only performs a data transfer on the file(s) if they are different.
+A data transfer can also be performed using the Remote Synchronization (`rsync`) utility between any Linux, Mac, or Windows (with Window's Subsystem for Linux) machine and DesignSafe. The `rsync` utility is different from the `scp` utility as it first compares the source and destination files prior to performing the transfer and only performs a data transfer on the file(s) if they are different.
 
 A file can be synced from your local system to the remote server by using the command:
 
-	<em><strong>rsync &lt;filename&gt; &lt;username&gt;@designsafe.data.tacc.utexas.edu:&lt;/path/to/project/directory/&gt;</strong></em>
+```sh
+rsync <filename> <username>@designsafe.data.tacc.utexas.edu:</path/to/project/directory/>
+```
 
-where <em><strong>&lt;filename&gt;</strong></em> is the name of the file you wish to copy, <em><strong>&lt;username&gt;</strong></em> is your DesignSafe/TACC username, and <em><strong>&lt;/path/to/directory/&gt;</strong></em> is the path on Corral where you wish to send the copy of your file. For the "Path", refer to <a href="/user-guide/managingdata/settingpathtodesignsafe" target="_blank">Setting Path to DS on Corral</a>.
+where `<filename>` is the name of the file you wish to copy, `<username>` is your DesignSafe/TACC username, and `</path/to/directory/>` is the path on Corral where you wish to send the copy of your file. For the "Path", refer to [Setting Path to DesignSafe on Corral](/user-guide/managingdata/settingpathtodesignsafe).
 
 An entire directory can be synced from your local system to the remote server by using the command:
 
-	<em><strong>rsync -avtr &lt;/path/to/folder/&gt; &lt;username&gt;@designsafe.data.tacc.utexas.edu:&lt;/path/to/project/directory&gt;</strong></em>
-
-where <strong>-avtr</strong> will transfer the files recursively <em><strong>-r</strong></em>,  with the modification times <em><strong>-t</strong></em>, in the archive mode <em><strong>-a</strong></em>, and verbosely <em><strong>-v </strong></em>and all other terms defined previously.
-
+```sh
+rsync -avtr </path/to/folder/> <username>@designsafe.data.tacc.utexas.edu:</path/to/project/directory>
+```
 
+where `-avtr` will transfer the files recursively `-r`,  with the modification times `-t`, in the archive mode `-a`, and verbosely `-v`and all other terms defined previously.
 
 For help execute:
 
-<em><strong>rsync -h</strong></em>
+```sh
+rsync -h
+```
 
 For more information execute:
 
-<em><strong>man rsync</strong></em>
+```sh
+man rsync
+```
 
 ---
 
-### Data Depot's Browser-Based Data Transfer Guide { #datadepotbrowser }
+## Data-Depot Web Browser { #datadepotbrowser data-subtitle="Data Transfer Guide" }
 
 The Data Depot's browser interface allows you to conveniently upload and download small quantities of data (&lt; 100 MB, &lt; 25 files, &lt; 2 folders) as well as move and copy data between directories.
 
-#### Upload { #datadepotbrowser-upload }
+### Upload { #datadepotbrowser-upload }
 
 To upload a small amount of data through your browser **login to DesignSafe** and **go to My Data**.
 
@@ -393,7 +420,7 @@ Select **Browse...** at the top to select the files you wish to upload. Press **
 
 Once the transfer is complete the Upload files window will close and you will see your files in your DesignSafe directory.
 
-**Note, if the files are not immediately visible refresh the page.**
+_**Note:** If the files are not immediately visible refresh the page._
 
 ![Upload Complete](./imgs/datadepotbrowser-4.png)
 
@@ -401,17 +428,17 @@ If you wish to upload a folder, follow the same procedure as above except select
 
 
 
-#### Download { #datadepotbrowser-download }
+### Download { #datadepotbrowser-download }
 
 To download a file from DesignSafe to your local desktop/laptop **select the file** you wish to download and press **Download**.
 
-**Note depending on how you have configured your browser, it will either download the file directly to your default downloads directory or will prompt you to save the file in a location of your choice.**
+_**Note:** Depending on how you have configured your browser, it will either download the file directly to your default downloads directory or will prompt you to save the file in a location of your choice._
 
 ![Select File for Download](./imgs/datadepotbrowser-5.png)
 
 If you would like to download an entire folder from DesignSafe, please use one of the large data transfer methods listed in this guide.
 
-#### Transferring Data Inside of DesignSafe { #datadepotbrowser-transferring }
+### Transferring Data Inside of DesignSafe { #datadepotbrowser-transferring }
 
 You can move and copy the data inside of DesignSafe using the browser-based interface.
 
@@ -419,15 +446,15 @@ You can move and copy the data inside of DesignSafe using the browser-based inte
 
 ![Select File for Move or Copy](./imgs/datadepotbrowser-6.png)
 
-##### If you selected Move { #datadepotbrowser-transferring-move }
+#### If you selected Move { #datadepotbrowser-transferring-move }
 
 Navigate to the new destination and press **Move Here**.
 
-**Note that you cannot move files between main directories, such as My Data and My Projects, however may copy between them. See instructions below for details.**
+_**Note:** You cannot move files between main directories, such as My Data and My Projects, however may copy between them. See instructions below for details._
 
 ![Move Here](./imgs/datadepotbrowser-7.png)
 
-##### If you selected Copy { #datadepotbrowser-transferring-copy }
+#### If you selected Copy { #datadepotbrowser-transferring-copy }
 
 **Use the drop down menu** in the top left to switch between main directories, such as My Data and My Projects, **navigate to the new destination**, and press **Copy Here**.
 
@@ -435,11 +462,11 @@ Navigate to the new destination and press **Move Here**.
 
 ---
 
-### JupyterHub's Browser-Based Data Transfer Guide { #jupyterhubbrowser }
+## JupyterHub Web Browser { #jupyterhubbrowser data-subtitle="Data Transfer Guide" }
 
-The DesignSafe JupyterHub provides a convenient way to upload and download small amounts of data ( &lt; 100 MB, &lt; 25 files).
+The DesignSafe JupyterHub provides a convenient way to upload and download small amounts of data (&lt; 100 MB, &lt; 25 files).
 
-#### To Upload a File Through Jupyter { #jupyterhubbrowser-upload }
+### To Upload a File Through Jupyter { #jupyterhubbrowser-upload }
 
 Launch Jupyter by logging into DesignSafe and going to **Use DesignSafe** &gt; **Tools &amp; Applications** &gt; **Analysis** &gt; **Jupyter** &gt; **Select Jupyter from dropdown**.
 
@@ -469,26 +496,30 @@ If you would like to upload an entire folder, please use one of the large data t
 
 
 
-#### To Download a File Through Jupyter { #jupyterhubbrowser-download }
+### To Download a File Through Jupyter { #jupyterhubbrowser-download }
 
 To download a file, **select the file** then select **Download**.
 
-*Note depending on how you have configured your browser, it will either download the file directly to your default downloads directory or will prompt you to save the file in a location of your choice.*
+_**Note:** Depending on how you have configured your browser, it will either download the file directly to your default downloads directory or will prompt you to save the file in a location of your choice._
 
 ![Select File for Download](./imgs/jupyterbrowser-6.png)
 
 If you would like to download an entire folder, please use one of the large data transfer methods listed in this guide.
 
-### Cloud Storage Transfer { #cloud }
+## Cloud Storage Services { #cloud }
 
 DesignSafe provides users the capability to connect to a cloud storage provider.
 
-Once connected, data held on the cloud storage provider can be easily copied to and from DesignSafe. Note DesignSafe does not actively synchronize your data and so any copy operation must be initiated manually. Any changes you make to data transferred to DesignSafe from a cloud storage provider will not affect the files located on the cloud storage provider. To update the files on the cloud storage provider you must manually copy them back to the provider using the copy functionality in the DesignSafe browser interface.
+Once connected, data held on the cloud storage provider can be easily copied to and from DesignSafe. Note that DesignSafe does not actively synchronize your data and so any copy operation must be initiated manually. Any changes you make to data transferred to DesignSafe from a cloud storage provider will not affect the files located on the cloud storage provider. To update the files on the cloud storage provider you must manually copy them back to the provider using the copy functionality in the DesignSafe browser interface.
 
-Currently Dropbox is supported. <!--The three main cloud storage providers, <a href="#cloud-box">Box</a>, <a href="#cloud-dropbox">Dropbox</a>,and <a href="#cloud-googledrive">Google Drive</a>, are supported on DesignSafe.--> Detailed instruction for setting up integration is provided below.
+_**Note:** Currently, only Dropbox is supported._
 
 <!--
-#### Box { #cloud-box }
+The three main cloud storage providers, [Box](#cloud-box), [Dropbox](#cloud-dropbox),and [Google Drive](#cloud-googledrive), are supported on DesignSafe. Detailed instruction for setting up integration is provided below.
+-->
+
+<!--
+### Box { #cloud-box }
 
 **Login to DesignSafe** and go to **Use DesignSafe &gt; Data Depot &gt; Box.com**.
 
@@ -507,14 +538,12 @@ Return to the Box.com section of the Data Depot. You can now copy files to and f
 ![Box Complete](./imgs/cloudstorage-1.png)
 -->
 
-#### Dropbox { #cloud-dropbox }
+### Dropbox { #cloud-dropbox }
 
 Login to DesignSafe and go to Use DesignSafe &gt; Data Depot &gt; Dropbox.com.
 
-
 ![Dropbox Begin](./imgs/cloudstorage-drop-1.png)
 
-
 Follow the on-screen instructions to login to your Dropbox.com account.
 
 ![Enable Dropbox](./imgs/cloudstorage-drop-2.png)
@@ -522,11 +551,11 @@ Follow the on-screen instructions to login to your Dropbox.com account.
 Return to the Dropbox.com section of the Data Depot. You can now copy files to and from your Dropbox.com account.
 
 <!--
-#### Google Drive - CURRENTLY NOT FUNCTIONAL { #cloud-googledrive }
+### Google Drive - CURRENTLY NOT FUNCTIONAL { #cloud-googledrive }
 
-GOOGLE HAS MADE CHANGES THAT WE ARE WORKING THROUGH TO REENABLE (status as of January 11, 2023)
+GOOGLE HAS MADE CHANGES THAT WE ARE WORKING THROUGH TO RE-ENABLE (status as of January 11, 2023)
 
-Google has made changes that we are working through to reenable.
+Google has made changes that we are working through to re-enable.
 
 Login to DesignSafe and go to Use DesignSafe &gt; Data Depot &gt; Google Drive
 
diff --git a/user-guide/docs/managingdata/experimentalfacilitychecklist.md b/user-guide/docs/managingdata/experimentalfacilitychecklist.md
index 7a753a4e..86019eb9 100644
--- a/user-guide/docs/managingdata/experimentalfacilitychecklist.md
+++ b/user-guide/docs/managingdata/experimentalfacilitychecklist.md
@@ -1,62 +1,55 @@
-## Experimental Facility Checklist
+# Experimental Facility Checklist { data-subtitle="An Onboarding Checklist for Data Curation" }
 
-### DesignSafe-EF Onboarding Checklist for Data Curation { #onboarding }
+DesignSafe has been developed as a comprehensive research environment supporting a range of activities from research planning to cloud-based data analysis to data curation/publication.  We encourage users to take full advantage of the DesignSafe capabilities associated with both the Data Depot data repository and the Tools and Apps.  To learn more about all of these capabilities, watch this [Introductory Webinar](https://www.youtube.com/watch?v=5Yus9MjtcTM&amp;feature=youtu.be){ target="_blank" }.
 
-DesignSafe has been developed as a comprehensive research environment supporting a range of activities from research planning to cloud-based data analysis to data curation/publication.  We encourage users to take full advantage of the DesignSafe capabilities associated with both the Data Depot data repository and the Tools and Apps.  To learn more about all of these capabilities, watch this <a href="https://www.youtube.com/watch?v=5Yus9MjtcTM&amp;feature=youtu.be" target="_blank">Introductory Webinar</a>.
 
-### Phase 1 - Before arriving to the Experimental Facility (EF): { #phase1 }
+## Phase 1: Before the Experimental Facility { #phase1 }
 
-* Create an account on DesignSafe: <a href="https://www.designsafe-ci.org/account/register/">Account Registration</a>
-* Familiarize yourself with the Data Depot and the curation process.
-
-	* User Guide for Data Curation and Publication: <a href="../curating/#curation-publication-faq">User Guide</a>
-	* Watch the data curation and publication tutorial available in the learning center: <a href="https://www.youtube.com/playlist?list=PL2GxvrdFrBlkwHBgQ47pZO-77ZLrJKYHV" target="_blank">Video Tutorial</a>
-	* Look at examples of well curated experimental projects:
-
-		* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3218" target="_blank">Experimental Investigation of Wave, Surge, and Tsunami Transformation Over Natural Shorelines: Reduced Scale Physical Model</a>
-		* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2141" target="_blank">CFS-NHERI: Seismic Resiliency of Repetitively Framed Mid-Rise cold-Formed Steel Buildings</a>
-		* <a href="https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3197" target="_blank">Progressive Damage and Failure of Wood-Frame Coastal Residential Structures Due to Hurricane Surge and Wave Forces</a>
-	
-	
-	* Read the FAQ regarding data curation and publication: <a href="/user-guide/curating/faq/">Frequently Asked Questions</a>
-	* Learn about the different data transfer methods to identify which one you may need for data upload: <a href="/user-guide/managingdata/datatransfer/">Data Transfer Guide</a>
-
-
-* Familiarize yourself with the available Tools and Apps.
-	* [Tools and Apps User Guide](https://www.designsafe-ci.org/use-designsafe/tools-applications/)
+1. [Create an account on DesignSafe **via TACC**.](https://www.designsafe-ci.org/account/register/)
+2. Familiarize yourself with the Data Depot and the curation process.
+	* [Best Practices](/user-guide/curating/bestpractices/) & [Policies](/user-guide/curating/policies/)
+	* [Data Curation and Publication Tutorial Videos](https://www.youtube.com/playlist?list=PL2GxvrdFrBlkwHBgQ47pZO-77ZLrJKYHV){ target="_blank" } available in the learning center.
+	* Well-Curated Experimental Projects:
+		* [Experimental Investigation of Wave, Surge, and Tsunami Transformation Over Natural Shorelines: Reduced Scale Physical Model](https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3218){ target="_blank" }
+		* [CFS-NHERI: Seismic Resiliency of Repetitively Framed Mid-Rise cold-Formed Steel Buildings](https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-2141){ target="_blank" }
+		* [Progressive Damage and Failure of Wood-Frame Coastal Residential Structures Due to Hurricane Surge and Wave Forces](https://www.designsafe-ci.org/data/browser/public/designsafe.storage.published/PRJ-3197){ target="_blank" }
+	* [Frequently Asked Questions](/user-guide/curating/faq/)
+	* [Data Transfer Guide](/user-guide/managingdata/datatransfer/)
+3. Familiarize yourself with the available Tools and Apps.
+	* [Tools and Apps](https://www.designsafe-ci.org/use-designsafe/tools-applications/){ target="_blank" }
 	* Python scripts in Jupyter can be used for real-time data analysis within the Data Depot.
-* Add a Project within the Data Depot.
-	* This Project may be created by any research team member (PI/co-PI/student) or it may already exist from a previous phase of the research project.
-	* Make sure that all PIs/co-PIs and team members are added to the project (accessed from the Edit Project link).
+4. Add a project within the Data Depot.
+	* This project may be created by any research team member (PI/co-PI/student) or it may already exist from a previous phase of the research project.
+	* Make sure that all PIs/co-PIs and team members are added to the project (accessed from the "Edit Project" link).
 	* Assign one team member responsible for uploading and coordinating data management activities.
 	* PIs and co-PIs should be informed and contribute to curation decisions including final publication.
 
 
-### Phase 2 - At the EF: { #phase2 }
+## Phase 2: While at the Experimental Facility { #phase2 }
+
+The following steps will be completed _as a team_.
 
-* The following steps will be completed as a team.
-* Upload project data files into your Project as soon as you gather and produce them.
+1. Upload project data files into your Project as soon as you gather and produce them.
 	* Include model drawings, sensors, loading inputs, ground motions, material testing, specs, and any experiment planning documents.
-	* It is best to use open formats for your data such as docx, csv, txt/ascii, tif and other preservation friendly formats (<font color="red">link here to information</font>).
-	* If possible upload both zipped and unzipped versions of your files to accommodate future data download and data use.
-* You may begin the curation process as soon as you start uploading files to DesignSafe. You will continue this process after your work at the EF.
+	* It is best to use open formats for your data such as `.docx`, `.csv`, `.txt`/ascii, `.tif` and other preservation friendly formats.
+	* If possible, upload both zipped and unzipped versions of your files to accommodate future data download and data use.
+2. You may begin the curation process as soon as you start uploading files to DesignSafe. You will continue this process after your work at the EF (Experimental Facility).
 
 
-### Phase 3 – After the EF: { #phase3 }
+## Phase 3: After the Experimental Facility { #phase3 }
 
-* Attend Virtual Curation Office Hours. As a team, make an appointment with the DesignSafe Data Curator to discuss data management. Office hours are every Tuesday and Thursday at 1 pm central:
-	* Curation Office Hours <a href="https://designsafe-ci.zoom.us/j/730745593?pwd=U0VyaG1nVHgya3RZaS9hZng1MU82UT09" target="_blank">Zoom Link</a>
-	* Sign up sheet to reserve a time slot: <a href="https://signup.com/go/fxHQnhr" target="_blank">Sign Up Sheet</a>
-* Finalize curation of your project:
+1. Attend [Virtual Curation Office Hours](https://designsafe-ci.org/facilities/virtual-office-hours/){ target="_blank" }. As a team, make an appointment with the DesignSafe Data Curator to discuss data management.
+2. Finalize curation of your project:
 	* Finalize and organize Experiments, Categories, and Relationships.
 	* Tag files appropriately.
 	* Ask someone unfamiliar with the project to review the project description to see if it makes sense to a wider audience.
-* Publish your project:
+3. Publish your project:
 	* Select Publication Preview to examine the layout of your publication.
-	* Publish your project using the Prepare to Publish button within the Publication Preview.  Confirm the project metadata, files to be published, etc., and then click Request DOI and Publish.
+	* Publish your project using the "Prepare to Publish" button within the Publication Preview. Confirm the project metadata, files to be published, et cetera, and then click "Request DOI and Publish".
 	* The project will be publicly available in the Published section of the Data Depot within about 24 hours.
 
-### General Comments { #comments }
+
+## General Comments { #comments }
 
 * Publishing the data from your project quickly will help you comply with the requirements of your funding sources, allow you to cite your data with a DOI in your upcoming publications and presentations, and bring prompt attention to your work.
 * DesignSafe provides the possibility to publish one experiment at a time, so you do not need to finish your entire research project to publish all the experiments.
diff --git a/user-guide/docs/managingdata/settingpathtodesignsafe.md b/user-guide/docs/managingdata/settingpathtodesignsafe.md
index bd4fbe15..8ebb089c 100644
--- a/user-guide/docs/managingdata/settingpathtodesignsafe.md
+++ b/user-guide/docs/managingdata/settingpathtodesignsafe.md
@@ -1,43 +1,40 @@
-## Setting Path to DesignSafe on Corral
+# Setting Path to DesignSafe on Corral
 
 The data stored on DesignSafe resides on the large (40 PB), shared data resource Corral located at the Texas Advanced Computing Center. Importantly, Corral services many different projects, not only DesignSafe, and as such utilizes a complex file structure for organization. The purpose of this documentation is to explain how to navitage this complex file structure to locate the directories pertinent to your data transfer needs on DesignSafe.
 
-There are four main locations for data transfers on DesignSafe: <a href="#mydata">My Data</a>, <a href="#myprojects">My Projects</a>, <a href="#published-nheri">Published</a>, and <a href="#published-nees">Published (NEES)</a>, they are each presented in detail below.
+There are four main locations for data transfers on DesignSafe — [My Data](#mydata), [My Projects](#myprojects), [Published](#published-nheri), [Published (NEES)](#published-nees) — each presented in detail below.
 
-### Path to My Data { #mydata }
+## Path to My Data { #mydata }
 
-For <strong>My Data</strong> set Path to <strong>/data/designsafe/mydata/&lt;username&gt;/</strong>
+1. Set Path to `/data/designsafe/mydata/<username>/`.
+2. Replace `<username>` with your username.
+    <br><small>You can find your username by examining the URL in My Data, see figure below.</small>
 
-Replace <strong>&lt;username&gt;</strong> with your username. You can find your username by examining the URL in My Data, see figure below.
+    ![Path to My Data](./imgs/settingpath-1.png)
 
-![Path to My Data](./imgs/settingpath-1.png)
+## Path to My Projects { #myprojects }
 
+1. Set Path to `/corral/projects/NHERI/projects/<project-uid>/`.
+2. Replace `<project-uid>` with your projects unique identifier (UID).
+    <br><small>You can find your projects UID by clicking the <strong>Learn how to transfer data to this project</strong> button, see figure below.</small>
 
+    ![Path to My Projects](./imgs/settingpath-2.png)
 
-### Path to My Projects { #myprojects }
+## Path to Published { #published-nheri }
 
-For <strong>My Projects</strong> set Path to <strong>/corral/projects/NHERI/projects/&lt;project-uid&gt;/</strong>
+1. Set Path to `/corral/projects/NHERI/published/<PRJ-XXXX>`.
+2. Replace `<PRJ-XXXX>` with your project's number.
+    <br><small>You can find your project number by examining the URL in Published, see figure below.</small>
 
-Replace <strong>&lt;project-uid&gt;</strong> with your projects unique identifier (UID). You can find your projects UID by clicking the <strong>Learn how to transfer data to this project</strong> button, see figure below.
+    ![Path to Published](./imgs/settingpath-3.png)
 
-![Path to My Projects](./imgs/settingpath-2.png)
+## Path to Published (NEES) { #published-nees }
 
-### Path to Published { #published-nheri }
+1. Set Path to `/corral/projects/NHERI/public/projects/<NEES-XXXX-XXXX.groups>`
+2. Replace `<NEES-XXXX-XXXX.group>` with the NEES project number.
+    <br><small>You can find the NEES project number by examining the URL in Published (NEES), see figure below.</small>
 
-For <strong>Published </strong>DesignSafe projects set Path to <strong>/corral/projects/NHERI/published/&lt;PRJ-XXXX&gt;</strong>
+    ![Path to Published (NEES)](./imgs/settingpath-4.png)
 
-Replace <strong>&lt;PRJ-XXXX&gt;</strong> with your project's number. You can find your project number by examining the URL in Published, see figure below.
-
-![Path to Published](./imgs/settingpath-3.png)
-
-
-### Path to Published (NEES) { #published-nees }
-
-For <strong>Published (NEES)</strong> projects set Path to <strong>/corral/projects/NHERI/public/projects/&lt;NEES-XXXX-XXXX.groups&gt;</strong>
-
-Replace <strong>&lt;NEES-XXXX-XXXX.groups&gt;</strong> with the NEES project number. You can find the NEES project number by examining the URL in Published (NEES), see figure below.
-
-![Path to Published (NEES)](./imgs/settingpath-4.png)
-
-
-<strong>If you have any issues setting the path to DesignSafe on Corral, please create a ticket (<a href="https://designsafe-ci.org/help">https://designsafe-ci.org/help</a>)</strong>.
+!!! note
+    If you have any issues setting the path to DesignSafe on Corral, please [create a ticket](https://designsafe-ci.org/help){ target="_blank" }.
diff --git a/user-guide/docs/overview.md b/user-guide/docs/overview.md
index 4a1e8028..6b380daa 100644
--- a/user-guide/docs/overview.md
+++ b/user-guide/docs/overview.md
@@ -1,7 +1,6 @@
+# Overview of DesignSafe
 
-## Documentation Overview
-
-**Data Depot**: The Data Depot section provides documentation on managing your data including various methods to transfer your data to DesignSafe, guidance for including DesignSafe in your NSF Data Management Plan, and a checklist for data curation when working with a NHERI Experimental Facility. There is extensive guidance for curating and publishing your datasets for reuse by others including working with protected/regulated/sensitive data.
+**Data Depot**: The Data Depot section provides documentation on managing your data including various methods to transfer your data to DesignSafe, guidance for including DesignSafe in your NSF [Data Management Plan](/user-guide/getting-started/manage-data/#data-management-plan), and a checklist for data curation when working with a NHERI Experimental Facility. There is extensive guidance for curating and publishing your datasets for reuse by others including working with protected/regulated/sensitive data.
 
 **Tools and Apps**: This section contains user guides for how to utilize our many offerings in data analytics, GIS and mapping, visualization, and our Jupyter Hub interacting with the data you bring to DesignSafe or that you discover in our Published datasets.
 